 ULE-BASED  Bril  Department of Computer Science  University of Pennsylvania  obtained a high degree of accuracy without performing  CT  Automatic part of speech tagging is an area of natural  lanany syntactic analysis on the input. These stochastic  guage processing where statistical techniques have been more  part of speech taggers make use of a Markov model  successful than rule-based methods. In this paper, we present  which captures lexical and contextual information. The  a simple rule-based part of speech tagger which  automatiparameters of the model can be estimated from tagged  cally acquires its rules and tags with accuracy comparable  [1, 3, 4, 6, 12] or untagged [2, 9, 11] text. Once the  to stochastic taggers. The rule-based tagger has many  adparameters of the model are estimated, a sentence can  vantages over these taggers, including: a vast reduction in  stored information required, the perspicuity of a small set  then be automatically tagged by assigning it the tag  seof meaningful rules, ease of nding and implementing  imquence which is assigned the highest probability by the  provements to the tagger, and better portability from one  model. Performance is often enhanced with the aid of  tag set, corpus genre or language to another. Perhaps the  various higher level and postprocessing procedures  biggest contribution of this work is in demonstrating that  or by manually tuning the model.  the stochastic method is not the only viable method for part  of speech tagging. The fact that a simple rule-based tagger  A number of rule-based taggers have been built [10, 7, 8].  that automatically learns its rules can perform so well should  [10] and [7] both have error rates substantially higher  oer encouragement for researchers to further explore  rulethan state of the art stochastic taggers. [8]  disambased tagging, searching for a better and more expressive  biguates words within a deterministic parser. We wanted  set of rule templates and other variations on the simple but  to determine whether a simple rule-based tagger  witheective theme described below.  out any knowledge of syntax can perform as well as a  stochastic tagger, or if part of speech tagging really is a  domain to which stochastic techniques are better suited.  INTR  There has been a dramatic increase in the application of  probabilistic models to natural language processing over In this paper we describe a rule-based tagger which per-the last few years. The appeal of stochastic techniques forms as well as taggers based upon probabilistic models.  over traditional rule-based techniques comes from the The rule-based tagger overcomes the limitationscommon ease with which the necessary statistics can be in rule-based approaches to language processing: it is ically acquired and the fact that very little handcrafted robust, and the rules are automatically acquired. In ad-knowledge need be built into the system. In contrast, dition, the tagger has many advantages over stochastic the rules in rule-based systems are usually dicult to taggers, including: a vast reduction in stored informa-construct and are typically not very robust.  tion required, the perspicuity of a smallset of meaningful  rules as opposed to the large tables of statistics needed  One area in which the statistical approach has done for stochastic taggers, ease of nding and implementing ticularly well is automatic part of speech tagging, improvements to the tagger, and better portability from signing each word in an input sentence its proper part of one tag set or corpus genre to another.  A version of this paper appears in Proceedings of the Third  Conference on Applied Computational Linguistics (ACL), Trento,  The tagger works by automatically recognizing and  remItaly, 1992. Used by permission of the Association for  Computational Linguistics; copies of the publication from which this  maedying its weaknesses, thereby incrementally improving  terial is derived can can be obtained from Dr. Donald E. Walker  its performance. The tagger initially tags by assigning  (ACL), Bellcore, MRE 2A379, 445 South Street, Box 1910,  Morriseach word its most likely tag, estimated by examining a  town, NJ 07960-1910, USA. The author would like to thank Mitch  large tagged corpus, without regard to context. In both  Marcus and Rich Pito for valuableinput. This work was supported  by DARPA and AFOSR jointly under grant No. AFOSR-90-0066,  sentences below, run would be tagged as a verb:  and by ARO grant No. DAAL 03-89-C0031 PRI.  The  lasted thirty minutes.  have been tagged with tag in the patch corpus. Next, for  three miles every day.  each error triple, it is determined which instantiation of  a template from the prespecied set of patch templates  results in the greatest error reduction. Currently, the  The initial tagger has two procedures built in to improve patch templates are:  performance; both make use of no contextual  information. One procedure is provided with information that Change tag to tag when:  words that were not in the training corpus and are  capitalized tend to be proper nouns, and attempts to x  tagging mistakes accordingly. This information could be  acquired automatically (see below), but is prespecied  1. The preceding (following) word is tagged z.  in the current implementation. In addition, there is a  procedure which attempts to tag words not seen in the  2. The word two before (after) is tagged z.  training corpus by assigning such words the tag most  3. One of the two preceding (following) words is tagged  common for words ending in the same three letters. For  example, blahblahous would be tagged as an adjective,  because this is the most common tag for words ending  4. One of the three preceding (following) words is  in ous. This information is derived automatically from  the training corpus.  5. The preceding word is tagged z and the following  This very simple algorithm has an error rate of about  7.9% when trained on 90% of the tagged Brown Corpus1  [5], and tested on a separate 5% of the corpus. Training  6. The preceding (following) word is tagged z and the  consists of compiling a list of the most common tag for  word two before (after) is tagged w.  each word in the training corpus.  7. The current word is (is not) capitalized.  The tagger then acquires patches to improve its  performance. Patch templates are of the form:  8. The previous word is (is not) capitalized.  If a word is tagged and it is in context , then For each error triple < tag ;tag ;number > and patch, a  change that tag to , or  we compute the reduction in error which results from  If a word is tagged and it has lexical property , applying the patch to remedy the mistagging of a word a  then change that tag to , or  as tag when it should have been tagged tag . We then  compute the number of new errors caused by applying  If a word is tagged and a word in region has the patch; that is, the number of times the patch results a  lexical property , then change that tag to .  in a word being tagged as tag when it should be tagged  tag . The net improvement is calculated by subtracting  the latter value from the former.  The initial tagger was trained on 90% of the corpus (the For example, when the initial tagger tags the patch cor-training corpus). 5% was held back to be used for the pus, it mistags 159 words as verbs when they should be patch acquisition procedure (the patch corpus) and 5% nouns. If the patch change the tag from verb to noun if for testing. Once the initial tagger is trained, it is used to one of the two preceding words is tagged as a determiner tag the patch corpus. A list of tagging errors is compiled is applied, it corrects 98 of the 159 errors. However, by comparing the output of the tagger to the correct it results in an additional 18 errors from changing tags tagging of the patch corpus. This list consists of triples which really should have been verb to noun. This patch  < tag ;tag ;number >, indicating the number of times results in a net decrease of 80 errors on the patch corpus.  the tagger mistagged a word with tag when it should  The patch which results in the greatest improvement to  The Brown Corpus contains about 1.1 million words from a  the patch corpus is added to the list of patches. The  variety of genres of written English. There are 192 tags in the tag  set, 96 of which occur more than one hundred times in the corpus.  patch is then applied in order to improve the tagging of  The test set contained text from all genres in the Brown  the patch corpus, and the patch acquisition procedure  Corpus.  The rst ten patches found by the system are listed  below .  Patch Application and Error Reduction  (1) TO IN NEXT-TAG AT  (2) VBN VBD PREV-WORD-IS-CAP YES  (6) TO IN NEXT-WORD-IS-CAP YES  (10) NP NN CURRENT-WORD-IS-CAP NO  The rst patch states that if a word is tagged  and the  following word is tagged  , then switch the tag from  to . This is because a noun phrase is much more  likely to immediately follow a preposition than to  immediately follow innitive  . The second patch states  that a tag should be switched from  to  if the  preceding word is capitalized. This patch arises from two  Number of Patches  facts: the past verb tag is more likely than the past  participle verb tag after a proper noun, and is also the more  likely tag for the second word of the sentence. The third  TS  patch states that  should be changed to  if The tagger was tested on 5% of the Brown Corpus  inany of the preceding three words are tagged  cluding sections from every genre. First, the test corpus  Once the list of patches has been acquired, new text was tagged by the simple lexical tagger. Next, each of can be tagged as follows. First, tag the text using the the patches was in turn applied to the corpus. Below is a basic lexical tagger. Next, apply each patch in turn to graph showing the improvement in accuracy from apply-the corpus to decrease the error rate. A patch which ing patches. It is signicant that with only 71 patches, changes the tagging of a word from to only applies an error rate of 5.1% was obtained . Of the 71 patches, 5  66 resulted in a reduction in the number of errors in the  if the word has been tagged somewhere in the training test corpus, 3 resulted in no net change, and 2 resulted b  in a higher number of errors. Almost all patches which  Note that one need not be too careful when constructing were eective on the training corpus were also eective the list of patch templates. Adding a bad template to the on the test corpus.  list will not worsen performance. If a template is bad,  then no rules which are instantiations of that template Unfortunately, it is dicult to compare our results with will appear in the nal list of patches learned by the other published results. In [12], an error rate of 3-4%  tagger. This makes it easy to experiment with extensions on one domain, Wall Street Journal articles and 5.6%  to the tagger.  on another domain, texts on terrorism in Latin  American countries, is quoted. However, both the domains  and the tag set are dierent from what we use. [1]  reAT = article, HVD = had, IN = preposition, MD = modal,  ports an accuracy of \95-99% correct, depending on the  NN = sing. noun, NP = proper noun, PPS = 3rd sing. nom.  denition of correct". We implemented a version of the  We ran the experiment three times. Each time we divided the  Both the rst word of a sentence and proper nouns are  corpus into training, patch and test sets in a dierent way. All  three runs gave an error rate of 5%.  algorithm described in [1] which did not make use of a was divided into a training corpus of about one million dictionary to extend its lexical knowledge. When trained words, a patch corpus of about 65,000 words and a test and tested on the same samples used in our experiment, corpus of about 65,000 words. Patches were acquired we found the error rate to be about 4.5%. [3] quotes as described above. When tested on the test corpus, a 4% error rate when testing and training on the same with lexical information derived solely from the training text. [6] reports an accuracy of 96-97%. Their corpus, the error rate was 5%. Next, the same patches bilistic tagger has been augmented with a handcrafted were used, but lexical information was gathered from procedure to pretag problematic \idioms". This the entire Brown Corpus. This reduced the error rate to dure, which requires that a list of idioms be laboriously 4.1%. Finally, the same experiment was run with lexical created by hand, contributes 3% toward the accuracy of information gathered solely from the test corpus. This their tagger, according to [3]. The idiom list would have resulted in a 3.5% error rate. Note that the patches used to be rewritten if one wished to use this tagger for a in the two experiments with no unknown words were dierent tag set or a dierent corpus. It is interesting not the optimal patches for these tests, since they were to note that the information contained in the idiom list derived from a corpus that contained unknown words.  can be automatically acquired by the rule-based tagger.  For example, their tagger had diculty tagging as old  as. An explicit rule was written to pretag as old as with  CONCLUSIONS  the proper tags. According to the tagging scheme of the We have presented a simple rule-based part of speech Brown Corpus, the rst as should be tagged as a tagger which performs as well as existing stochastic tag-er, and the second as a subordinating conjunction. In gers, but has signicant advantages over these taggers.  the rule-based tagger, the most common tag for as is  subordinating conjunction. So initially, the second as is The tagger is extremely portable. Many of the higher tagged correctly and the rst as is tagged incorrectly. To level procedures used to improve the performance of remedy this, the system acquires the patch: if the stochastic taggers would not readily transfer over to a rent word is tagged as a subordinating conjunction, and  dierent tag set or genre, and certainly would not  transso is the word two positions ahead, then change the tag of  fer over to a dierent language. Everything except for  the current word to qualier. The rule-based tagger has  the proper noun discovery procedure is  automaticallyacautomatically learned how to properly tag this \idiom." quired by the rule-based tagger , making it much more 7  portable than a stochastic tagger. If the tagger were  Regardless of the precise rankings of the various taggers, trained on a dierent corpus, a dierent set of patches we have demonstrated that a simple rule-based tagger suitable for that corpus would be found automatically.  with very few rules performs on par with stochastic  taggers. It should be mentioned that our results were Large tables of statistics are not needed for the rule-tained without the use of a dictionary. Incorporating a based tagger. In a stochastic tagger, tens of thousands large dictionary into the system would improve of lines of statistical information are needed to capture mance in two ways. First, it would increase the accuracy contextual information. This information is usually a ta-in tagging words not seen in the training corpus, since ble of trigram statistics, indicating for all tags tag , tag a  part of speech information for some words not appearing and tag the probability that tag follows tag and tag .  in the training corpus can be obtained from the In the rule-based tagger, contextual information is cap-nary. Second, it would increase the error reduction tured in fewer than eighty rules. This makes for a much sulting from applying patches. When a patch indicates more perspicuous tagger, aiding in better understanding that a word should be tagged with tag instead of tag , and simplifying further development of the tagger. Contextual informationis expressed in a much more compact  the tag is only switched if the word was tagged with tag  and understandable form. As can be seen from  comparsomewhere in the training corpus. Using a dictionary  would provide more accurate knowledge about the set ing error rates, this compact representation of contextual of permissible part of speech tags for a particular word. information is just as eective as the information hidden We plan to incorporate a dictionary into the tagger in in the large tables of contextual probabilities.  the future.  Perhaps the biggest contribution of this work is in  As an estimate of the improvement possible by using demonstrating that the stochastic method is not the only a dictionary, we ran two experiments where all words viable approach for part of speech tagging. The fact that were known by the system. First, the Brown Corpus the simple rule-based tagger can perform so well should oer encouragement for researchers to further explore  rule-based tagging, searching for a better and more  exThis was one of the 71 patches acquired by the rule-based  And even this could be learned by the tagger.  pressive set of patch templates and other variations on  this simple but eective theme.  1. Church, K. A Stochastic Parts Program and Noun  Phrase Parser for Unrestricted Text. In Proceedings of  the Second Conference on Applied Natural Language  Processing, ACL, 136-143, 1988.  2. Cutting, D., Kupiec, J., Pederson, J. and Sibun, P. A  Practical Part-of-Speech Tagger. In Proceedings of the  Third Conference on Applied Natural Language  Process3. DeRose, S.J. Grammatical Category Disambiguation by  Statistical Optimization. Computational Linguistics 14:  4. Deroualt, A. and Merialdo, B. Natural language  modeling for phoneme-to-text transcription. IEEE  Transactions on Pattern Analysis and Machine Intelligence,Vol.  5. Francis, W. Nelson and Kucera, Henry, Frequency  analysis of English usage. Lexicon and grammar. Houghton  6. Garside, R., Leech, G. & Sampson, G. The  Computational Analysis of English: A Corpus-Based Approach.  7. Green, B. and Rubin, G. Automated Grammatical  Tagging of English. Department of Linguistics, Brown  Uni8. Hindle, D. Acquiring disambiguation rules from text.  Proceedings of the 27th Annual Meeting of the  Association for Computational Linguistics, 1989.  9. Jelinek, F. Markov source modeling of text generation.  In J. K. Skwirzinski, ed., Impact of Processing  Tech10. Klein, S. and Simmons, R.F. A Computational  Approach to Grammatical Coding of English Words. JACM  phrase-dependent word tagging. In Proceedings of the  DARPA Speech and Natural Language Workshop,  MorStudies in Part of Speech Labelling, Proceedings of the  DARPA Speech and Natural Language Workshop, 