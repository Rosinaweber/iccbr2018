 Effects of Adjective Orientation and Gradability on Sentence Subjectivity  Department of Computer Science  Department of Computer Science  Columbia University  New Mexico State University  New York, NY 10027  sages ('flames') and mining online sources for product  Subjectivity is a pragmatic, sentence-level feature that reviews. Other tasks for which subjectivity recognition has important implications for text processing applica-is potentially very useful include information extraction tions such as information extraction and information re-and information retrieval. Assigning subjectivity labels trieval. We study the effects of dynamic adjectives, se-to documents or portions of documents is an example of  mantically oriented adjectives, and gradable adjectives non-topical characterization of information. Current in-on a simple subjectivity classifier, and establish that formation extraction and retrieval technology focuses al-they are strong predictors of subjectivity. A novel train-most exclusively on the subject matter of the documents.  able method that statistically combines two indicators of Yet, additional components of a document influence its  gradability is presented and evaluated, complementing  relevance to particular users or tasks, including, for ex-existing automatic techniques for assigning orientation ample, the evidential status of the material presented, and labels.  attitudes adopted in favor or against a particular person, event, or position (e.g., articles on a presidential cam-1  Introduction  paign written to promote a specific candidate). In  summarization, subjectivity judgments could be included in In recent years, computational techniques for the deter-document profiles to augment automatically produced  mination of lexical semantic features have been proposed document summaries, and to help the user make rele-and evaluated. Such features include sense, register, do-vance judgments when using a search engine.  main specificity, pragmatic restrictions on usage, semantic markedness, and orientation, as well as automatically Other work on subjectivity (Wiebe et al., 1999; Bruce  and Wiebe, 2000) has established a positive and statisti-ness, synonymy, antonymy, and meronymy).  Automatcally significant correlation with the presence of adjec-ically learning features of this type from large corpora tives. Since the mere presence of one or more adjectives allows the construction or augmentation of lexicons, and is useful for predicting that a sentence is subjective, we the assignment of semantic labels to words and phrases  investigate in this paper the effects of additional lexical in running text. This information in turn can be used to semantic features of adjectives that can be automatically help determine additional features at the lexical, clause, learned from corpora. We consider two such features: se-sentence, or document level.  mantic orientation, which represents an evaluative char-This paper explores the benefits that some lexical  feaacterization of a word's deviation from the norm for its tures of adjectives offer for the prediction of a contextual semantic group (e.g., beautiful is positively oriented, as sentence-level feature, subjectivity. Subjectivity in nat-opposed to ugly); and gradability, which characterizes a ural language refers to aspects of language used to ex-word's ability to express a property in varying degrees.  press opinions and evaluations. The computational task  In the remainder of this paper, we first address  adjecaddressed here is to distinguish sentences used to present tive orientation in Section 2, summarizing a previously opinions and other forms of subjectivity ( subjective sen-published method for automatically separating oriented  tences, e.g., 'At several different layers, it's a fascinating adjectives into positive and negative classes. Then, Sec-tale') from sentences used to objectively present factual tion 3 presents a novel method for learning gradable ad-information ( objective sentences, e.g., 'Bell industries jectives using a large corpus and a statistical feature com-Inc. increased its quarterly to 10 cents from 7 cents a bination model. In Section 4, we review earlier exper-share').  iments on testing subjectivity using various features as Much research in discourse processing has focused  predictors, and then present comparative analyses of the on task-oriented and instructional dialogs. The task ad-effects that orientation and gradability have on our abil-dressed here comes to the fore in other genres, especially ity to predict sentence subjectivity from adjectives. We news reporting and Internet forums, in which opinions  show that both give us higher-quality features for recog-of various agents are expressed and where subjectivity  nizing subjective sentences, and conclude by discussing judgements could help in recognizing inflammatory mes-future extensions to this work.  Number of  Number of  Ratio of average  adjectives in  of links for  Accuracy  each adjective  Table 1: Evaluation of the adjective orientation classification and labeling methods (from (Hatzivassiloglou and McKeown, 1997)).  Semantic Orientation  Once the classes have been determined, frequency  information is used to assign positive or negative labels to The semantic orientation or polarity of a word indicates each class (there are slightly fewer positive terms, but the direction the word deviates from the norm for its se-with a significantly higher rate of occurrence than nega-mantic group or lexical field (Lehrer, 1974). It is an eval-tive terms).  uative characteristic (Battistella, 1990) of the meaning of Hatzivassiloglou and McKeown applied their method  the word which restricts its usage to appropriate  pragto 1,336 (657 positive and 679 negative) adjectives which matic contexts. Words that encode a desirable state (e.g., were all the oriented adjectives appearing in the corpus beautiful, unbiased) have a positive orientation, while 20 times or more. Orientation labels were assigned to  words that represent undesirable states have a negative these adjectives by hand.1 Subsequent validation of the orientation. Within the particular syntactic class of ad-initial selection and label assignment steps with indepen-jectives, orientation can be expressed as the ability of an dent human judges showed an agreement of 89% for the  adjective to ascribe in general a positive or negative qual-first step and 97% for the second step, establishing that ity to the modified item, making it better or worse than a orientation is a fairly objective semantic property. Be-similar unmodified item.  cause the accuracy of the method depends on the  denMost antonymous adjectives can be contrasted on  sity of conjunctions per adjective, Hatzivassiloglou and the basis of orientation (e.g., beautiful ugly); similarly, McKeown tested separately their algorithm for adjectives nearly synonymous terms are often distinguished by dif-appearing in at least 2, 3, 4, or 5 conjunctions in the cor-ferent orientations (e.g., simple simplistic). While ori-pus; their results are shown in Table 1.  entation applies to many adjectives, there are also those In this paper, we use the model labels assigned by  that have no orientation, typically as members of groups hand by Hatzivassiloglou and McKeown, and the labels  of complementary, qualitative terms (Lyons, 1977) (e.g., automatically obtained by their method and reported in  domestic, medical, or red). Since orientation is  inher(Hatzivassiloglou and McKeown, 1997) with the  followently connected with evaluative judgements, it appears  ing extension: An adjective that appears in  to be a promising feature for predicting subjectivity.  tions will receive (possibly different) labels when ana-Hatzivassiloglou and McKeown (1997) presented a  lyzed together with all adjectives appearing in at least 2, method for automatically assigning a  or  conjunctions; since performance generally  inlabel to adjectives known to have some semantic  oriencreases with the number of conjunctions per adjective,  tation. Their method is based on information extracted  we select as the orientation label the one assigned by  from conjunctions between adjectives in a large corpus  the experiment using the highest applicable conjunctions because orientation constrains the use of the words in  threshold. Overall, we have labels for 730 adjectives2, specific contexts (e.g., compare corrupt and brutal with with a prediction accuracy of 81.51%.  * corrupt but brutal), observed conjunctions of adjectives can be exploited to infer whether the conjoined words  are of the same or different orientation. Using a shallow Gradability (or grading) (Sapir, 1944; Lyons, 1977, p.  parser on a 21 million word corpus of Wall Street  Jour271) is the semantic property that enables a word to parnal articles, Hatzivassiloglou and McKeown developed  ticipate in comparative constructs and to accept  modand trained a log-linear statistical model that predicts ifying expressions that act as intensifiers or diminish-whether any two adjectives have the same orientation  ers. Gradable adjectives express properties in varying  with 82% accuracy. The predicted links of same or  difdegrees of strength, relative to a norm either explicitly ferent orientation are automatically assigned a strength 1  value (essentially, a confidence estimate) by the model, Some adjectives with unclear, ambiguous, or context-dependent orientation were excluded.  and induce a graph that can be partitioned with a  clus2Those appearing in the corpus in two conjunctions or more, since tering algorithm into components so that all words in the some conjunction data must be left out to train the link prediction algo-same component belong to the same orientation class.  cold  Unmodified by  Unmodified by  Uninflected  Inflected for degree  Table 2: Extracted values of gradability indicators, i.e., frequencies of the word with or without the specified inflection or modification, for two adjectives, one gradable ( cold) and one primarily non-gradable ( civil). The frequencies were computed from the 1987 Wall Street Journal corpus.  mentioned or implicitly supplied by the modified noun  recognizes several irregular forms (e.g., good better  (for example, a small planet is usually much larger than a best) and strips the grading suffixes -er and -est from large house; cf. the distinction between absolute and rel-regularly inflected adjectives, producing a list of candi-ative adjectives made by Katz (1972, p. 254)). This rel-date base forms that if inflected would yield the origi-ativism in the interpetation of gradable words indicates nal adjective (e.g., bigger produces three potential forms, that gradability is likely to be a good predictor of subjec-big, bigg, and bigge). The frequency of these candi-tivity.  date base words is checked against the corpus, and the  form with significantly higher frequency is selected. To 3.1  Indicators of gradability  guard against cases of base adjective forms that end in -er Most gradable words appear at least several times in a  or -est (e.g., silver), the original word is also included large corpus either in forms inflected for degree (i.e., among the candidates. The total number of times this  comparative and superlative), or in the context of grading procedure is successfully applied for each adjective be-modifiers such as very. However, non-gradable words comes a second indicator of gradability.  may also occasionally appear in such contexts or forms  For example, very  dead can be used for emphasis, and redder and redder The presence or absence of each of the above two  indica(as in 'her face became redder and redder') can be used tors results in a  frequency table for each adjective;  to indicate a progression of coloring. To distinguish be-examples for one gradable and one non-gradable  adjectween truly gradable adjectives and non-gradable  adjective are given in Table 2. To convert these four numbers tives in these exceptional contexts, we have developed  to a single decision on the gradability of the adjective, we a trainable log-linear statistical model that takes into ac-use a log-linear model. Log-linear models (Santner and  count the number of times an adjective has been observed Duffy, 1989) construct a linear combination (weighted  in a form or context indicating gradability relative to the sum) of the predictor variables  number of times it has been seen in non-gradable  conWe use a shallow parser to retrieve from a large corpus i=1  tagged for part-of-speech with Church's PARTS tagger  (Church, 1988) all adjectives and their modifiers.  Aland relate it to the actual response  (in this case, 0 for  though the most common use of an adverb modifying  non-gradable and 1 for gradable) via the so-called logis-an adjective is to function as an intensifier or diminisher tic transformation,  (Quirk et al., 1985, p. 445), adverbs can also add to the e  semantic content of the adjectival phrase instead of pro-R  viding a grading effect (e.g., immediately available, po-1  litically vulnerable), or function as emphasizers, adding Maximum likelihood estimates for the coefficients i  to the force of the base adjective and not to its degree are obtained from training samples for which the correct (e.g., virtually impossible; compare * very impossible).  is known, using the iterative reweighted  nonTherefore, we compiled by hand a list of 73 adverbs and linear least squares algorithm (Bates and Watts, 1988).  noun phrases (such as a little, exceedingly, somewhat, This statistical model is particularly suited for model-and very) that are frequently used as grading modifiers.  ing variables with a 'yes' 'no' (binary) value, because, The number of times each adjective appears modified by  unlike linear models, it captures the dependency of  's  a term form this list becomes a first indicator of gradabil-variance on its mean (Santner and Duffy, 1989).  ity.  We normalize the counts for the two indicators of  To detect inflected forms of adjectives (which, in  Engradability, and the count of joint occurrences of both in-glish, always indicate gradability subject to the excep-flection and modification by grading modifiers, by divid-tions discussed earlier), we have implemented an  autoing with the total frequency of the adjective in the corpus.  matic morphology analysis component. This program  In this manner, we obtain three real-valued predictors  Classified as gradable:  label of that sense. In some cases, the word did not  appear in COBUILD; these typically were descriptive  compounds specific to the domain (e.g., anti-takeover, cautious cheap creative critical dangerous  over-the-counter) and were in most cases marked as non-different disappointing equal fair familiar far gradable adjectives. Overall, 453 of the 496 adjectives favorable formal free frequent good grand  (91.33%) were assigned gradability labels by hand, while inadequate intense interesting legitimate likely  the remaining 53 words were discarded because they  positive professional reasonable rich  were misclassified as adjectives by the part-of-speech  short-term significant slow solid sophisticated  tagger (e.g., such) or because they could not be assigned sound speculative thin tight tough uncertain  a unique gradability label in accordance with COBUILD.  widespread worth  Out of these words, 235 (51.88%) were manually  classified as gradable adjectives, and 218 (48.12%) were clasClassified as non-gradable:  sified as non-gradable adjectives.  additional alleged alternative annual antitrust  Following the methodology of the preceding  subsection, we recovered the inflection and modification indica-deputy domestic elderly false financial  tors for these 453 adjectives, and trained both the unmod-first-quarter full hefty illegal institutional ified and modified log-linear models repeatedly, using a internal legislative long-distance military  randomly selected subset of 300 adjectives for training minimum monthly moral national official  and 100 adjectives for testing. The entire cycle of  selecting random test and training sets, fitting the model's one-time other outstanding present prior  coefficients, making predictions, and evaluating the pre-prospective punitive regional scientific  dicted gradability labels is repeated 100 times, to ensure secondary sexual subsidiary taxable  that the evaluation is not affected by a lucky (or unlucky) three-month three-year total tremendous  partition of the data between training and test sets. This two-year unfair unsolicited upper voluntary  procedure yields over the 453 adjectives gradability clas-white wholesale world-wide wrong  sifications with an average precision of 93.55% and  average recall of 82.24% (in terms of the gradable words  Figure 1: Automatically obtained classification of a  reported or recovered, respectively). The overall  accusample of 100 adjectives as gradable or not. Correct  racy of the predicted gradability labels is 87.97%. These decisions (according to the COBUILD-based reference  results were obtained with the modified log-linear model, model) are indicated in bold.  which slightly outperformed the model that uses all three predictors (in that case, we obtained an average precision of 93.86%, average recall of 81.70%, and average overall accuracy of 87.70%). Figure 1 lists the gradability for the log-linear model. We also conV  labels that were automatically assigned to one of the 100  sider a modified model, where any adjective for which  random test sets using the modified prediction algorithm.  any occurrence of simultaneous inflection and  modificaWe also assigned automatically labels to the entire set of tion has been detected is automatically labeled gradable; 453 adjectives, using 4-fold cross-validation (repeatedly the remaining two predictors are used to classify the ad-training on three-fourths of the 453 adjectives and test-jectives that do not fulfill this condition. This modifica-ing on the rest). This resulted in precision of 94.15%, tion is motivated by the fact that observing an adjective recall of 82.13%, and accuracy of 88.08% for the entire in such a context offers a very high likelihood of grad-adjective set.  Subjectivity  We extracted from the 1987 Wall Street Journal corpus  The main motivation for the present paper is to examine (21 million words) all adjectives with a frequency of 300  the effect that information about an adjective's semantic or more; this produced a collection of 496 words. Grad-orientation and gradability has on its probability of oc-ability labels specifying whether each word is gradable curring in a subjective sentence (and hence on its quality or not were manually assigned, using the designations  as a subjectivity predictor). We first review related work of the Collins COBUILD (Collins Birmingham Univer-on subjectivity recognition and then present our results.  sity International Language Database) dictionary  (SinPrevious work on subjectivity recognition  clair, 1987). COBUILD marks each sense of each  adjective with one of the labels  In work by Wiebe, Bruce, and O'Hara (Wiebe et al.,  QUALIT, CLASSIF, or COLOR,  corresponding to gradable, non-gradable, and color  ad1999; Bruce and Wiebe, 2000), a corpus of 1,001  senjectives. In cases where COBUILD supplies conflicting  tences3 of the Wall Street Journal TreeBank Corpus  labels for different senses of a word, we either omitted 3Compound sentences were manually segmented into their con-that word or, if a sense were predominant, gave it the  juncts, and each conjunct treated as a separate sentence.  (Marcus et al., 1993) was manually annotated with  subtivity.  jectivity classifications. Specifically, each sentence was For the present study, we use the set of all adjectives assigned a subjective or objective classification, accord-automatically identified in the corpus by Wiebe et al.  ing to concensus tags derived by a statistical analysis of (1999) (Section 4.1); the set of dynamic adjectives manu-the classes assigned by three human judges (see (Wiebe  ally identified by Bruce and Wiebe (2000) (Section 4.1); et al., 1999) for further information). The total number the set of semantic orientation labels assigned by Hatzi-of subjective sentences in the data is 486, and the total vassiloglou and McKeown (1997), both manually and  number of objective sentences is 515.  automatically with our extension described in Section 2; Bruce and Wiebe (2000) performed a statistical anal-and the set of gradability labels, both manually and au-ysis of the assigned classifications, finding that adjec-tomatically assigned according to the revised log-linear tives are statistically significantly and positively corre-model of Section 3. We calculate results (shown in  Talated with subjective sentences in the corpus on the basis ble 3) for each of these sets of all adjectives, dynamic, of the log-likelihood ratio test statistic  2 . The  probaoriented and gradable adjectives, as well as for unions G  bility of a sentence being subjective, simply given that and intersections of those sets. Note that these four sets there is at least one adjective in the sentence, is 56%, have been extracted from comparable but different cor-even though there are more objective than subjective sen-pora (different years of the Wall Street Journal), therefore tences in the corpus. In addition, Bruce and Wiebe iden-sometimes adjectives in one corpus may not be present  tified a type of adjective that is indicative of subjective in the other corpus, reducing the size of intersection sets.  sentences: those Quirk et al. (1985) term dynamic, which Also, for gradability, we worked with a sample set of 100  'denote qualities that are thought to be subject to con-adjectives rather than all possible adjectives we could trol by the possessor' (p. 434). Examples are 'kind' and automatically calculate gradability values for, since our  'careful'. Bruce and Wiebe manually applied syntactic  goal in the present work is to measure correlations  betests to identify dynamic adjectives in half of the corpus tween these sets and subjectivity, rather than building a mentioned above. We include such adjectives in the anal-system for predicting subjectivity for as many adjectives ysis below, to assess whether additional lexical semantic as possible.  features associated with subjectivity help improve  preIn Table 3, the second column identifies  , the set  dictability.  of adjective types in question. The third column gives  Wiebe et al. (1999) developed an automatic system to  the number of subjective sentences that contain one or  perform subjectivity tagging. In 10-fold cross  validamore instances of members of  , and the fourth column  tion experiments applied to the corpus described above, gives the same figure for objective sentences. Therefore a probabilistic classifier obtained an average accuracy on these two columns together specify the coverage of the  subjectivity tagging of 72.17%, more than 20 percentage subjectivity indicator examined. The fifth column gives points higher than the baseline accuracy obtained by al-the conditional probability that a sentence is subjective, ways choosing the more frequent class. A binary feature given that one or more instances of members of  is included for each of the following: the presence in the pears. This is a precision metric that assesses feature sentence of a pronoun, an adjective, a cardinal number, quality: if instances of  appear, how likely is the  sena modal other than will, and an adverb other than not.  tence to be subjective? The last two columns contrast the They also included a binary feature representing whether observed conditional probability with the a priori prob-or not the sentence begins a new paragraph. Finally, a  ability of subjective sentences (i.e., chance; sixth col-feature was included representing co-occurrence of word umn) and with the probability assigned by the baseline  tokens and punctuation marks with the subjective and ob-all-adjectives model (i.e., the first row in the table; sev-jective classification. An analysis of the system showed enth column).  that the adjective feature was important to realizing the The most striking aspect of these results is that all sets improvements over the baseline accuracy. In this paper, involving dynamic adjectives, positive or negative po-we use the performance of the simple adjective feature as larity, or gradability are better predictors of subjective a baseline, and identify higher quality adjective features sentences than the class of adjectives as a whole. Five based on gradability and orientation.  of the sets are at least 25 points better (L14, L16, L21, L23, and L24); four others are at least 20 points better 4.2  Orientation and gradability as subjectivity  (L2, L9, L13, and L15); and five others are at least 15  points better (L4, L11, L18, L20, and L22). In most of  these cases, the difference between these predictors and We measure the precision of a simple prediction method  all adjectives is statistically significant4 at the 5% level or for subjectivity: a sentence is classified as subjective if at less; almost all of these predictors offer statistically sig-least one member of a set of adjectives  occurs in the  nificantly better than even odds in predicting subjectivity sentence, and objective otherwise. By varying the set S  correctly. In many cases where statistical significance (e.g., all adjectives, only gradable adjectives, only negatively oriented adjectives, etc.) we can assess the useful-4We applied a chi-square test on the  cross-classification table  ness of the additional knowledge for predicting  subjecAdjective Set  with  with  Against majority Against all adjs  (s  (s  (s  All Adjectives  Dynamic Adjectives  of L5.  of L6.  of L10.  of L11  of L22.  of L19.  : one or more instances of members of  . Pol : positive polarity. Pol : negative polarity.  (s  Grad: gradable. Dyn: dynamic. Man: manually identified. Auto: automatically identified.  Table 3: Subjectivity prediction results.  could not established this is due to small counts, caused it remains the same or improves. The results are even  by the small size of the set of adjectives automatically better for the automatically assigned polarity and grad-labeled for gradability.  ability sets: predictability improves when both features It is also important to note that, in most cases,  are considered in all but one case, when predictability the automatically-classified adjectives are comparable  remains the same (L20  or better predictors of subjective sentences than the  and L11  manually-assigned ones. Comparing the automatically  generated classes with the manually identified ones, the 5  Conclusion and Future Work  positive polarity set decreases by 1 percentage point (L3  This paper presents an analysis of different adjective fea-and L8), while the negative polarity set increases by 7  tures for predicting subjectivity, showing that they are points (L4 and L9), and the gradable set increases by 5  more precise than those previously used for this task. We percentage points (L6 and L11). Among the intersection  establish that lexical semantic features such as  semansets, in two cases the results are lower for the computer-tic orientation and gradability determine in large part the generated sets (L13/L15 and L14/L16), but in the other 4  subjectivity status of sentences in which they appear. We cases, the results are higher (L17/L20, L18/L21, L19/L2, also present an automatic method for extracting gradabil-L24/L23).  ity values reliably, complementing earlier work on  seFinally, the table shows that, in most cases,  premantic orientation and dynamic adjectives.  dictability improves or at worst remains essentially the In addition to finding more precise features for auto-same as additional lexical features are considered. For matic subjectivity recognition, this kind of analysis could the set of dynamic adjectives, the predictability is 74%  help efforts to encode subjective features in ontologies (L2), and improves in 4 of the 6 cases in which it is in-such as those described in (Knight and Luk, 1994;  Matersected with other sets (L14, L16, L23, and L24). For hesh and Nirenburg, 1995; Hovy, 1998).  These  onthe other two (L13 and L15), predictability is only 1 or 2  tologies are useful for many NLP tasks, such as  mapoints lower (not statistically significant). For the man-chine translation, word-sense disambiguation, and  genually assigned polarity and gradability sets, in one case eration. Some subjective features are included in exist-predictability is lower (L17  L6), but in the other cases  ing ontologies (for example, Mikrokosmos (Mahesh and  Nirenburg, 1995) includes attitude slots). Our corpus-Vasileios Hatzivassiloglou and Kathleen R. McKeown.  based methods could help in identifying more or  extend1997. Predicting the semantic orientation of  adjecing their coverage.  tives. In Proceedings of the 35th Annual Meeting  To be able to use automatic subjectivity recognition  of the ACL and the 8th Conference of the European  in text-processing applications, good clues of subjectiv-Chapter of the ACL, pages 174 181, Madrid, Spain, ity must be found. The features developed in this paper July. Association for Computational Linguistics.  are not only good clues of subjectivity, they can be iden-Eduard Hovy.  Combining and standardizing  tified automatically from corpora (see (Hatzivassiloglou large-scale practical ontologies for machine transla-and McKeown, 1997), and Section 3 in the present  pation and other uses. In Proceedings of the 1st Interna-per). In fact, the results in Table 3 show that the pre-tional Conference on Language Resources and  Evaludictability of the automatically determined gradability ation (LREC), Granada, Spain.  and polarity sets is better than or at least comparable to Jerrold J. Katz. 1972. Semantic Theory. Harper and the predictability of the manually determined sets. Thus, Row, New York.  the oriented and gradable adjectives in the particular ap-Kevin Knight and Steve K. Luk. 1994. Building a  largeplication genre can be identified for use in subjectivity scale knowledge base for machine translation. In Pro-recognition.  ceedings of the 12th National Conference on  ArtifiOur efforts in this paper are largely exploratory,  aimcial Intelligence (AAAI-94), volume 1, pages 773 778, ing to establish correlations among the various features Seattle, Washington, July August. American Associ-examined. In related work, we have begun to incorporate ation for Artificial Intelligence.  the features developed here into systems for recognizing Adrienne Lehrer. 1974. Semantic Fields and Lexical  flames and mining reviews in Internet forums,  extendStructure. North Holland, Amsterdam and New York.  ing subjectivity judgments from the sentence to the doc-John Lyons. 1977. Semantics, volume 1. Cambridge ument level. In addition, we are seeking ways to extend University Press, Cambridge, England.  the orientation and gradability methods so that individual K. Mahesh and S. Nirenburg. 1995. A situated ontol-word occurrences, rather than word types, are character-ogy for practical NLP. In Proceedings of the  Workized as oriented or gradable. We also plan to  incorposhop on Basic Ontological Issues in Knowledge  Sharrate the new features presented here in machine learning ing, 14th International Joint Conference on Artificial models for the prediction of subjectivity (e.g., (Wiebe et Intelligence (IJCAI-95), Montr al, Canada, August.  al., 1999)) and test their interactions with other proposed Mitchell P. Marcus, Beatrice Santorini, and Mary Ann  features.  Marcinkiewicz. 1993. Building a large annotated  corpus of English: the Penn Treebank. Computational  Acknowledgments  Linguistics, 19(2):313 330, June.  This research was supported in part by the National Sci-Randolph Quirk, Sidney Greenbaum, Geoffrey Leech,  ence Foundation under grant number IIS-9817434, and  by the Office of Naval Research under grant number  of the English Language. Longman, London and New N00014-95-1-0776. Any opinions, findings, or recom-York.  mendations are those of the authors, and do not  necesThomas J. Santner and Diane E. Duffy. 1989. The Statis-sarily reflect the views of the above agencies.  tical Analysis of Discrete Data. Springer-Verlag, New York.  Edward Sapir. 1944. On grading: A study in semantics.  Douglas M. Bates and Donald G. Watts. 1988.  NonlinPhilosophy of Science, 2:93 116. Reprinted in (Sapir, ear Regression Analysis and its Applications. Wiley, 1949).  New York.  Edward Sapir. 1949. Selected Writings in Language,  Edwin L. Battistella. 1990. Markedness: The Evaluative Culture and Personality.  University of California  Superstructure of Language. State University of New Press, Berkeley, California. Edited by David G. Man-York Press, Albany, New York.  Rebecca Bruce and Janyce Wiebe. 2000. Recognizing  John M. Sinclair (editor in chief).  Collins  subjectivity: A case study of manual tagging. Natural COBUILD English Language Dictionary. Collins,  Kenneth W. Church. 1988. A stochastic parts program  J. Wiebe, R. Bruce, and T. O'Hara. 1999.  Developand noun phrase parser for unrestricted text. In Pro-ment and use of a gold standard data set for  subjecceedings of the Second Conference on Applied  Natutivity classifications. In Proceedings of the 37th An-ral Language Processing (ANLP-88), pages 136 143, nual Meeting of the Association for Computational  Austin, Texas, February. Association for  ComputaLinguistics (ACL-99), pages 246 253, University of tional Linguistics.  Maryland, June.  Joseph L. Fleiss. 1981. Statistical Methods for Rates and Proportions. Wiley, New York, 2nd edition. 