 Hierarchical Sequential Learning for Extracting Opinions and their Attributes  Yejin Choi and Claire Cardie  Department of Computer Science  Cornell University  systems with cascaded component architectures,  causing performance degradation in the  end-toAutomatic opinion recognition involves a  number of related tasks, such as  identicase, in the end-to-end opinion recognition  sysfying the boundaries of opinion  expression, determining their polarity, and  deIn this paper, we apply a hierarchical  paramtermining their intensity. Although much  eter sharing technique (e.g., Cai and Hofmann  progress has been made in this area,  ex(2004), Zhao et al. (2008)) using Conditional  Ranisting research typically treats each of the  dom Fields (CRFs) (Lafferty et al., 2001) to  fineabove tasks in isolation.  In this paper,  grained opinion analysis. In particular, we aim to  we apply a hierarchical parameter  sharjointly identify the boundaries of opinion  expresing technique using Conditional Random  sions as well as to determine two of their key  atFields for fine-grained opinion analysis,  tributes polarity and intensity.  jointly detecting the boundaries of opinion  Experimental results show that our proposed  apexpressions as well as determining two of  proach improves the performance over the  basetheir key attributes polarity and  intenline that does not exploit the hierarchical structure sity. Our experimental results show that  among the classes. In addition, we find that the  our proposed approach improves the  perjoint approach outperforms a baseline that is based  formance over a baseline that does not  on cascading two separate systems.  exploit hierarchical structure among the  classes. In addition, we find that the joint  approach outperforms a baseline that is  Hierarchical Sequential Learning  based on cascading two separate  compoWe define the problem of joint extraction of  opinion expressions and their attributes as a sequence  Introduction  tagging task as follows. Given a sequence of  tokens, x = x1 ... xn, we predict a sequence of  Automatic opinion recognition involves a number  of related tasks, such as identifying expressions of defined as conjunctive values of polarity labels  opinion (e.g. Kim and Hovy (2005), Popescu and  and intensity labels, as shown in Table 1. Then  the conditional probability p(y|x) for linear-chain  their polarity (e.g. Hu and Liu (2004), Kim and  CRFs is given as (Lafferty et al., 2001)  ing their strength, or intensity (e.g. Popescu and  vious work treats each subtask in isolation:  opinion expression extraction (i.e. detecting the  boundaries of opinion expressions) and opinion attribute  where Zx is the normalization factor.  classification (e.g. determining values for  polarIn order to apply a hierarchical parameter  sharity and intensity) are tackled as separate steps in  ing technique (e.g., Cai and Hofmann (2004),  opinion recognition systems. Unfortunately,  erZhao et al. (2008)), we extend parameters as  folrors from individual components will propagate in  Proceedings of the ACL 2010 Conference Short Papers, pages 269 274, Uppsala, Sweden, 11-16 July 2010. c  2010 Association for Computational Linguistics  Figure 1: The hierarchical structure of classes for opinion expressions with polarity (positive, neutral, negative) and intensity (high, medium, low)  high  high  high  Table 1: Labels for Opinion Extraction with Polarity and Intensity yi  {1, 2, 3} will share the same  compoNote that there  can be other variations of hierarchical  construction.  For instance, one can add g ( , x, i)  and  , x, i) to Equation (1) for  {0, 1, ..., 9}, in order to allow more individualized i 1, yi, x, i)  learning for each label.  Notice also that the number of sets of  parameters constructed by Equation (1) is significantly  smaller than the number of sets of parameters that  where g and g are feature vectors defined for  are needed without the hierarchy. The former  reOpinion extraction, g and g are feature vectors  defined for Polarity extraction, and g and g are  sets of parameters, but the latter requires (10) +  feature vectors defined for Strength extraction, and (10 10) = 110 sets of parameters. Because a  combination of a polarity component and an  intensity component can distinguish each label, it is  {POSITIVE, NEGATIVE, NEUTRAL, NO-POLARITY} not necessary to define a separate set of parameters ,  for each label.  For instance, if yi = 1, then  Features  We first introduce definitions of key terms that will POSITIVE gP (POSIT VE, x, i)  be used to describe features.  If yi 1 = 0, yi = 4, then  We obtain these prior-attributes from the  polarity lexicon populated by Wilson et al. (2005).  Words in a given opinion expression often do  not share the same prior-attributes. Such  disNO-INTENSITY, HIGH g S (NO-INT E NSIT Y, HIGH, x, i) continuous distribution of features can make  it harder to learn the desired opinion  expresThis hierarchical construction of feature and  sion boundaries. Therefore, we try to obtain  weight vectors allows similar labels to share the  expression-level attributes (EXP-POLARITY and  same subcomponents of feature and weight  vecEXP-INTENSITY) using simple heuristics. In  ortors.  For instance, all f (yi, x, i) such that  der to derive EXP-POLARITY, we perform simple  voting. If there is a word with a negation effect,  Intensity Per-Token Features  such as never , not , hardly , against , then  These features are included only for g ( , x, i)  we flip the polarity. For EXP-INTENSITY, we use  and g ( , x, i), which are the feature functions cor-S  the highest PRIOR-INTENSITY in the span. The text  responding to the intensity-based classes.  span with the same expression-level attributes  are referred to as EXP-SPAN.  COUNT-OF-STRONG, COUNT-OF-WEAK:  the number of strong and weak EXP-INTENSITY  Per-token features are defined in the form of  words in the current sentence.  The  do INTENSIFIER(xi): whether xi is an intensifier,  mains of , , are as given in Section 3.  such as extremely , highly , really .  Common Per-Token Features  STRONGMODAL(xi): whether xi is a strong modal  verb, such as must , can , will .  Following features are common for all class labels.  The notation indicates conjunctive operation of  i): whether xi is a weak modal  verb, such as may , could , would .  DIMINISHER(xi): whether xi is a diminisher, such  as little , somewhat , less .  based on GATE (Cunningham et al., 2002).  where { INTENSIFIER, STRONGMODAL,  WEAKbased on WordNet (Miller, 1995).  based on opinion lexicon (Wiebe et al., 2002).  based on CASS partial parser (Abney, 1996).  Transition Features  Transition features are employed to help with  boundary extraction as follows:  boolean to indicate whether xi is in an EXP-SPAN.  Polarity Transition Features  Polarity transition features are features that are  used only for g ( ,  Polarity Per-Token Features  These features are included only for g ( , x, i)  and g ( , x, i), which are the feature functions  Intensity Transition Features  corresponding to the polarity-based classes.  Intensity transition features are features that are  used only for g ( ,  COUNT-OF-P olarity:  where P olarity {positive, neutral, negative}.  This feature encodes the number of positive,  neutral, and negative EXP-POLARITY words  respectively, in the current sentence.  the  Multi STEM(xi) COUNT-OF-P olarity  Perspective Question Answering (MPQA)  cor EXP-POLARITY(xi) COUNT-OF-P olarity  pus1. Our gold standard opinion expressions  cor1The  obtained  Negative  Method Description  Polarity-Only Intensity-Only (BASELINE1)  Joint without Hierarchy (BASELINE2)  Joint with Hierarchy  Table 2: Performance of Opinion Extraction with Correct Polarity Attribute High  Method Description  Polarity-Only Intensity-Only (BASELINE1)  Joint without Hierarchy (BASELINE2)  Joint with Hierarchy  Table 3: Performance of Opinion Extraction with Correct Intensity Attribute Method Description  baseline effectively represents a cascaded  compoPolar-Only Intensity-Only  nent approach.  Joint without Hierarchy  [Baseline-2] Joint without Hierarchy:  Joint with Hierarchy  we use simple linear-chain CRFs without  exploitTable 4: Performance of Opinion Extraction  ing the class hierarchy for the opinion recognition  task. We use the tags shown in Table 1.  Joint with Hierarchy:  Finally, we test the  hirespond to direct subjective expression and  expreserarchical sequential learning approach elaborated  in Section 3.  Our implementation of hierarchical sequential  learning is based on the Mallet (McCallum, 2002)  code for CRFs. In all experiments, we use a  Gaussian prior of 1.0 for regularization. We use 135  We evaluate all experiments at the opinion entity  documents for development, and test on a  diflevel, i.e. at the level of each opinion expression  ferent set of 400 documents using 10-fold  crossrather than at the token level. We use three  evaluavalidation. We investigate three options for jointly tion metrics: recall, precision, and F-measure with  extracting opinion expressions with their attributes equally weighted recall and precision.  as follows:  Table 4 shows the performance of opinion  extraction without matching any attribute. That is, an  [Baseline-1] Polarity-Only Intensity-Only:  extracted opinion entity is counted as correct if it For this baseline, we train two separate sequence  overlaps4 with a gold standard opinion expression,  tagging CRFs: one that extracts opinion  expreswithout checking the correctness of its attributes.  sions only with the polarity attribute (using  comTable 2 and 3 show the performance of opinion  mon features and polarity extraction features in  extraction with the correct polarity and intensity  Section 3), and another that extracts opinion  exrespectively.  pressions only with the intensity attribute (using  From all of these evaluation criteria, JOINT WITH  common features and intensity extraction features  in Section 3). We then combine the results from  Overlap matching is a reasonable choice as the annotator agreement study is also based on overlap matching (Wiebe two separate CRFs by collecting all opinion en-et al., 2005). One might wonder whether the overlap match-tities extracted by both sequence taggers.3 This  ing scheme could allow a degenerative case where extracting the entire test dataset as one giant opinion expression would 2Only 1.5% of the polarity annotations correspond to yield 100% recall and precision. Because each sentence cor-both; hence, we merge both into the neutral. Similarly, for responds to a different test instance in our model, and because gold standard intensity, we merge extremely high into high.  some sentences do not contain any opinion expression in the 3We collect all entities whose portions of text spans are dataset, such degenerative case is not possible in our experi-extracted by both models.  HIERARCHY performs the best, and the least  effecdirectly comparable to our results; much of  previtive one is BASELINE-1, which cascades two  sepaous work studies only a subset of what we tackle  rately trained models. It is interesting that the sim-in this paper. However, as shown in Section 4.1,  ple sequential tagging approach even without  exwhen we train the learning models only for a  subploiting the hierarchy (BASELINE-2) performs better  set of the tasks, we can achieve a better  perforthan the cascaded approach (BASELINE-1).  mance instantly by making the problem simpler.  When evaluating with respect to the polarity  atOur work differs from most of previous work in  tribute, the performance of the negative class is  that we investigate how solving multiple related  substantially higher than the that of other classes.  tasks affects performance on sub-tasks.  This is not surprising as there is approximately  The hierarchical parameter sharing technique  twice as much data for the negative class. When  used in this paper has been previously used by  evaluating with respect to the intensity attribute,  Zhao et al. (2008) for opinion analysis. However,  the performance of the LOW class is substantially  Zhao et al. (2008) employs this technique only to  lower than that of other classes. This result reflects classify sentence-level attributes (polarity and in-the fact that it is inherently harder to distinguish tensity), without involving a much harder task of  an opinion expression with low intensity from no  detecting boundaries of sub-sentential entities.  opinion. In general, we observe that determining  correct intensity attributes is a much harder task  Conclusion  than determining correct polarity attributes.  We applied a hierarchical parameter sharing  techIn order to have a sense of upper bound, we  nique using Conditional Random Fields for  finealso report the individual performance of two  sepgrained opinion analysis. Our proposed approach  arately trained models used for BASELINE-1: for the  jointly extract opinion expressions from  unstrucPolarity-Only model that extracts opinion  boundtured text and determine their attributes  polararies only with polarity attribute, the F-scores with ity and intensity. Empirical results indicate that  respect to the positive, neutral, negative classes are the simple joint sequential tagging approach even  46.7, 47.5, 57.0, respectively. For the  Intensitywithout exploiting the hierarchy brings a better  Only model, the F-scores with respect to the high,  performance than combining two separately  demedium, low classes are 37.1, 40.8, 26.6,  respecveloped systems. In addition, we found that the  tively. Remind that neither of these models alone  hierarchical joint sequential learning approach  imfully solve the joint task of extracting boundaries  proves the performance over the simple joint  seas well as determining two attributions  simultaneously. As a result, when conjoining the results  from the two models (BASELINE-1), the final  perAcknowledgments  formance drops substantially.  We conclude from our experiments that the  simThis work was supported in part by National  ple joint sequential tagging approach even  withScience Foundation Grants BCS-0904822,  BCSout exploiting the hierarchy brings a better  perfor0624277, IIS-0535099 and by the Department of  mance than combining two separately developed  Homeland Security under ONR Grant  N0014-07In addition, our hierarchical joint  se1-0152. We thank the reviewers and Ainur  Yessequential learning approach brings a further  perfornalina for many helpful comments.  mance gain over the simple joint sequential  tagRelated Work  S. Abney. 1996. Partial parsing via finite-state cascades. In Journal of Natural Language Engineering,  Although there have been much research for  finegrained opinion analysis (e.g., Hu and Liu (2004),  E. Breck, Y. Choi and C. Cardie. 2007. Identifying  Expressions of Opinion in Context. In IJCAI.  and Claire (2008), Wilson et al. (2009)),5 none is  on the entire corpus as unstructured input. Instead, Wilson et al. (2005) evaluate only on known words that are in their 5For instance, the results of Wilson et al. (2005) is not opinion lexicon. Furthermore, Wilson et al. (2005) simplifies comparable even for our Polarity-Only model used inside the problem by combining neutral opinions and no opinions BASELINE-1, because Wilson et al. (2005) does not operate into the same class, while our system distinguishes the two.  L. Cai and T. Hofmann. 2004. Hierarchical document categorization with support vector machines.  In CIKM.  Y. Choi and C. Cardie. 2008. Learning with  Compositional Semantics as Structural Inference for  Subsentential Sentiment Analysis. In EMNLP.  H. Cunningham, D. Maynard, K. Bontcheva and V.  Tablan. 2002. GATE: A Framework and Graphical  Development Environment for Robust NLP Tools  and Applications. In ACL.  J. R. Finkel, C. D. Manning and A. Y. Ng.  Solving the Problem of Cascading Errors:  Approximate Bayesian Inference for Linguistic Annotation  M. Hu and B. Liu. 2004. Mining and Summarizing  Customer Reviews. In KDD.  S. Kim and E. Hovy. 2004. Determining the sentiment  of opinions. In COLING.  S. Kim and E. Hovy. 2005. Automatic Detection of  Opinion Bearing Words and Sentences. In  Companion Volume to the Proceedings of the Second  International Joint Conference on Natural Language  Processing (IJCNLP-05).  J. Lafferty, A. McCallum and F. Pereira. 2001. Conditional Random Fields: Probabilistic Models for  Segmenting and Labeling Sequence Data. In ICML.  A. McCallum. 2002. MALLET: A Machine Learning  for Language Toolkit. http://mallet.cs.umass.edu.  G. A. Miller. 1995. WordNet: a lexical database for  English. In Communications of the ACM, 38(11).  Product Features and Opinions from Reviews. In  J. Wiebe, E. Breck, C. Buckley, C. Cardie, P. Davis, B. Fraser, D. Litman, D. Pierce, E. Riloff and T.  Wilson.  Summer Workshop on  MultiplePerspective Question Answering: Final Report. In  J. Wiebe and T. Wilson and C. Cardie 2005.  Annotating Expressions of Opinions and Emotions in  Language. In Language Resources and Evaluation,  volT. Wilson, J. Wiebe and P. Hoffmann. 2005.  Recognizing Contextual Polarity in Phrase-Level Sentiment  Analysis. In HLT-EMNLP.  T. Wilson, J. Wiebe and R. Hwa. 2006. Recognizing  strong and weak opinion clauses. In Computational  ing Contextual Polarity: an exploration of features  for phrase-level sentiment analysis. Computational  Linguistics 35(3).  dant Features for CRFs-based Sentence Sentiment  Classification. In EMNLP. 