 Dependency-based Syntactic Semantic Analysis with PropBank and NomBank  Richard Johansson and Pierre Nugues  Lund University, Sweden  {richard, pierre}@cs.lth.se  such as paths when predicting semantic structures, exact search is clearly intractable. This is true even This paper presents our contribution in the  with simpler feature representations the problem closed track of the 2008 CoNLL Shared  is a special case of multi-headed dependency anal-Task (Surdeanu et al., 2008). To tackle the  ysis, which is NP-hard even if the number of heads problem of joint syntactic semantic anal-is bounded (Chickering et al., 1994).  ysis, the system relies on a syntactic and  This means that we must resort to a simplifica-a semantic subcomponent. The syntactic  tion such as an incremental method or a reranking model is a bottom-up projective parser us-approach. We chose the latter option and thus cre-ing pseudo-projective transformations, and  ated syntactic and semantic submodels. The joint the semantic model uses global inference  syntactic semantic prediction is selected from a mechanisms on top of a pipeline of clas-small list of candidates generated by the respective sifiers. The complete syntactic semantic  output is selected from a candidate pool  generated by the subsystems.  The system achieved the top score in the  We model the process of syntactic parsing of  closed challenge: a labeled syntactic  accua sentence x as finding the parse tree  racy of 89.32%, a labeled semantic F1 of  arg maxy F (x, y) that maximizes a scoring func-81.65, and a labeled macro F1 of 85.49.  tion F . The learning problem consists of fitting this function so that the cost of the predictions is 1  Introduction: Syntactic Semantic  as low as possible according to a cost function .  In this work, we consider linear scoring functions Intuitively, semantic interpretation should help of the following form:  syntactic disambiguation, and joint syntactic  semantic analysis has a long tradition in linguis-where (x, y) is a numeric feature representation tic theory. This motivates a statistical modeling of of the pair (x, y) and w a vector of feature weights.  the problem of finding a syntactic tree  ysyn and a We defined the syntactic cost as the sum of link semantic graph  ysem for a sentence x as costs, where the link cost was 0 for a correct de-ing a function F that scores the joint syntactic  pendency link with a correct label, 0.5 for a correct semantic structure:  link with an incorrect label, and 1 for an incorrect h y  A widely used framework for fitting the weight vector is the max-margin model (Taskar et al., The dependencies in the feature representation 2003), which is a generalization of the well-used to compute F determine the tractability of the known support vector machines to general cost-search procedure needed to perform the maximiza-based prediction problems. Since the large num-tion. To be able to use complex syntactic features ber of training examples and features in our case c  Licensed under the Creative Commons  make an exact solution of the max-margin  optiAttribution-Noncommercial-Share Alike 3.0 Unported license  mization problem impractical, we used the  onSome rights reserved.  CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 183 187  2006), which approximates the optimization pro-parsers that consider features of single links only, cess in two ways:  the Chu-Liu/Edmonds algorithm can be used  inHowever, this algorithm cannot be  gen The weight vector w is updated  incremeneralized to the second-order setting McDonald tally, one example at a time.  and Pereira (2006) proved that this problem is  NP For each example, only the most violated con-hard, and described an approximate greedy search straint is considered.  To simplify implementation, we instead opted  The algorithm is a margin-based variant of the perfor the pseudo-projective approach (Nivre and  ceptron (preliminary experiments show that it out-Nilsson, 2005), in which nonprojective links are performs the ordinary perceptron on this task). Al-lifted upwards in the tree to achieve projectivity, gorithm 1 shows pseudocode for the algorithm.  and special trace labels are used to enable recovery of the nonprojective links at parse time. The use Algorithm 1 The Online PA Algorithm  of trace labels in the pseudo-projective transfor-input Training set T = {(xt, yt)}Tt=1  mation leads to a proliferation of edge label types: Number of iterations N  from 69 to 234 in the training set, many of which Initialize w to zeros  occur only once. Since the running time of our repeat N times  parser depends on the number of labels, we used t, yt) in T  only the 20 most frequent trace labels.  return waverage  Our semantic model consists of three parts:  A SRL classifier pipeline that generates a list We used a C value of 0.01, and the number of  of candidate predicate argument structures.  iterations was 6.  A constraint system that filters the candidate list to enforce linguistic restrictions on the 2.1  Features and Search  global configuration of arguments.  The feature function is a second-order  edge A global classifier that rescores the predicate  factored representation (McDonald and Pereira, argument structures in the filtered candidate  2006; Carreras, 2007). The second-order  representation allows us to express features not only of head dependent links, but also of siblings and chil-Rather than training the models on  golddren of the dependent. This feature set forces us standard syntactic input, we created an automati-to adopt the expensive search procedure by Car-cally parsed training set by 5-fold cross-validation.  reras (2007), which extends Eisner's span-based Training on automatic syntax makes the semantic dynamic programming algorithm (1996) to allow  classifiers more resilient to parsing errors, in par-second-order feature dependencies. Since the cost ticular adjunct labeling errors.  function is based on the cost of single links, this procedure can also be used to find the maximizer 3.1  of F (xi, yij) + (yi, yij), which is needed at train-The SRL pipeline consists of classifiers for predi-ing time. The search was constrained to disallow cate identification, predicate disambiguation, sup-multiple root links.  port identification (for noun predicates), argument identification, and argument classification.  Handling Nonprojective Links  trained one set of classifiers for verb predicates Although only 0.4% of the links in the training set and another for noun predicates.  For the  predare nonprojective, 7.6% of the sentences contain at icate disambiguation classifiers, we trained one least one nonprojective link. Many of these links subclassifier for each lemma. All classifiers in the represent long-range dependencies such as  whpipeline were L2-regularized linear logistic regres-movement that are valuable for semantic  prosion classifiers, implemented using the efficient cessing.  Nonprojectivity cannot be handled by  LIBLINEAR package (Lin et al., 2008). For multi-span-based dynamic programming algorithms. For class problems, we used the one-vs-all binarization 184  method, which makes it easy to prevent outputs not CHILDDEPSET,  CHILDWORDSET,   CHILDallowed by the PropBank or NomBank frame.  WORDDEPSET, CHILDPOSSET,  CHILDSince our classifiers were logistic, their output POSDEPSET. These features represent the  values could be meaningfully interpreted as prob-set of dependents of the predicate using  abilities. This allowed us to combine the scores combinations of dependency labels, words,  from subclassifiers into a score for the complete and parts of speech.  predicate argument structure. To generate the can-DEPSUBCAT. Subcategorization frame: the  condidate lists used by the global SRL models, we ap-catenation of the dependency labels of the  plied beam search based on these scores using a predicate dependents.  beam width of 4.  PREDRELTOPARENT. Dependency relation  beThe features used by the classifiers are listed in tween the predicate and its parent.  Tables 1 and 2. In the tables, the features used Features Used in Argument Identification and by the classifiers for noun and verb predicates are Classification  indicated by N and V, respectively. We selected the feature sets by greedy forward subset selection.  The lemma and sense  number of the predicate, e.g. give.01.  PredId  PredDis  VOICE. For verbs, this feature is Active or Pas-PREDWORD  sive. For nouns, it is not defined.  CHILDDEPSET  POSITION. Position of the argument with respect CHILDWORDSET  to the predicate: Before, After, or On.  CHILDWORDDEPSET  CHILDPOSSET  ARGWORD and ARGPOS. Lexical form and  CHILDPOSDEPSET  part-of-speech tag of the argument node.  Table 1: Classifier features in predicate identifica-POS. Form/part-of-speech tag of the  lefttion and disambiguation.  most/rightmost dependent of the argument.  Form/part-of-speech  of  the  CHILDDEPSET  left/right sibling of the argument.  PREDPOS. Part-of-speech tag of the predicate.  A representation of the complex  grammatical relation between the predicate  and the argument. It consists of the sequence  of dependency relation labels and link  directions in the path between predicate and  arguRELPATHTOSUPPORT  POSPATH. An alternative view of the  grammatical relation, which consists of the POS tags  passed when moving from predicate to  arguTable 2: Classifier features in argument identifica-ment, e.g. VB TO VBP PRP.  tion and classification and support detection.  RELPATHTOSUPPORT. The RELPATH from the  argument to a support chain.  VERBCHAINHASSUBJ. Binary feature that is set  Features Used in Predicate Identification and to true if the predicate verb chain has a sub-Disambiguation  ject. The purpose of this feature is to resolve PREDWORD, PREDLEMMA. The lexical form  verb coordination ambiguity as in Figure 1.  and lemma of the predicate.  Binary feature that is  PREDPARENTWORD and PREDPARENTPOS.  true if the link between the predicate verb  Form and part-of-speech tag of the parent  chain and its parent is OPRD, and the parent  node of the predicate.  has an object. This feature is meant to resolve control ambiguity as in Figure 2.  FUNCTION. The grammatical function of the  ardefined as the number of incorrect links in the gument node. For direct dependents of the  predicate argument structure. The number of it-predicate, this is identical to the RELPATH.  erations was 20 and the regularization parameter C was 0.01. Interestingly, we noted that the global ROOT  ROOT  SRL model outperformed the pipeline even when  SBJ COORD  SBJ COORD CONJ  no global features were added. This shows that the I  eat  eat  and  global learning model can correct label bias problems introduced by the pipeline architecture.  Figure 1: Coordination ambiguity: The subject I is in an ambiguous position with respect to drink.  Syntactic Semantic Integration  Our baseline joint feature representation contained only three features: the log probability of the syn-ROOT  ROOT  SBJ OPRD IM  tactic tree and the log probability of the semantic structure according to the pipeline and the global I want him to sleep  model, respectively. This model was trained on the complete training set using cross-validation. The Figure 2: Subject/object control ambiguity: I is in probabilities were obtained using the multinomial an ambiguous position with respect to sleep.  logistic function ( softmax ).  We carried out an initial experiment with a more 3.2  Linguistically Motivated Global  complex joint feature representation, but failed to Constraints  improve over the baseline. Time prevented us from exploring this direction conclusively.  The following three global constraints were used to filter the candidates generated by the pipeline.  CORE ARGUMENT CONSISTENCY. Core  arguThe submitted results on the development and test ment labels must not appear more than once.  corpora are presented in the upper part of Table 3.  DISCONTINUITY CONSISTENCY. If there is a  laAfter the submission deadline, we corrected a bug bel C-X, it must be preceded by a label X.  in the predicate identification method. This re-REFERENCE CONSISTENCY. If there is a label  sulted in improved results shown in the lower part.  R-X and the label is inside a relative clause, it Corpus  must be preceded by a label X.  Test Brown  Toutanova et al. (2005) have showed that a  Test WSJ + Brown  global model that scores the complete predicate  argument structure can lead to substantial perfor-Test Brown  mance gains. We therefore created a global SRL  Test WSJ + Brown  classifier using the following global features in ad-Table 3: Results.  dition to the features from the pipeline:  CORE ARGUMENT LABEL SEQUENCE.  The  The sequence also includes the predicate and  Table 4 shows the effect of adding second-order voice, for instance A0+ break.01/Active+A1.  features to the parser in terms of accuracy as well as training and parsing time on a Mac Pro, 3.2  MISSING CORE ARGUMENT LABELS. The set  GHz. The training times were measured on the  of core argument labels declared in the  Propcomplete training set and the parsing time and ac-Bank/NomBank frame that are not present in  curacies on the development set. Similarly to Car-the predicate argument structure.  reras (2007), we see that these features have a very Similarly to the syntactic submodel, we trained large impact on parsing accuracy, but also that the the global SRL model using the online passive  parser pays dearly in terms of efficiency as the aggressive algorithm.  The cost function was  search complexity increases from O(n3) to O(n4).  Since the low efficiency of the second-order parser semantic F1. This holds for the constraint-based restricts its use to batch applications, we see an in-SRL system as well as for the full system.  teresting research direction to find suitable com-Sem model  promises between the two approaches, for instance P+C  by sacrificing the exact search procedure.  P+C  60 hours  Table 7: Syntactic semantic integration.  Table 4: Impact of second-order features.  Conclusion  Table 5 shows the dependency types most  afWe have described a system1 for syntactic and se-fected by the addition of second-order features to mantic dependency analysis based on PropBank  the parser when ordered by the increase in F1. As and NomBank, and detailed the implementation  can be seen, they are all verb adjunct categories, of its subsystems. Crucial to our success was the which demonstrates the effect of grandchild fea-high performance of the syntactic parser, which tures on PP attachment and labeling.  achieved a high accuracy. In addition, we recon-Label  firmed the benefits of global inference in semantic TMP  analysis: both constraint-based and learning-based DTV  methods resulted in improvements over a baseline.  Finally, we showed that integration of syntactic DIR  and semantic analysis is beneficial for both sub-tasks. We hope that this shared task will spur fur-Table 5: Labels affected by second-order features.  ther research that leads to new feature representations and search procedures to handle the problem 5.2  of joint syntactic and semantic analysis.  To assess the effect of the components in the semantic submodel, we tested their performance on References  the top-scoring parses from the syntactic model.  Carreras, Xavier. 2007. Experiments with a higher-order projective dependency parser. In Proceedings of CoNLL.  Table 6 shows the results. The baseline system Chickering, David M., Dan Geiger, and David Heckerman.  consists of the SRL pipeline only (P). Adding lin-1994. Learning Bayesian networks: The combination of guistic constraints (C) results in a more precision-knowledge and statistical data. Technical Report MSR-TR-94-09, Microsoft Research.  oriented system with slightly lower recall, but sig-Crammer, Koby, Ofer Dekel, Joseph Keshet, Shai Shalev-nificantly higher F1. Even higher performance is Schwartz, and Yoram Singer.  obtained when adding the global SRL model (G).  aggressive algorithms. JMLR, 2006(7):551 585.  Eisner, Jason M. 1996. Three new probabilistic models for dependency parsing: An exploration. In Proc. of ICCL.  Lin, Chih-Jen, Ruby C. Weng, and S. Sathiya Keerthi. 2008.  Trust region Newton method for large-scale logistic regres-P+C  sion. JMLR, 2008(9):627 650.  McDonald, Ryan and Fernando Pereira. 2006. Online learning of approximate dependency parsing algorithms.  Table 6: SRL results on the top-scoring parse trees.  Proceedings of EACL-2006.  Nivre, Joakim and Jens Nilsson. 2005. Pseudo-projective dependency parsing. In Proceedings of ACL-2005.  Surdeanu, Mihai, Richard Johansson, Adam Meyers, Llu s 5.3  Syntactic Semantic Integration  M rquez, and Joakim Nivre. 2008. The CoNLL 2008  shared task on joint parsing of syntactic and semantic de-The final experiment concerned the integration of pendencies. In Proceedings of CoNLL 2008.  syntactic and semantic analysis. In this setting, Taskar, Ben, Carlos Guestrin, and Daphne Koller.  the system chooses the output that maximizes the Max-margin Markov networks. In Proceedings of NIPS.  Toutanova, Kristina, Aria Haghighi, and Christopher D. Man-joint syntactic semantic score, based on the top N  ning. 2005. Joint learning improves semantic role label-syntactic trees. Table 7 shows the results on the ing. In Proceedings of ACL-2005.  development set. We see that syntactic semantic 1Our system is freely available for download at integration improves both syntactic accuracy and http://nlp.cs.lth.se/lth_srl. 