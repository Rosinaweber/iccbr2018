 Learning with Compositional Semantics as Structural Inference for Subsentential Sentiment Analysis  Yejin Choi and Claire Cardie  Department of Computer Science  Cornell University  Ithaca, NY 14853  1: [I did [not] have any [doubt] about it.]+  2: [The report [eliminated] my [doubt] .]+  Determining the polarity of a  sentiment3: [They could [not] [eliminate] my [doubt] .]  bearing expression requires more than a  simple bag-of-words approach.  words or constituents within the expression  In the first example, doubt in isolation carries  can interact with each other to yield a  particua negative sentiment, but the overall polarity of the lar overall polarity. In this paper, we view such  sentence is positive because there is a negator not , subsentential interactions in light of composi-which flips the polarity. In the second example, both tional semantics, and present a novel  learning eliminated and doubt carry negative sentiment  based approach that incorporates structural  inin isolation, but the overall polarity of the sentence ference motivated by compositional seman-is positive because eliminated acts as a negator for tics into the learning procedure. Our exper-its argument doubt . In the last example, there are iments show that (1) simple heuristics based  on compositional semantics can perform  beteffectively two negators not and eliminated  ter than learning-based methods that do not  inwhich reverse the polarity of doubt twice,  resultcorporate compositional semantics (accuracy  ing in the negative polarity for the overall sentence.  of 89.7% vs. 89.1%), but (2) a method that  These examples demonstrate that words or  conintegrates compositional semantics into  learnstituents interact with each other to yield the  ing performs better than all other  alternaexpression-level polarity. And a system that  simWe also find that  contentply takes the majority vote of the polarity of  indiword negators , not widely employed in  previous work, play an important role in  devidual words will not work well on the above  examtermining expression-level polarity. Finally,  ples. Indeed, much of the previous learning-based  in contrast to conventional wisdom, we find  research on this topic tries to incorporate salient in-that expression-level classification accuracy  teractions by encoding them as features. One  apuniformly decreases as additional, potentially  proach includes features based on contextual  vadisambiguating, context is considered.  lence shifters1 (Polanyi and Zaenen, 2004), which  are words that affect the polarity or intensity of sen-1  Introduction  timent over neighboring text spans (e.g., Kennedy  Determining the polarity of sentiment-bearing  exal. (2007)). Another approach encodes frequent  subpressions at or below the sentence level requires  sentential patterns (e.g., McDonald et al. (2007)) as more than a simple bag-of-words approach. One of  features; these might indirectly capture some of the the difficulties is that words or constituents within subsentential interactions that affect polarity. How-the expression can interact with each other to yield a particular overall polarity. To facilitate our discus-1For instance, never , nowhere , little , most , lack , sion, consider the following examples:  scarcely , deeply .  Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 793 801, Honolulu, October 2008. c  2008 Association for Computational Linguistics  ever, both types of approach are based on learning  step in this direction.  models with a flat bag-of-features: some structural  In addition to the novel learning approach, this  information can be encoded as higher order features, paper presents new insights for content-word nega-but the final representation of the input is still a flat tors, which we define as content words that can  feature vector that is inherently too limited to ade-negate the polarity of neighboring words or  conquately reflect the complex structural nature of the stituents. (e.g., words such as eliminated in the  underlying subsentential interactions. (Liang et al., example sentences).  Unlike function-word  negators, such as not or never , content-word  negaMoilanen and Pulman (2007), on the other hand,  tors have been recognized and utilized less actively handle the structural nature of the interactions more in previous work. (Notable exceptions include e.g.,  directly using the ideas from compositional  semanNiu et al. (2005), Wilson et al. (2005), and Moilanen tics (e.g., Montague (1974), Dowty et al. (1981)). In and Pulman (2007).2)  short, the Principle of Compositionality states that In our experiments, we compare and  the meaning of a compound expression is a  funcnon-learning-based approaches to expression-level  tion of the meaning of its parts and of the  syntacpolarity classification with and without  comtic rules by which they are combined (e.g.,  Monpositional semantics and find that (1) simple  tague (1974), Dowty et al. (1981)). And Moilanen  heuristics based on compositional semantics  outperand Pulman (2007) develop a collection of  compoform (89.7% in accuracy) other reasonable  heurissition rules to assign a sentiment value to individual tics that do not incorporate compositional seman-expressions, clauses, or sentences. Their approach  tics (87.7%); they can also perform better than  simcan be viewed as a type of structural inference, but ple learning-based methods that do not incorporate  their hand-written rules have not been empirically  compositional semantics (89.1%), (2) combining  compared to learning-based alternatives, which one  learning with the heuristic rules based on  compomight expect to be more effective in handling some  sitional semantics further improves the performance  aspects of the polarity classification task.  (90.7%), (3) content-word negators play an  imporIn this paper, we begin to close the gap between  tant role in determining the expression-level  polarlearning-based approaches to expression-level  poity, and, somewhat surprisingly, we find that (4)  larity classification and those founded on  composiexpression-level classification accuracy uniformly  tional semantics: we present a novel learning-based  decreases as additional, potentially disambiguating, approach that incorporates structural inference mo-context is considered.  tivated by compositional semantics into the learning In what follows, we first explore heuristic-based  approaches in 2, then we present learning-based  apAdopting the view point of compositional  semanproaches in 3. Next we present experimental results tics, our working assumption is that the polarity of a in 4, followed by related work in 5.  sentiment-bearing expression can be determined in a  two-step process: (1) assess the polarities of the con-2  Heuristic-Based Methods  stituents of the expression, and then (2) apply a rela-This section describes a set of heuristic-based meth-tively simple set of inference rules to combine them ods for determining the polarity of a sentiment-recursively. Rather than a rigid application of hand-bearing expression. Each assesses the polarity of the written compositional inference rules, however, we  words or constituents using a polarity lexicon that  hypothesize that an ideal solution to the expression-indicates whether a word has positive or negative  level polarity classification task will be a method  polarity, and finds negators in the given expression that can exploit ideas from compositional seman-using a negator lexicon. The methods then infer the  tics while providing the flexibility needed to handle expression-level polarity using voting-based heuris-the complexities of real-world natural language  tics ( 2.1) or heuristics that incorporate  composiexceptions, unknown words, missing semantic  feational semantics ( 2.2). The lexicons are described  tures, and inaccurate or missing rules. The learning-based approach proposed in this paper takes a first  2See 5. Related Work for detailed discussion.  type of negators  function-word  function-word & content-word  maximum # of negations applied  scope of negators  over the entire expression  Table 1: Heuristic methods. (n refers to the number of negators found in a given expression.) Rules  Polarity( not [arg1] ) =  Polarity( arg1 )  Polarity( [VP] [NP] ) =  [destroyed]V P [the terrorism]NP .  Polarity( [VP1] to [VP2] ) =  [refused]V P1 to [deceive]V P2 the man.  Polarity( [adj] to [VP] ) =  [unlikely]adj to [destroy]V P the planet.  Polarity( [NP1] [IN] [NP2] ) =  Compose( [NP1], [NP2] )  [lack]NP1 [of]IN [crime]NP2 in rural areas.  Polarity( [NP] [VP] ) =  [pollution]NP [has decreased]V P .  Polarity( [NP] be [adj] ) =  Definition of Compose( arg1, arg2 )  Compose( arg1, arg2 ) =  For COMPOMC:  if (arg1 is a negator) then Polarity( arg2 )  (COMPOsition with Majority Class)  else if (Polarity( arg1 ) == Polarity( arg2 )) then Polarity( arg1 ) else the majority polarity of data  Compose( arg1, arg2 ) =  For COMPOPR:  if (arg1 is a negator) then Polarity( arg2 )  (COMPOsition with PRiority)  else Polarity( arg1 )  Table 2: Compositional inference rules motivated by compositional semantics.  majority vote. See Table 1 for summary. Note that a  word can be both a negator and have a negative prior 2.1  polarity. For the purpose of voting, if a word is de-We first explore five simple heuristics based on vot-fined as a negator per the voting scheme, then that  word does not participate in the majority vote.  OTE is defined as the majority polarity vote  by words in a given expression. That is, we count  For brevity, we refer to NEG(1) and NEG(N)  colthe number of positive polarity words and negative  lectively as NEG, and NEGEX(1) and NEGEX(N)  colpolarity words in a given expression, and assign the lectively as NEGEX.  majority polarity to the expression. In the case of a 2.2  Compositional semantics  tie, we default to the prevailing polarity of the data.  Whereas the heuristics above use voting-based  inEG(1), we first determine the majority  polarity vote as above, and then if the expression contains ference, those below employ a set of hand-written  any function-word negator, flip the polarity of the  rules motivated by compositional semantics. Table 2  majority vote once. N  shows the definition of the rules along with  motiEG(N) is similar to NEG(1),  except we flip the polarity of the majority vote n times vating examples. In order to apply a rule, we first  after the majority vote, where n is the number of  detect a syntactic pattern (e.g., [destroyed]V P [the function-word negators in a given expression.  terrorism]NP ), then apply the Compose function as  defined in Table 2 (e.g., Compose([destroyed], [the  NEGEX(1) and NEGEX(N) are defined similarly as  terrorism]) by rule #2).3  EG(1) and NEG(N) above, except both  functionword negators and content-word negators are  con3Our implementation uses part-of-speech tags and function-sidered as negators when flipping the polarity of the words to coarsely determine the patterns. An implementation 795  Compose first checks whether the first argument is  Learning-Based Methods  a negator, and if so, flips the polarity of the second While we expect that a set of hand-written heuristic argument. Otherwise, Compose resolves the polar-rules motivated by compositional semantics can be  ities of its two arguments. Note that if the second  effective for determining the polarity of a sentiment-argument is a negator, we do not flip the polarity of bearing expression, we do not expect them to be per-the first argument, because the first argument in gen-fect. Interpreting natural language is such a  comeral is not in the semantic scope of the negation.4 In-plex task that writing a perfect set of rules would  stead, we treat the second argument as a constituent be extremely challenging. Therefore, a more ideal  with negative polarity.  solution would be a learning-based method that can  We experiment with two variations of the  Comexploit ideas from compositional semantics while  pose function depending on how conflicting  polariproviding the flexibility to the rigid application of ties are resolved: COMPOMC uses a Compose func-the heuristic rules. To this end, we present a novel tion that defaults to the Majority Class of the po-learning-based approach that incorporates inference  larity of the data,5 while COMPOPR uses a Compose  rules inspired by compositional semantics into the  function that selects the polarity of the argument that learning procedure ( 3.2). To assess the effect of  has higher semantic PRiority. For brevity, we refer  compositional semantics in the learning-based  methto COMPOPR and COMPOMC collectively as COMPO.  ods, we also experiment with a simple  classification approach that does not incorporate  compositional semantics ( 3.1). The details of these two  approaches are elaborated in the following  subsections.  The polarity lexicon is initialized with the lexicon of Wilson et al. (2005) and then expanded using the  Simple Classification (SC)  General Inquirer dictionary.6 In particular, a word  Given an expression x consisting of n words x1,  contained in at least two of the following categories  is considered as positive:  n, the task is to determine the polarity y  {positive, negative} of x. In our simple binary  PLEASUR, VIRTUE, INCREAS, and a word contained  classification approach, x is represented as a  vecin at least one of the following categories is consid-tor of features f(x), and the prediction y is given by ered as negative: NEGATIV, NGTV, NEGAFF, PAIN,  argmax w f(x, y), where w is a vector of parameters  ICE, HOSTILE, FAIL, ENLLOSS, WLBLOSS,  TRANlearned from training data. In our experiment, we  use an online SVM algorithm called MIRA (Margin  For the and content-word) negator  lexInfused Relaxed Algorithm) (Crammer and Singer,  icon, we collect a handful of seed words as well as  2003)7 for training.  General Inquirer words that appear in either NOTLW  For each x, we encode the following features:  or DECREAS category. Then we expand the list of  Lexical: We add every word xi in x, and also  content-negators using the synonym information of  add the lemma of xi produced by the CASS  WordNet (Miller, 1995) to take a simple vote among  partial parser toolkit (Abney, 1996).  Dictionary: In order to mitigate the problem of  unseen words in the test data, we add features  based on parse trees might further improve the performance.  that describe word categories based on the  Gen4Moilanen and Pulman (2007) provide more detailed dis-eral Inquirer dictionary. We add this feature for  cussion on the semantic scope of negations and the semantic each x  priorities in resolving polarities.  i that is not a stop word.  5The majority polarity of the data we use for our  experi Vote: We experiment with two variations of  ments is negative.  voting-related features: for SC-VOTE, we add  When consulting the General Inquirer dictionary, senses with 7We use the Java implementation of this algorithm  less than 5% frequency and senses specific to an idiom are available at http://www.seas.upenn.edu/ strctlrn/StructLearn dropped.  /StructLearn.html.  Classification with Compositional Inference  (if such zbad not found in Z, skip parameter update for this.) If loss compo(y , z , x) > 0  (if such zgood not found in Z, stick to the original z .) l loss compo(y , zbad, x) loss compo(y , z , x)  Definitions of score functions and loss functions  Figure 1: Training procedures. y {positive, negative} denotes the true label for a given expression x = x1, ..., xn.  z denotes the pseudo gold standard for hidden variables z.  a feature that indicates the dominant polarity of  For each token xi,  words in the given expression, without  considif xi is a word in the negator lexicon  ering the effect of negators. For SC-NEGEX,  then z negator  we count the number of content-word  negaelse if xi is in the polarity lexicon as negative  tors as well as function-word negators to  dethen z negative  termine whether the final polarity should be  else if xi is in the polarity lexicon as positive  flipped. Then we add a conjunctive feature that  then z positive  indicates the dominant polarity together with  whether the final polarity should be flipped. For  then z none  brevity, we refer to SC-VOTE and SC-NEGEX  Figure 2: Constructing Soft Gold Standard z  collectively as SC.  Notice that in this simple binary classification setting, it is inherently difficult to capture the compo-depend only on the input x, so that zi = argmax w  sitional structure among words in x, because f(x, y) f(x, zi, i), where f(x, zi, i) is the feature vector en-is merely a flat bag of features, and the prediction coding around the ith word (described on the next  is governed simply by the dot product of f(x, y) and page). Once we determine the intermediate decision  the parameter vector w.  variables, we apply the heuristic rules motivated by compositional semantics (from Table 2) in order to  Classification with Compositional  obtain the final polarity y of x. That is, y = C(x, z), Inference (CCI)  where C is the function that applies the  composiNext, instead of determining y directly from x,  tional inference, either COMPOPR or COMPOMC.  For training, there are two issues we need to  as intermediate decision variables, where zi  handle: the first issue is dealing with the hidden  Because the structure of  composirepresents whether xi is a word with  positional inference C does not allow dynamic  programtive/negative polarity, or a negator, or none of the ming, it is intractable to perform exact expectation-above. For simplicity, we let each intermediate  demaximization style training that requires  enumeratcision variable zi (a) be determined independently  ing all possible values of the hidden variables z. In-from other intermediate decision variables, and (b)  stead, we propose a simple and tractable training  rule based on the creation of a soft gold standard for  whether xi is a function-word negator  z. In particular, we exploit the fact that in our task,  whether xi is a content-word negator  we can automatically construct a reasonably  accu whether xi is a negator of any kind  rate gold standard for z, denoted as z : as shown in  the polarity of xi according to Wilson et  Figure 2, we simply rely on the negator and  polaral. (2005)'s polarity lexicon  ity lexicons. Because z is not always correct, we  the polarity of x  allow the training procedure to replace z with  poi according to the lexicon  derived from the General Inquirer  dictiotentially better assignments as learning proceeds: in nary  the event that the soft gold standard z leads to an incorrect prediction, we search for an assignment that  conjunction of the above two features  leads to a correct prediction to replace z . The exact  Vote: We encode the same vote feature that we  procedure is given in Figure 1, and will be discussed use for SC-NEGEX described in 3.1.  again shortly.  As in the heuristic-based compositional semantics  Figure 1 shows how we modify the parameter  upapproach ( 2.2), we experiment with two variations  date rule of MIRA (Crammer and Singer, 2003) to  of this learning-based approach:  CCI-COMPOPR  reflect the aspect of compositional inference. In the and CCI-COMPOMC, whose compositional infer-event that the soft gold standard z leads to an incor-ence rules are COMPOPR and COMPOMC  respecrect prediction, we search for zgood, the assignment tively. For brevity, we refer to both variations col-with highest score that leads to a correct prediction, lectively as CCI-COMPO.  and replace z with zgood. In the event of no such  zgood being found among the K-best assignments of  The second issue is finding the assignment of z  The experiments below evaluate our and  with the highest score(z) =  learning-based methods for subsentential sentiment  leads to an incorrect prediction y = C(x, z).  Beanalysis ( 4.1). In addition, we explore the role  cause the structure of compositional inference C  of context by expanding the boundaries of the  does not allow dynamic programming, finding such  sentiment-bearing expressions ( 4.2).  an assignment is again intractable. We resort to enu-4.1  Evaluation with given boundaries  merating only over K-best assignments instead. If  none of the K-best assignments of z leads to an  inFor evaluation, we use the Multi-Perspective  Quescorrect prediction y, then we skip the training  intion Answering (MPQA) corpus (Wiebe et al.,  stance for parameter update.  2005), which consists of 535 newswire documents  manually annotated with phrase-level subjectivity  Features.  For each xi in x, we encode the  followinformation. We evaluate on all strong (i.e.,  intening features:  sity of expression is medium' or higher),  sentiment Lexical: We include the current word xi as well  bearing (i.e., polarity is positive' or negative') ex-as the lemma of xi produced by CASS partial  pressions.8 As a result, we can assume the  boundparser toolkit (Abney, 1996). We also add a  aries of the expressions are given. Performance is  boolean feature to indicate whether the current  reported using 10-fold cross-validation on 400  documents; a separate 135 documents were used as a  Dictionary: In order to mitigate the problem  development set. Based on pilot experiments on the  with unseen words in the test data, we add  feadevelopment data, we set parameters for MIRA as  tures that describe word categories based on the  follows: slack variable to 0.5, and the number of  General Inquirer dictionary. We add this  feaincorrect labels (constraints) for each parameter upture for each x  date to 1. The number of iterations (epochs) for  i that is not a stop word.  also add a number of boolean features that  protraining is set to 1 for simple classification, and to 4  vide following properties of xi using the  polar8We discard expressions with confidence marked as uncer-ity lexicon and the negator lexicon:  Heuristic-Based  Learning-Based  CCI  CCI  MC  Table 3: Performance (in accuracy) on MPQA dataset.  Heuristic-Based  Learning-Based  CCI  CCI  MC  Table 4: Performance (in accuracy) on MPQA data set with varying boundaries of expressions.  for classification with compositional inference. We  statistically significant. In addition, the difference use K = 20 for classification with compositional  between CCICOMPOPR (learning-based) and  COMinference.  POMC (non-learning-based) is statistically  significant, as is the difference between NEGEX and VOTE.  Performance is reported in Table 3.  Interestingly, the heuristic-based methods NEG (  Evaluation with noisy boundaries  82.2%) that only consider function-word negators  One might wonder whether employing additional  perform even worse than VOTE (86.5%), which does  context outside the annotated expression boundaries  not consider negators. On the other hand, the NEGEX  could further improve the performance. Indeed,  conmethods (87.7%) that do consider content-word  ventional wisdom would say that it is necessary to  negators as well as function-word negators perform  employ such contextual information (e.g., Wilson et  better than VOTE. This confirms the importance of  al. (2005)). In any case, it is important to determine content-word negators for determining the polari-whether our results will apply to more real-world  ties of expressions. The heuristic-based methods  settings where human-annotated expression  boundmotivated by compositional semantics COMPO  further improve the performance over NEGEX,  achievTo address these questions, we gradually relax  ing up to 89.7% accuracy. In fact, these  heurisour previous assumption that the exact boundaries of tics perform even better than the SC learning-based  expressions are given: for each annotation  boundmethods ( 89.1%). This shows that heuristics that  ary, we expand the boundary by x words for each  take into account the compositional structure of the direction, up to sentence boundaries, where x  expression can perform better than learning-based  {1, 5, }. We stop expanding the boundary if it  methods that do not exploit such structure.  will collide with the boundary of an expression with Finally, the learning-based methods that in-a different polarity, so that we can consistently re-corporate compositional inference CCI-COMPO (  cover the expression-level gold standard for  evalua90.7%) perform better than all of the previous  tion. This expansion is applied to both the training methods. The difference between CCI-COMPOPR  and test data, and the performance is reported in  Ta(90.7%) and SC-NEGEX (89.1%) is statistically  sigble 4. From this experiment, we make the following  nificant at the .05 level by paired t-test. The  difobservations:  ference between COMPO and any other heuristic that  is not based on computational semantics is also  Expanding the boundaries hurts the  performance for any method. This shows that most of  ated our approaches on the polarity classification  relevant context for judging the polarity is  contained within the expression boundaries, and  2007). We achieve 88.6% accuracy with COMPOPR,  motivates the task of finding the boundaries of  90.1% with SCNEGEX, and 87.6% with  CCICOMopinion expressions.  POMC.9 There are a number of possible reasons for  our lower performance vs. Moilanen and Pulman  The NEGEX methods perform better than VOTE  (2007) on this data set. First, SemEval-07 does not  only when the expression boundaries are  reainclude a training data set for this task, so we use sonably accurate. When the expression bound-400 documents from the MPQA corpus instead. In  aries are expanded up to sentence boundaries,  addition, the SemEval-07 data is very different from they perform worse than VOTE. We conjecture  the MPQA data in that (1) the polarity annotation  this is because the scope of negators tends to be  is given only at the sentence level, (2) the sentences limited to inside of expression boundaries.  are shorter, with simpler structure, and not as many  The COMPO methods always perform better  negators as the MPQA sentences, and (3) there are  than any other heuristic-based methods. And  many more instances with positive polarity than in  their performance does not decrease as steeply  the MPQA corpus.  as the NEGEX methods as the expression  Nairn et al. (2006) also employ a polarity  propboundaries expand. We conjecture this is  beagation algorithm in their approach to the semantic  cause methods based on compositional  semaninterpretation of implicatives. However, their notion tics can handle the scope of negators more ade-of polarity is quite different from that assumed here quately.  and in the literature on sentiment analysis. In  partic Among the learning-based methods, those that  ular, it refers to the degree of commitment of the involve compositional inference (  author to the truth or falsity of a complement clause CCI-COMPO)  always perform better than those that do not  (SC) for any boundaries. And learning with  McDonald et al. (2007) use a structured model  compositional inference tend to perform  betto determine the sentence-level polarity and the  ter than the rigid application of heuristic rules  (COMPO), although the relative performance  sions at each sentence level does not consider struc-gain decreases once the boundaries are relaxed.  tural inference within the sentence.  Related Work  Among the studies that examined content-word  negators, Niu et al. (2005) manually collected a  The task focused on in this paper is similar to that small set of such words (referred as words that  of Wilson et al. (2005) in that the general goal of the change phases ), but their lexicon was designed  task is to determine the polarity in context at a sub-mainly for the medical domain and the type of  negators was rather limited. Wilson et al. (2005) also  mulated the task differently by limiting their evalua-manually collected a handful of content-word  negation to individual words that appear in their polarity tors (referred as general polarity shifters ), but not lexicon. Also, their approach was based on a flat bag extensively. Moilanen and Pulman (2007) collected  of features, and only a few examples of what we call a more extensive set of negators semi-automatically  content-word negators were employed.  using WordNet 2.1, but the empirical effect of such  Our use of compositional semantics for the task  words was not explicitly investigated.  of polarity classification is preceded by Moilanen  and Pulman (2007), but our work differs in that  we integrate the key idea of compositional  seman9For lack of space, we only report our performance on in-tics into learning-based methods, and that we  perstances with strong intensities as defined in Moilanen and Pul-form empirical comparisons among reasonable  alman (2007), which amounts to only 208 test instances. The ternative approaches. For comparison, we evalu-cross-validation set of MPQA contains 4.9k instances.  Conclusion  FINEXIN 2005, Workshop on the Analysis of  Informal and Formal Information Exchange during  NegoIn this paper, we consider the task of determining  tiations.  the polarity of a sentiment-bearing expression,  conSoo-Min Kim and Eduard Hovy. 2004. Determining the  sidering the effect of interactions among words or  sentiment of opinions. In Proceedings of COLING.  constituents in light of compositional semantics. We Ryan McDonald, Kerry Hannan, Tyler Neylon, Mike  presented a novel learning-based approach that  inWells and Jeff Reynar. 2007. Structured Models for  corporates structural inference motivated by  compoFine-to-Coarse Sentiment Analysis. In Proceedings of sitional semantics into the learning procedure. Our  Association for Computational Linguistics (ACL) .  George A. Miller. 1995. WordNet: a lexical database for approach can be considered as a small step toward  English. In Communications of the ACM, 38(11):3941  bridging the gap between computational semantics  Richard Montague. 1974. Formal Philosophy; Selected  and machine learning methods.  papers of Richard Montague. Yale University Press.  tal results suggest that this direction of research is Karo Moilanen and Stephen Pulman. 2007. Sentiment  promising. Future research includes an approach  Composition. In Proceedings of Recent Advances in  that learns the compositional inference rules from  Natural Language Processing (RANLP 2007).  2006. Computing relative polarity for textual  inferAcknowledgments  ence. In Inference in Computational Semantics  (ICoSThis work was supported in part by National Science  Foundation Grants BCS-0624277 and IIS-0535099  2005. Analysis of polarity information in medical text.  and by Department of Homeland Security Grant  In Proceedings of the American Medical Informatics  N0014-07-1-0152. We also thank Eric Breck,  LilAssociation 2005 Annual Symposium (AMIA).  lian Lee, Mats Rooth, the members of the Cornell  Livia Polanyi and Annie Zaenen. 2004. Contextual lex-NLP reading seminar, and the EMNLP reviewers for  ical valence shifters. In Exploring Attitude and Affect insightful comments on the submitted version of the  in Text: Theories and Applications: Papers from the  2004 Spring Symposium, AAAI.  Ishizuka. 2007. Assessing sentiment of text by  semantic dependency and contextual valence analysis.  In Proc 2nd Int'l Conf on Affective Computing and In-Steven Abney.  telligent Interaction (ACII'07).  cascades. Journal of Natural Language Engineering,  2007 task 14: Affective text. In Proceedings of  SeKoby Crammer and Yoram Singer. 2003.  Ultraconservative online algorithms for multiclass problems. JMLR  Janyce Wiebe, Theresa Wilson and Claire Cardie. 2005.  Annotating expressions of opinions and emotions  David R. Dowty, Robert E. Wall and Stanley Peters.  In Language Resources and  Evalua1981. Introduction to Montague Semantics.  tion (formerly Computers and the Humanities),  39(2Net: A Publicly Available Lexical Resource for  OpinTheresa Wilson, Janyce Wiebe and Paul Hoffmann.  ion Mining. In Proceedings of 5th Conference on  Lan2005. Recognizing contextual polarity in phrase-level guage Resources and Evaluation (LREC),.  sentiment analysis. In Proceedings of HLT/EMNLP.  Percy Liang, Hal Daum III and Dan Klein. 2008. Structure Compilation: Trading Structure for Features. In International Conference on Machine Learning.  marizing customer reviews.  In Proceedings of the  ACM SIGKDD International Conference on  Knowledge Discovery & Data Mining (KDD-2004).  Alistair Kennedy and Diana Inkpen.  ment Classification of Movie and Product Reviews  Using Contextual Valence Shifters. In Proceedings of 