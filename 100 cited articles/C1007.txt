 Recognizing Expressions of Commonsense Psychology in English Text Andrew Gordon, Abe Kazemzadeh, Anish Nair and Milena Petrova  University of Southern California  Within the field of computational linguistics,  the study of commonsense psychology has not  received special attention, and is generally viewed as  Many applications of natural language  just one of the many conceptual areas that must be  processing technologies involve analyzing  addressed in building large-scale lexical-semantic  texts that concern the psychological states  resources for language processing. Although there  and processes of people, including their  have been a number of projects that have included  beliefs, goals, predictions, explanations,  concepts of commonsense psychology as part of a  and plans. In this paper, we describe our  larger lexical-semantic resource, e.g. the Berkeley  efforts to create a robust, large-scale  lexical-semantic resource for the recognition  attempted to achieve a high degree of breadth or  and classification of expressions of  comdepth over the sorts of expressions that people use  monsense psychology in English Text.  to refer to mental states and processes.  We achieve high levels of precision and  The lack of a large-scale resource for the  analyrecall by hand-authoring sets of local  sis of language for commonsense psychological  grammars for commonsense psychology  concepts is seen as a barrier to the development of  concepts, and show that this approach can  a range of potential computer applications that  inachieve classification performance greater  volve text analysis, including the following:  than that obtained by using machine  Natural language interfaces to mixed-initiative  learning techniques. We demonstrate the  utility of this resource for large-scale  corTraum, 1993) require the ability to map  expus analysis by identifying references to  pressions of users' beliefs, goals, and plans  adversarial and competitive goals in  po(among other commonsense psychology  conlitical speeches throughout U.S. history.  cepts) onto formalizations that can be  manipulated by automated planning algorithms.  Automated question answering systems  1 Commonsense Psychology in Language  (Voorhees & Buckland, 2002) require the  abilAcross all text genres it is common to find words  ity to tag and index text corpora with the  releand phrases that refer to the mental states of people  vant commonsense psychology concepts in  (their beliefs, goals, plans, emotions, etc.) and their  order to handle questions concerning the  bemental processes (remembering, imagining,  prioriliefs, expectations, and intentions of people.  tizing, problem solving). These mental states and  Research efforts within the field of psychology  processes are among the broad range of concepts  that employ automated corpus analysis  techthat people reason about every day as part of their  commonsense understanding of human  psycholtal illness impacts on language production, e.g.  ogy. Commonsense psychology has been studied  Reboul & Sabatier's (2001) study of the  disin many fields, sometimes using the terms Folk  course of schizophrenic patients, require the  psychology or Theory of Mind, as both a set of  beability to identify all references to certain  psyliefs that people have about the mind and as a set  chological concepts in order to draw statistical  of everyday reasoning abilities.  In order to enable future applications, we  unmain of children's language acquisition, but rather  dertook a new effort to meet this need for a  linguistic resource. This paper describes our efforts in  We conducted a study to determine how  politibuilding a large-scale lexical-semantic resource for  cal speeches have been tailored over the course of  automated processing of natural language text  U.S. history throughout changing climates of  miliabout mental states and processes. Our aim was to  tary action. Specifically, we wondered if  politibuild a system that would analyze natural language  cians were more likely to talk about goals having  text and recognize, with high precision and recall,  to do with conflict, competition, and aggression  every expression therein related to commonsense  during wartime than in peacetime. In order to  psychology, even in the face of an extremely broad  automatically recognize references to goals of this  range of surface forms. Each recognized  expressort in text, we used a set of local grammars  sion would be tagged with an appropriate concept  authored using the methodology described in  Secfrom a broad set of those that participate in our  tion 3 of this paper. The corpus we selected to  apcommonsense psychological theories.  ply these concept recognizers was the U.S. State of  Section 2 demonstrates the utility of a  lexicalthe Union Addresses from 1790 to 2003. The  reasemantic resource of commonsense psychology in  sons for choosing this particular text corpus were  automated corpus analysis through a study of the  its uniform distribution over time and its easy  changes in mental state expressions over the course  availability in electronic form from Project  Gutenof over 200 years of U.S. Presidential  State-of-theberg (www.gutenberg. net). Our set of local  gramUnion Addresses. Section 3 of this paper describes  mars identified 4290 references to these goals in  the methodology that we followed to create this  this text corpus, the vast majority of them begin  resource, which involved the hand authoring of  references to goals of an adversarial nature (rather  than competitive). Examples of the references that  scribes a set of evaluations to determine the  perwere identified include the following:  formance levels that these local grammars could  They sought to use the rights and privileges  achieve and to compare these levels to those of  they had obtained in the United Nations, to  machine learning approaches. Section 5 concludes  frustrate its purposes [ adversarial-goal] and  this paper with a discussion of the relative merits  cut down its powers as an effective agent of  of this approach to the creation of lexical-semantic  world progress. ( Truman, 1953)  resources as compared to other approaches.  The nearer we come to vanquishing [  adversarial-goal] our enemies the more we  inevita2 Applications to corpus analysis  bly become conscious of differences among  the victors. ( Roosevelt, 1945)  One of the primary applications of a  lexicalMen have vied [ competitive-goal] with each  semantic resource for commonsense psychology is  other to do their part and do it well. ( Wilson,  toward the automated analysis of large text  corpora. The research value of identifying  commonI will submit to Congress comprehensive  legsense psychology expressions has been  islation to strengthen our hand in combating  demonstrated in work on children's language use,  [ adversarial-goal] terrorists. ( Clinton, 1995)  where researchers have manually annotated large  text corpora consisting of parent/child discourse  Figure 1 summarizes the results of applying our  transcripts (Barsch & Wellman, 1995) and  chillocal grammars for adversarial and competitive  dren's storybooks (Dyer et al., 2000). While these  goals to the U.S. State of the Union Addresses. For  previous studies have yielded interesting results,  each year, the value that is plotted represents the  they required enormous amounts of human effort  number of references to these concepts that were  to manually annotate texts. In this section we aim  identified per 100 words in the address. The  interto show how a lexical-semantic resource for  comesting result of this analysis is that references to  monsense psychology can be used to automate this  adversarial and competitive goals in this corpus  annotation task, with an example not from the  doincrease in frequency in a pattern that directly  corresponds to the major military conflicts that the  U.S. has participated in throughout its history.  Features per 100 words  Figure 1. Adversarial and competitive goals in the U.S. State of the Union Addresses from 1790-2003  Each numbered peak in Figure 1 corresponds to  els of each of these conceptual areas are being  a period in which the U.S. was involved in a  miliauthored to support automated inference about  tary conflict. These are: 1) 1813, War of 1812, US  commonsense psychology (Gordon & Hobbs,  and Britain; 2) 1847, Mexican American War; 3)  2003). We adopted this conceptual framework in  1864, Civil War; 4) 1898, Spanish American War;  our current project because of the broad scope of  5) 1917, World War I; 6) 1943, World War II; 7)  the concepts in this ontology and its potential for  future integration into computational reasoning  1991, Gulf War; 10) 2002, War on Terrorism.  The wide applicability of a lexical-semantic  reThe full list of the 30 concept areas identified is  source for commonsense psychology will require  as follows: 1) Managing knowledge, 2) Similarity  that the identified concepts are well defined and  comparison, 3) Memory retrieval, 4) Emotions, 5)  are of broad enough scope to be relevant to a wide  Explanations, 6) World envisionment, 7)  Execurange of tasks. Additionally, such a resource must  tion envisionment, 8) Causes of failure, 9)  Manachieve high levels of accuracy in identifying these  aging expectations, 10) Other agent reasoning, 11)  concepts in natural language text. The remainder of  Threat detection, 12) Goals, 13) Goal themes, 14)  this paper describes our efforts in authoring and  evaluating such a resource.  17) Planning modalities, 18) Planning goals, 19)  Plan construction, 20) Plan adaptation, 21) Design,  3 Authoring recognition rules  22) Decisions, 23) Scheduling, 24) Monitoring, 25)  The first challenge in building any lexical-semantic  Repetitive execution, 28) Plan following, 29)  Obresource is to identify the concepts that are to be  servation of execution, and 30) Body interaction.  recognized in text and used as tags for indexing or  Our aim for this lexical-semantic resource was  markup. For expressions of commonsense  psyto develop a system that could automatically  idenchology, these concepts must describe the broad  tify every expression of commonsense psychology  scope of people's mental states and processes. An  in English text, and assign to them a tag  correontology of commonsense psychology with a high  sponding to one of the 635 concepts in this  ontoldegree of both breadth and depth is described by  ogy. For example, the following passage (from  Gordon (2002). In this work, 635 commonsense  William Makepeace Thackeray's 1848 novel,  psychology concepts were identified through an  Vanity Fair) illustrates the format of the output of  analysis of the representational requirements of a  this system, where references to commonsense  corpus of 372 planning strategies collected from 10  psychology concepts are underlined and followed  real-world planning domains. These concepts were  by a tag indicating their specific concept type  degrouped into 30 conceptual areas, corresponding to  limited by square brackets:  various reasoning functions, and full formal  modPerhaps [ partially-justified-proposition] she  directly to one of these three concepts, which  had mentioned the fact [ proposition] already to  prompted us to elaborate the original sets of  conRebecca, but that young lady did not appear to  cepts to accommodate these and other distinctions  [ partially-justified-proposition] have  rememmade in language. In the case of the conceptual  bered it [ memory-retrieval]; indeed, vowed and  area of memory retrieval, a total of twelve unique  protested that she expected [ add-expectation] to  concepts were necessary to achieve coverage over  see a number of Amelia's nephews and nieces.  the distinctions evident in English.  She was quite disappointed [  disappointmentThese local grammars were authored one  conemotion] that Mr. Sedley was not married; she  ceptual area at a time. At the time of the writing of  was sure [ justified-proposition] Amelia had said  this paper, our group had completed 6 of the  origihe was, and she doted so on [ liking-emotion]  litnal 30 commonsense psychology conceptual areas.  tle children.  The remainder of this paper focuses on the first 4  The approach that we took was to author (by  of the 6 areas that were completed, which were  hand) a set of local grammars that could be used to  evaluated to determine the recall and precision  peridentify each concept. For this task we utilized the  formance of our hand-authored rules. These four  Intex Corpus Processor software developed by the  areas are Managing knowledge, Memory,  Explanations, and Similarity judgments. Figure 2  preguistique (LADL) of the University of Paris 7  (Silsents each of these four areas with a single  berztein, 1999). This software allowed us to author  fabricated example of an English expression for  a set of local grammars using a graphical user  ineach of the final set of concepts. Local grammars  terface, producing lexical/syntactic structures that  for the two additional conceptual areas, Goals (20  can be compiled into finite-state transducers. To  concepts) and Goal management (17 concepts),  simplify the authoring of these local grammars,  were authored using the same approach as the  othIntex includes a large-coverage English dictionary  ers, but were not completed in time to be included  compiled by Blandine Courtois, allowing us to  in our performance evaluation.  specify them at a level that generalized over noun  After authoring these local grammars using the  and verb forms. For example, there are a variety of  Intex Corpus Processor, finite-state transducers  ways of expressing in English the concept of  reafwere compiled for each commonsense psychology  firming a belief that is already held, as exemplified  concept in each of the different conceptual areas.  in the following sentences:  To simplify the application of these transducers to  text corpora and to aid in their evaluation,  trans1) The finding was confirmed by the new  ducers for individual concepts were combined into  data. 2) She told the truth, corroborating his  a single finite state machine (one for each  concepstory. 3) He reaffirms his love for her. 4) We  tual area). By examining the number of states and  need to verify the claim. 5) Make sure it is true.  transitions in the compiled finite state graphs, some  Although the verbs in these sentences differ in  indication of their relative size can be given for the  tense, the dictionaries in Intex allowed us to  recogfour conceptual areas that we evaluated: Managing  nize each using the following simple description:  knowledge (348 states / 932 transitions), Memory  (<confirm> by | <corroborate> | <reaffirm> |  (203 / 725), Explanations (208 / 530), and  Similarity judgments (121 / 500).  While constructing local grammars for each of  the concepts in the original ontology of  common4 Performance evaluation  sense psychology, we identified several conceptual  distinctions that were made in language that were  In order to evaluate the utility of our set of  handnot expressed in the specific concepts that Gordon  authored local grammars, we conducted a study of  had identified. For example, the original ontology  their precision and recall performance. In order to  included only three concepts in the conceptual area  calculate the performance levels, it was first  necesof memory retrieval (the sparsest of the 30 areas),  sary to create a test corpus that contained  refernamely memory, memory cue, and memory  reences to the sorts of commonsense psychological  trieval. English expressions such as to forget and  concepts that our rules were designed to recognize.  repressed memory could not be easily mapped  To accomplish this, we administered a survey to  1. Managing knowledge (37 concepts)  He's got a logical mind ( managing-knowledge-ability). She's very gullible ( bias-toward-belief). He's skepti-cal by nature ( bias-toward-disbelief). It is the truth ( true). That is completely false ( false). We need to know whether it is true or false ( truth-value). His claim was bizarre ( proposition). I believe what you are saying ( belief). I didn't know about that (unknown). I used to think like you do ( revealed-incorrect-belief). The assumption was widespread ( assumption). There is no reason to think that ( unjustified-proposition). There is some evidence you are right ( partially-justified-proposition). The fact is well established ( justified-proposition). As a rule, students are generally bright ( inference). The conclusion could not be otherwise ( consequence). What was the reason for your suspicion ( justification)? That isn't a good reason ( poor-justification). Your argument is circular ( circular-justification). One of these things must be false ( contradiction). His wisdom is vast ( knowledge). He knew all about history ( knowledge-domain). I know something about plumbing ( partial-knowledge-domain).  He's got a lot of real-world experience ( world-knowledge). He understands the theory behind it ( world-model-knowledge). That is just common sense ( shared-knowledge). I'm willing to believe that ( add-belief). I stopped believing it after a while ( remove-belief). I assumed you were coming ( add-assumption). You can't make that assumption here ( remove-assumption). Let's see what follows from that ( check-inferences). Disregard the consequences of the assumption ( ignore-inference). I tried not to think about it ( suppress-inferences). I concluded that one of them must be wrong ( realize-contradiction). I realized he must have been there ( realize). I can't think straight ( knowledge-management-failure). It just confirms what I knew all along ( reaffirm-belief).  2. Memory (12 concepts)  He has a good memory ( memory-ability). It was one of his fondest memories ( memory-item). He blocked out the memory of the tempestuous relationship ( repressed-memory-item). He memorized the words of the song ( memory-storage). She remembered the last time it rained ( memory-retrieval). I forgot my locker combination ( memory-retrieval-failure). He repressed the memories of his abusive father ( memory-repression). The widow was reminded of her late husband ( reminding). He kept the ticket stub as a memento ( memory-cue). He intended to call his brother on his birthday ( schedule-plan). He remembered to set the alarm before he fell asleep ( scheduled-plan-retrieval). I forgot to take out the trash ( scheduled-plan-retrieval-failure).  He's good at coming up with explanations ( explanation-ability). The cause was clear ( cause). Nobody knew how it had happened ( mystery). There were still some holes in his account ( explanation-criteria). It gave us the explanation we were looking for ( explanation). It was a plausible explanation ( candidate-explanation). It was the best explanation I could think of ( best-candidate-explanation). There were many contributing factors ( factor). I came up with an explanation ( explain). Let's figure out why it was so ( attempt-to-explain). He came up with a reasonable explanation ( generate-candidate-explanation). We need to consider all of the possible explanations ( assess-candidate-explanations). That is the explanation he went with ( adopt-explanation). We failed to come up with an explanation ( explanation-failure). I can't think of anything that could have caused it ( explanation-generation-failure). None of these explanations account for the facts ( explanation-satisfaction-failure).  Your account must be wrong ( unsatisfying-explanation). I prefer non-religious explanations (explanation-preference). You should always look for scientific explanations ( add-explanation-preference). We're not going to look at all possible explanations ( remove-explanation-preference).  4. Similarity judgments (13 concepts)  She's good at picking out things that are different ( similarity-comparison-ability). Look at the similarities between the two ( make-comparison). He saw that they were the same at an abstract level ( draw-analogy). She could see the pattern unfolding ( find-pattern). It depends on what basis you use for comparison ( comparison-metric). They have that in common ( same-characteristic). They differ in that regard ( different-characteristic). If a tree were a person, its leaves would correspond to fingers ( analogical-mapping). The pattern in the rug was intricate ( pattern). They are very much alike ( similar). It is completely different ( dissimilar). It was an analogous example ( analogous).  Figure 2. Example sentences referring to 92 concepts in 4 areas of commonsense psychology  collect novel sentences that could be used for this  area. The results show that the precision of our  system is very high, with marginal recall  performThis survey was administered over the course  ance.  of one day to anonymous adult volunteers who  The low recall scores raised a concern over the  stopped by a table that we had set up on our  uniquality of our test data. In reviewing the sentences  versity's campus. We instructed the survey taker to  that were collected, it was apparent that some  surauthor 3 sentences that included words or phrases  vey participants were not able to complete the task  related to a given concept, and 3 sentences that  as we had specified. To improve the validity of the  they felt did not contain any such references. Each  test data, we enlisted six volunteers (native English  survey taker was asked to generate these 6  senspeakers not members of our development team) to  tences for each of the 4 concept areas that we were  judge whether or not each sentence in the corpus  evaluating, described on the survey in the  followwas produced according to the instructions. The  corpus of sentences was divided evenly among  these six raters, and each sentence that the rater  Managing knowledge: Anything about the  judged as not satisfying the instructions was  filknowledge, assumptions, or beliefs that people  tered from the data set. In addition, each rater also  have in their mind  judged half of the sentences given to a different  Memory: When people remember things,  forrater in order to compute the degree of inter-rater  get things, or are reminded of things  Explanations: When people come up with  possentences from the corpus, a second  precisible explanations for unknown causes  sion/recall evaluation was performed. Table 2  pre Similarity judgments: When people find  simisents the results of our hand-authored local  larities or differences in things  grammars on the filtered data set, and lists the  inter-rater agreement for each conceptual area among  A total of 99 people volunteered to take our  our six raters. The results show that the system  survey, resulting in a corpus of 297 positive and  achieves a high level of precision, and the recall  297 negative sentences for each conceptual area,  performance is much better than earlier indicated.  with a few exceptions due to incomplete surveys.  The performance of our hand-authored local  Using this survey data, we calculated the  precigrammars was then compared to the performance  sion and recall performance of our hand-authored  that could be obtained using more traditional  malocal grammars. Every sentence that had at least  chine-learning approaches. In these comparisons,  one concept detected for the corresponding concept  the recognition of commonsense psychology  conarea was treated as a hit . Table 1 presents the  cepts was treated as a classification problem,  precision and recall performance for each concept  where the task was to distinguish between positive  Correct Hits  Wrong hits  Precision  Memory  Similarity judgments  Table 1. Precision and recall results on the unfiltered data set  Inter-rater  Correct  Precision  Hits (a)  hits (b)  Managing knowledge  Memory  Table 2. Precision and recall results on the filtered data set, with inter-rater agreement on filtering  A. Hand authored local  B. SVM with word level  C. SVM with word and  features  Memory  Similarity judgments  Table 3. Percent agreement ( Pa) and Kappa statistics ( K) for classification using hand-authored local grammars (A), SVMs with word features (B), and SVMs with word and concept features (C) and negative sentences for any given concept area.  Sentences in the filtered data sets were used as  training instances, and feature vectors for each  sentence were composed of word-level unigram  The most significant challenge facing developers  and bi-gram features, using no stop-lists and by  of large-scale lexical-semantic resources is coming  ignoring punctuation and case. By using a toolkit  to some agreement on the way that natural  lanof machine learning algorithms (Witten & Frank,  guage can be mapped onto specific concepts. This  1999), we were able to compare the performance  challenge is particularly evident in consideration of  of a wide range of different techniques, including  our survey data and subsequent filtering. The  Na ve Bayes, C4.5 rule induction, and Support  abilities that people have in producing and  recogVector Machines, through stratified  crossnizing sentences containing related words or  validation (10-fold) of the training data. The  highphrases differed significantly across concept areas.  est performance levels were achieved using a  seWhile raters could agree on what constitutes a  sentence containing an expression about memory  training a support vector classifier using  polyno(Kappa=.8069), the agreement on expressions of  mial kernels (Platt, 1998). These performance  remanaging knowledge is much lower than we  sults are presented in Table 3. The percentage  would hope for (Kappa=.5636). We would expect  correctness of classification ( Pa) of our  handmuch greater inter-rater agreement if we had  authored local grammars (column A) was higher  trained our six raters for the filtering task, that is,  than could be attained using this machine-learning  described exactly which concepts we were looking  approach (column B) in three out of the four  confor and gave them examples of how these concepts  can be realized in English text. However, this  apWe then conducted an additional study to  deproach would have invalidated our performance  termine if the two approaches (hand-authored local  results on the filtered data set, as the task of the  grammars and machine learning) could be  comraters would be biased toward identifying  examplimentary. The concepts that are recognized by  ples that our system would likely perform well on  our hand-authored rules could be conceived as  adrather than identifying references to concepts of  ditional bimodal features for use in machine  commonsense psychology.  learning algorithms. We constructed an additional  Our inter-rater agreement concern is indicative  set of support vector machine classifiers trained on  of a larger problem in the construction of  largethe filtered data set that included these additional  scale lexical-semantic resources. The deeper we  concept-level features in the feature vector of each  delve into the meaning of natural language, the less  instance along side the existing unigram and  biwe are likely to find strong agreement among  ungram features. Performance of these enhanced  trained people concerning the particular concepts  classifiers, also obtained through stratified  crossthat are expressed in any given text. Even with  validation (10-fold), are also reported in Table 3 as  well (column C). The results show that these  enknowledge (e.g. commonsense psychology), finer  hanced classifiers perform at a level that is the  distinctions in meaning will require the efforts of  greater of that of each independent approach.  trained knowledge engineers to successfully map  between language and concepts. While this will  sion/recall performance evaluations, the concern is  even more serious for other methodologies that  rely on large amounts of hand-tagged text data to  Baker, C., Fillmore, C., & Lowe, J. (1998) The  Berkeley FrameNet project. in Proceedings of the  create the recognition rules in the first place. We  expect that this problem will become more evident  as projects using algorithms to induce local  gramBartsch, K. & Wellman, H. (1995) Children talk about  mars from manually-tagged corpora, such as the  the mind. New York: Oxford University Press.  Dyer, J., Shatz, M., & Wellman, H. (2000) Young  chilbroaden and deepen their encodings in conceptual  dren's storybooks as a source of mental state  inforareas that are more abstract (e.g. commonsense  mation. Cognitive Development 15:17-37.  Ferguson, G. & Allen, J. (1993) Cooperative Plan  ReaThe approach that we have taken in our  resoning for Dialogue Systems, in AAAI-93 Fall  Symsearch does not offer a solution to the growing  posium on Human-Computer Collaboration:  problem of evaluating lexical-semantic resources.  Reconciling Theory, Synthesizing Practice, AAAI  However, by hand-authoring local grammars for  Technical Report FS-93-05. Menlo Park, CA: AAAI  specific concepts rather than inducing them from  Press.  tagged text, we have demonstrated a successful  Gordon, A. (2002) The Theory of Mind in Strategy  methodology for creating lexical-semantic  reRepresentations. 24th Annual Meeting of the  Cognisources with a high degree of conceptual breadth  tive Science Society. Mahwah, NJ: Lawrence  Erland depth. By employing linguistic and knowledge  baum Associates.  engineering skills in a combined manner we have  Gordon, A. & Hobbs (2003) Coverage and competency  been able to make strong ontological commitments  in formal theories: A commonsense theory of  memabout the meaning of an important portion of the  ory. AAAI Spring Symposium on Formal Theories of  English language. We have demonstrated that the  Commonsense knowledge, March 24-26, Stanford.  precision and recall performance of this approach  Platt, J. (1998). Fast Training of Support Vector  Mais high, achieving classification performance  chines using Sequential Minimal Optimization. In B.  greater than that of standard machine-learning  Sch lkopf, C. Burges, and A. Smola (eds.) Ad vances  techniques. Furthermore, we have shown that  in Kernel Methods Support Vector Learning,  Camhand-authored local grammars can be used to  bridge, MA: MIT Press.  identify concepts that can be easily combined with  Reboul A., Sabatier P., No l-Jorand M-C. (2001) Le  word-level features (e.g. unigrams, bi-grams) for  essing systems. Our early exploration of the  application of this work for corpus analysis (U.S. State  of the Union Addresses) has produced interesting  Computers and the Humanities 33(3).  results, and we expect that the continued  development of this resource will be important to the  sucTraum, D. (1993) Mental state in the TRAINS-92  diacess of future corpus analysis and human-computer  logue manager. In Working Notes of the AAAI Spring  interaction projects.  Symposium on Reasoning about Mental States:  Formal Theories and Applications, pages 143-149, 1993.  Acknowledgments  Menlo Park, CA: AAAI Press.  Voorhees, E. & Buckland, L. (2002) The Eleventh Text  This paper was developed in part with funds from  REtrieval Conference (TREC 2002). Washington,  the U.S. Army Research Institute for the  BehavDC: Department of Commerce, National Institute of  ioral and Social Sciences under ARO contract  Standards and Technology.  number DAAD 19-99-D-0046. Any opinions,  Witten, I. & Frank, E. (1999) Data Mining: Practical  findings and conclusions or recommendations  exMachine Learning Tools and Techniques with Java  pressed in this paper are those of the authors and  do not necessarily reflect the views of the  Department of the Army. 