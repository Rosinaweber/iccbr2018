 Cross-Linguistic Sentiment Analysis: From English to Spanish Julian Brooke  Department of Linguistics  School of Computing Science  Department of Linguistics  Simon Fraser University  Simon Fraser University  Simon Fraser University  resources, which we build both manually and  automatically. The second approach, used in Bautin et al.  We explore the adaptation of English resources  [4] and Wan [18], consists of translating the texts into and techniques for text sentiment analysis to a  new language, Spanish. Our main focus is the  English, and using an existing English calculator. Finally, modification of an existing English semantic  the third approach builds unigram Support Vector  orientation calculator and the building of  Machine classifiers from our Spanish corpora.  dictionaries; however we also compare alternate  approaches, including machine translation and  that, although translation and machine learning  Support Vector Machine classification. The  classification both perform reasonably well, there is a results indicate that, although language-significant cost to automated translation. A language-independent methods provide a decent baseline  specific SO Calculator with dictionaries built using  performance, there is also a significant cost to  words that actually appear in relevant texts gives the best automation, and thus the best path to long-term  performance, with significant potential for improvement.  improvement is through the inclusion of  language-specific knowledge and resources.  2. The English SO Calculator  1. Introduction  Our semantic orientation calculator (SO-CAL) uses five main dictionaries: four lexical dictionaries with 2,257  Sentiment analysis refers to the automatic determination adjectives, 1,142 nouns, 903 verbs, and 745 adverbs, and of subjectivity (whether a text is objective or subjective), a fifth dictionary containing 177 intensifying words and polarity (positive or negative) and strength (strongly or expressions. Although the vast majority of the entries are weakly positive/negative). It is a growing field of  single words, our calculator also allows for multiword research, especially given the gains to be obtained from entries written in regular expression-like language.  mining opinions available online. Approaches to  The SO-carrying words in these dictionaries were  sentiment analysis have tackled the problem from two  taken from a variety of sources, the three largest a corpus different angles: a word-based or semantic approach, or a of 400 mixed reviews from Epinions.com, a 100 text  machine learning (ML) approach. The word-based  subset of the 2,000 movie reviews in the Polarity Dataset approach uses dictionaries of words tagged with their  [12], and positive and negative words from the General semantic orientation (SO), and calculates sentiment by Inquirer dictionary [15]. Each of the open-class words aggregating the values of those present in a text or  were given a hand-ranked SO value between 5 and -5 by sentence [17]. The ML approach uses collections of texts a native English speaker. The numerical values were  that are known to express a favorable or unfavorable  chosen to reflect both the prior polarity and strength of opinion as training data, and learns to recognize  the word, averaged across likely interpretations. For sentiment based on those examples [13].  example, the word phenomenal is a 5, nicely a 2, disgust Our approach is semantic, and makes use of a series  a -3, and monstrosity a -5. The dictionary was later of dictionaries, additionally taking into account the role reviewed by a committee of three other researchers in of negation, intensification and irrealis expressions. We order to minimize the subjectivity of ranking SO by  believe that a semantic approach offers the advantage of hand.  taking many different aspects of a text into account.  SO-CAL also implements a modified version of  One of the disadvantages of a semantic approach is  contextual valence shifting as originally proposed by that the resources necessary for a new domain or a new Polanyi and Zaenen [14], including negation and  language need to be built from scratch, whereas a  intensification. We have also added irrealis blocking.  machine-learning approach only needs enough data to  Our approach to negation differs from Polanyi and  train. In this paper we show that porting to a new  Zaenen's in that negation involves a polarity shift instead language, Spanish, requires only a small initial  of a switch: A negated adjective is shifted by a fixed investment, while providing the opportunities for further amount (4) toward the origin. This means that the  improvement available only to semantic methods.  negation of a strongly negative word (like terrible) will For comparison, we have taken three approaches to  be neutral or weakly negative ( not terrible 5 + 4 = -1  performing sentiment analysis in a new language. Our  instead of 5), while the negation of a weakly positive main approach involves deploying Spanish-specific  word like nice is equally negative ( not nice 2 4 = -2).  International Conference RANLP 2009 Borovets, Bulgaria, pages 50 54  The calculation of intensification is somewhat more and we adapted a 500,000+ word lemma dictionary  sophisticated than simple addition and subtraction. Each included in the FreeLing software package1, which we  expression in our intensifier dictionary is associated with used to both lemmatize the words and to add more detail a multiplier value. For instance, very has a value of .25, to the basic verb tags assigned by SVMTool (each verb is which means the SO value of any adjective modified by lemmatized, but tagged with information about its tense very is increased by 25%. We also included three other and mood). We found that some sentiment-relevant  kinds of intensification that are common within our  words were not being lemmatized properly, so we also  genre: the use of all capital letters, the use of exclamation implemented a second layer of lemmatization within the points, and the use of discourse but to indicate more calculator.  salient information (e.g., but the movie was GREAT! ).  Most of the Python code written for the English  Some markers indicate that the words appearing in a  version of SO-CAL could be reused. With regards to  sentence might not be reliable for the purposes of  detecting negation, intensification, and modifier  sentiment analysis. We refer to these using the linguistic blocking, it was necessary to take into account the fact term irrealis. Irrealis markers in English include modals that in Spanish adjectives appear both before and (more ( would, could), some verbs ( expect, doubt), and certain commonly) after the noun. The most interesting  kinds of punctuation (questions, quotations). When SO-difference was the fact that verb forms in Spanish  carrying words appear within the scope of these markers, provide irrealis information. In particular, the conditional our calculator ignores them.  tense and the imperative and subjunctive moods often  Lexicon-based sentiment classifiers generally show a  serve to indicate that the situation being referred to is not positive bias [10], likely the result of a human tendency in fact the case. Thus, in Spanish we used a mixture of to favor positive language [6]. In order to overcome this word and inflection-based irrealis blocking, using the bias, we increase the final SO of any negative expression same words as the English version whenever possible.  (after other modifiers have applied) by a fixed amount We built new Spanish dictionaries, including  (currently 50%).  dictionaries for adjectives, nouns, verbs, adverbs and For initial testing, we use the 400 text Epinions  intensifiers. For intensifiers, given the fact that they are corpus (50 texts in each of eight different product types), closed-class and highly idiosyncratic, we simply created the other 1,900 texts in the Polarity Dataset (Movie), and a new list of 157 expressions, based on the English list.  a 2,400 text corpus of camera, printer, and stroller  For the open-class dictionaries, we tested three different reviews (Camera) taken from a larger set of Epinions  methods of dictionary-building; we compare their  reviews also used by Bloom et al. [5], for a total of 4,700  performance on the Spanish corpus in Section 5.  texts split equally between positive and negative. Table 1  The first set of dictionaries started with the English shows the performance of the English calculator with all dictionaries for each part of speech, which we translated features, and disabling the three types of valence shifters automatically into Spanish, preserving the semantic  (negation, intensification and irrealis) and the extra orientation value for each word. For the automatic  weight on negative words. An asterisk (*) indicates that a translation we used, in turn, two different methods. The chi-square test yielded significance at the p<0.05 level, as first was an online bilingual dictionary, from the site compared to the result with all features enabled. Whereas www.spanishdict.com. We extracted the first definition not all the differences are statistically significant, it does under the appropriate syntactic category, ignoring any seem that the set of features that we have chosen has a cases where either the English or the Spanish were multi-positive effect on performance.  word expressions. The second automatic translation  Table 1. Effects of disabling various features  method involved simply plugging our English  dictionaries into the Google translator and parsing the Percent Correct by Corpus  Features Epinions  For the second method of dictionary creation, we  took the lists from Spanishdict.com and manually fixed No Neg  entries that were obviously wrong. This involved mostly No Int  79.0* 74.7 77.5* 76.5* removing words in the wrong dictionary for their part of No Irreal  speech, but also changing some of the values (less than No Neg W  10% for each dictionary). This hand-correction took a native speaker of Spanish about two hours to complete.  3. The Spanish SO Calculator  Finally, the third method consisted in creating all  Compared to English, Spanish is a highly inflected  dictionaries from scratch. Our source corpora created for language, with gender and plural markers on nouns, as this project consists of reviews extracted from the  well as a rich system of verbal inflection (45 possible Ciao.es review website. Following the basic format of the verb forms). In the English version of SO-CAL, the only Epinions corpus, we collected 400 reviews from the  external software we made use of was the Brill tagger domains of hotels, movies, music, phones, washing  [7]; lemmatization of noun and verbs was simple enough machines, books, cars, and computers. Each category  to be carried out during the calculation. For Spanish, we used a high-accuracy statistical tagger, the SVMTool [9], 1 http://garraf.epsevg.upc.es/freeling/  contained 50 reviews: 25 positive and 25 negative.  Support Vector Machine (SVM) classifiers, built with the Whenever possible, exactly two reviews, one positive  sequential minimal optimization algorithm included in and one negative, were taken for any particular product, the WEKA software suite [20], with a linear kernel and so that the machine learning classifier described in  testing done with 10-fold cross-validation. We trained Section 4.2 could not use names as sentiment clues.  using unigram features that appeared at least four times We tagged the Spanish corpus collected from  in the dataset (the same cut-off was used by Pang and Ciao.es, and extracted all adjectives, nouns, adverbs and Lee [12]). To test the efficacy of the WEKA classifiers, verbs. This resulted in large lists for each category (e.g., we first trained a classifier on the full 2,000 text Polarity over 10,000 nouns). We manually pruned the lists,  Dataset, a collection of balanced positive and negative removing words that did not convey sentiment,  movie reviews [12], comparing the cross-validated  misspelled and inflected words, and words with the  results with the baseline for SVM unigram classifiers on wrong part of speech tag. Finally, semantic orientation this dataset (before other improvements) given in Pang values were assigned for each. This process took a native and Lee [12]. The difference (about 1%) was not  speaker of Spanish about 12 hours. We decided against a statistically significant. It is worth noting that more committee review of the Spanish dictionaries for the time recent work in SVM-based sentiment analysis has shown being.  significant improvement on this baseline [19], however Another type of dictionary tested was a merging of  relevant resources are not available for Spanish.  the dictionaries created using the second and third  In order to compare the classifier across languages,  methods, i.e., the automatically-created (but hand-fixed) we trained separately on each of our two 400-text  dictionaries and the ones created from scratch (Ciao  development corpora. In each case we used the output  manual). We created two versions of these dictionaries, after pre-processing, with lemmatizing in the case of depending on whether we used the value from the Fixed Spanish. In addition to basic unigrams we also tested Spanishdict.com or Ciao dictionary.  unigrams with full POS tags and, for Spanish, partial tags The dictionaries range from smallest (retaining word class but disregarding inflection such as (Spanishdict.com) to largest (Ciao+Fixed). The first one number and person). The results were identical or in  contains 1,160 adjectives, 979 nouns, 500 verbs and 422  some cases worse than a simple unigram model.  adverbs. The combined dictionary has 2,049 adjectives, 5. Evaluation  We built two additional 400 text corpora, in English and We performed a comparison of fully automated and  Spanish, with the same basic constituency as the  fully manual methods, comparing the unedited  Epinions and Ciao Corpus discussed earlier. The English Spanishdict.com dictionaries and the ones created by  corpus (Epinions 2) is also from the Epinions site, while hand. We calculated the percentage of words in common, the Spanish corpus came from Dooyoo.es. This second  as a percentage of the size for the larger of the two sets set of texts for each language has never been used for (the Spanishdict.com dictionaries). The commonalities training or development of any of our resources  ranged from roughly 20% of the words for nouns to 41%  All four corpora were translated using the  for adjectives (i.e., 41%, or 480 of the hand-ranked  appropriate Google translator, and for each version the adjectives were also found in the automatic dictionary).  accuracy identifying the polarity of reviews for all  We also compared the values assigned to each word: The possible dictionaries and methods was tested. Note that variance of the error ranged from 1.001 (verbs) to 1.518  when the corpus and the dictionary are the same  (adjectives). Automatically translated dictionaries tend to language, the original version of the corpus is used, and include more formal words, whereas the ones created by when the corpus and the dictionary are in different  hand include many more informal and slang words  languages, we use the translated version. The results are 4. Alternative approaches  4.1 Corpus translation  There are a number of clear patterns in Table 2.  For translation, we used Google's web-based translation First, for the original Spanish versions, the translated system. Google Translate (translate.google.com) uses  Spanish dictionaries, taken together, do poorly compared phrase-based statistical machine translation. We used to the versions of the dictionaries derived from actual only one translator, but Bautin et al. [4] discuss the use of Spanish texts; this is significant at the p<0.05 level for all different Spanish translating systems, and Wan [18]  possible dictionary combinations (all significance results compare Chinese machine translators; the latter found are derived from chi-square tests). For Spanish, including that Google gave the best performance, which is  words from translated dictionaries has little or no benefit.  consistent with our preliminary testing of other systems.  The opposite is true for Spanish translations of English texts, where the Ciao (manual) dictionary performance is 4.2 Machine Learning  low, and performance improves dramatically with the  A popular approach to sentiment analysis has been the addition of translated (although manually fixed)  automatic training of a text classifier. Cross-linguistic resources; in the case of the Epinions 2 corpus, this sentiment detection seems particularly amenable to  improvement is significant ( p<0.05). We attribute this to machine learning, since classifiers can be easily trained the fact that translated texts and translated dictionaries in any language. Following Pang et al. [13], we used  speak the same language ; translated English corpora 52  Table 2. Accuracy of polarity detection for various corpora and methods Corpus  Method English  Spanish  Dictionary  Epinions  English  English SO-CAL  Spanish  Google-translated  Spanish  Spanishdict.com 68.75  Spanish  Fixed Spanishdict.com  Spanish  Ciao + Fixed Combined,  Spanish  Ciao + Fixed Combined,  Support Vector Machine, English versions  Support Vector Machine, Spanish versions  are unlikely to contain the colloquial Spanish found  in the Ciao dictionary, and are more likely to contain the these high coverage corpora do outperform their low  kind of formal language we saw in our translated  dictionaries (compared with the Subjective dictionary, Turning now to machine learning methods, the SVM  for instance); in general, though, there were no  classifiers show the worse performance overall, however significant differences among same-language corpora  only the difference seen in the Epinions 2 corpus is  tested using the same dictionary. Note also that using significant (at the p<0.01 level). The relatively poor high-coverage corpora is not analogous to testing and performance of the SVM classifier in this case can be training on the same corpora, since words are rated for attributed to the small size of the training set and the SO independently of the texts in which they appear.  heterogeneity of the corpora; SVM classifiers have been 6. Related Work  shown to have poor cross-domain performance in text  Wan [18] created a hybrid classifier which combined the sentiment tasks [2], a problem that can be remedied  scores from a Chinese lexicon-based system and an  somewhat by integrating a lexicon-based system [1].  English lexicon-based system (with translated texts). In The numbers in Table 2 do not indicate a clear  contrast to our results, his Chinese lexicon-based system winner with respect to the performance of Spanish SO-performed quite poorly compared to the English system.  CAL as compared to English SO-CAL with translated  Similar to our results, Chinese lexicons created by  texts, although it is clear that translating English texts translating English lexicons did not help performance.  into Spanish is, at present, a bad approach ( p<0.01). The Although they are concerned with sentence level  totals for all corpora for each method suggest that  subjectivity instead of text-level polarity, the work of Spanish SO-CAL is performing well below English SO-Mihalcea et al. [11] is quite relevant, since their focus, CAL ( p<0.01).  like ours, is on exploring ways to deriving new resources Table 3 summarizes the effects of translation.  from existing resources for English. In adapting  Original refers to all the 1,600 original versions and subjectivity cues to Romanian, they also saw limited  Translated to all 1,600 translated versions. For SO  benefits to straight translation of dictionaries, but calculation, we use the best performing dictionary in the obtained promising results from the projection of English relevant language.  annotations into Romanian.  Table 3. Accuracy for translated/original corpora  Bautin et al. [4] used online resources from multiple Method Texts  Accuracy languages, including Spanish, into English, using the Original 76.62  output from an existing sentiment analyzer to track  SO Calculation  Translated 71.81  [21] made use of a bilingual lexicon to build a Chinese SVM  Translated 69.25  sentiment dictionary using English glosses.  LexiconTable 3 shows a general deficit for translated texts; based sentiment analysis has also been pursued  for SO calculation, this is significant at the p<0.01 level.  independently in a number of East Asian languages,  The fact that it is also visible in SVMs (which are not including Japanese [16], Chinese [22], and Korean [8].  subject to dictionary biases) suggests that it is a general As far as we know, ours is the first Spanish SO  phenomenon. One potential criticism here is our use of calculator. Banea et al. [3] report on work in Spanish, but corpora whose words were the basis for our dictionary, theirs is a subjectivity classification task.  unfairly providing two of the four original corpora with In terms of approaches to calculation of text level  high coverage which would not pass to the translations.  sentiment in English, the work of Kennedy and Inkpen  Indeed, there is some evidence in Table 3 to suggest that  [10] is the most directly comparable. Their main focus was the comparison of lexicon-based versus machine  learning approaches; in contrast to our results, they found  [4] M. Bautin, L. Vijayarenu and S. Skiena. International that performance of their semantic model was  sentiment analysis for news and blogs. Proc. of 3rd AAAI significantly below that of an SVM classifier.  International Conference on Weblogs and Social Media.  To facilitate comparisons with other approaches, the  [5] K. Bloom, G. Navendu and S. Argamon. Extracting  corpora and some of the resources described in the paper appraisal expressions. Proc. of HLT/NAACL. Rochester, are available2.  7. Conclusion  [6] J.D. Boucher and C.E. Osgood. The Pollyanna hypothesis.  Journal of Verbal Learning and Verbal Behaviour 8: 1-8, The surge in attention paid to automated analysis of text 1969.  sentiment has largely been focused on English. In this  [7] E. Brill. A simple rule-based part of speech tagger. Proc.  paper, we have discussed how to adapt an existing  of 3rd Conference on Applied Natural Language  English semantic orientation system to Spanish while at Processing. Trento, Italy, 1992.  the same time comparing several alternative approaches.  [8] Y.H. Cho and K.J. Lee. Automatic affect recognition using Our results indicate that SVMs, at least the fairly  natural language processing techniques and manually built simple SVMs we have tested here, do not do very well in affect lexicon. IEICE Transactions on Information and our Spanish corpora. There are a number of obvious  reasons for this, and our rejection of SVMs is far from  tagger generator based on support vector machines. Proc.  decisive; on the contrary, machine learning might be  of Conference on Language Resources and Evaluation  useful, for instance, in identifying parts of the text that (LREC). Lisbon, Portugal, 2004.  should be disregarded during the SO calculation [12].  [10] A. Kennedy and D. Inkpen. Sentiment classification of For calculation of semantic orientation using  movie and product reviews using contextual valence  lexicons, translation of any kind seems to come with a shifters. Computational Intelligence 22(2): 110-125, 2006.  price, even between closely related languages such as  [11] R. Mihalcea, C. Banea and J. Wiebe. Learning  English and Spanish. Our Spanish SO calculator  (SOmultilingual subjective language via cross-lingual  CAL) is clearly inferior to our English SO-CAL,  projections. Proc. of ACL. Prague, Czech Republic, 2007.  probably the result of a number of factors, including a  [12] B. Pang and L. Lee. A sentimental education: Sentiment small, preliminary dictionary, and a need for additional analysis using subjectivity summarization based on  minimum cuts. Proc. of ACL. Barcelona, Spain, 2004.  adaptation to a new language. Translating our English  [13] B. Pang, L. Lee and S. Vaithyanathan. Thumbs up?  dictionary also seems to result in significant semantic Sentiment classification using Machine Learning  loss, at least for original Spanish texts. Although  techniques. Proc. of EMNLP, 2002.  performance of Spanish texts translated into English is  [14] L. Polanyi and A. Zaenen. Contextual valence shifters. In comparable to native SO-CAL performance, the overall  Computing Attitude and Affect in Text: Theory and  accuracy of translated texts in both English and Spanish Applications, J.G. Shanahan, Y. Qu, and J. Wiebe, Eds.  suggests that there is 3-5% performance cost for any  (automated) translation. This, together with the fact that  [15] P.J. Stone. Thematic text analysis: New agendas for translation seems to have a disruptive effect on previous analyzing text content. In Text Analysis for the Social Sciences, C. Roberts, Ed. Lawrence Erlbaum: Mahwah,  reliable improvements, as well as the relatively small NJ, 1997.  time investment required to develop Spanish SO-CAL,  lead us to conclude that there is value in pursuing the semantic orientations of words using spin model. Proc. of development of language-specific resources,  ACL. Ann Arbor, 2005.  notwithstanding new breakthroughs in machine  [17] P. Turney. Thumbs up or thumbs down? Semantic  translation.  orientation applied to unsupervised classification of 8. Acknowledgments  reviews. Proc. of ACL, 2002.  [18] X. Wan. Using bilingual knowledge and ensemble  This work was supported by a NSERC Discovery Grant  [19] C. Whitelaw, N. Garg and S. Argamon. Using Appraisal groups for sentiment analysis. Proc. of ACM SIGIR  [1] A. Andreevskaia and S. Bergler. When specialists and Conference on Information and Knowledge Management  (CIKM 2005). Bremen, Germany, 2005.  sentiment tagging. Proc. of 46th ACL. Columbus, OH,  [20] I.H. Witten and E. Frank. Data Mining: Practical Machine 2008.  Learning Tools and Techniques. 2nd ed. San Francisco:  [2] A. Aue and M. Gamon. Customizing sentiment classifiers Morgan Kaufmann, 2005.  to new domains: A case study. Proc. of RANLP. Borovets,  lexicon to judge sentiment orientation of Chinese words.  [3] C. Banea, R. Mihalcea, J. Wiebe and S. Hassan.  Proc. of 6th International Conference on Computer and Multilingual subjectivity analysis using machine  Information Technology (CIT'06). Seoul, Korea, 2006.  translation. Proc. of EMNLP. Honolulu, 2008.  [22] Q. Ye, B. Lin and Y.-J. Li. Sentiment classification for Chinese reviews: A comparison between SVM and  semantic approaches. Fourth Int. Conference on Machine Learning and Cybernetics. Guangzhou, China, 2005. 