 More than Words:  Syntactic Packaging and Implicit Sentiment  ATG, Inc.  Linguistics / UMIACS CLIP Laboratory  1111 19th St, NW Suite 600  University of Maryland  Washington, DC 20036  College Park, MD 20742  Both descriptions appear on the surface to be  objective statements, and they use nearly the same words.  Work on sentiment analysis often focuses on  Lexically, the sentences' first clauses differ only in the words and phrases that people use in  the difference between 's and his to express the rela-overtly opinionated text. In this paper, we  intionship between the soldier and the jeep, and in the troduce a new approach to the problem that  second clauses both kill and death are terms with focuses not on lexical indicators, but on the  syntactic packaging of ideas, which is well  negative connotations, at least according to the  Gensuited to investigating the identification of  implicit sentiment, or perspective. We establish a tions clearly differ in the feelings they evoke: if the strong predictive connection between linguis-soldier were being tried for his role in what  haptically well motivated features and implicit  pened on November 25, surely the prosecutor would  sentiment, and then show how computational  be more likely to say (1a) to the jury, and the defense approximations of these features can be used  attorney (1b), rather than the reverse.1  to improve on existing state-of-the-art  sentiWhy, then, should a description like (1a) be  perceived as less sympathetic to the soldier than (1b)?  If the difference is not in the words, it must be in  Introduction  the way they are put together; that is, the structure of the sentence. In Section 2, we offer a specific hy-As Pang and Lee (2008) observe, the last several  pothesis about the connection between structure and  years have seen a land rush in research on  sentiimplicit sentiment: we suggest that the relationship  ment analysis and opinion mining, with a frequent  is mediated by a set of grammatically relevant  seemphasis on the identification of opinions in  evaluamantic properties well known to be important  crosstive text such as movie or product reviews.  Howlinguistically in characterizing the interface between ever, sentiment also may be carried implicitly by  syntax and lexical semantics. In Section 3, we  valstatements that are not only non-evaluative, but not  idate this hypothesis by means of a human ratings  even visibly subjective. Consider, for example, the  study, showing that these properties are highly  prefollowing two descriptions of the same (invented)  dictive of human sentiment ratings. In Section 4, we  introduce observable proxies for underlying seman-1(a) On November 25, a soldier veered his jeep into  tics (OPUS), a practical way to approximate the rele-a crowded market and killed three civilians.  vant semantic properties automatically as features in (b) On November 25, a soldier's jeep veered into a  a supervised learning setting. In Section 5, we show  crowded market, causing three civilian deaths.  that these features improve on the existing state of  the art in automatic sentiment classification.  SecThis work was done while the first author was a student in the Department of Linguistics, University of Maryland.  1We refer readers not sharing this intuition to Section 3.  Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 503 511, Boulder, Colorado, June 2009. c  2009 Association for Computational Linguistics  tions 6 and 7 discuss related work and summarize.  participants causation, change of state, and others  are central not only in theoretical work on  lexLinguistic Motivation  ical semantics, but in computational approaches to  the lexicon, as well (e.g. (Pustejovsky, 1991; Dorr,  Verbal descriptions of an event often carry along  with them an underlying attitude toward what is  beThe approach we propose draws on two  influing described. By framing the same event in  differential discussions about grammatically relevant  seent ways, speakers or authors select some aspects  mantic properties in theoretical work on lexical  seof a perceived reality and make them more salient  mantics. First, Dowty (1991) characterizes  gramin a communicating text, in such a way as to  promatically relevant properties of a verb's arguments  (e.g. subject and object) via inferences that follow  pretation, moral evaluation, and/or treatment  recomfrom the meaning of the verb. For example,  expresmendation (Entman, 1993, p. 52). Clearly  lexisions like X murders Y or X interrogates Y entail cal choices can accomplish this kind of selection,  that subject X caused the event.3 Second, Hopper  e.g. choosing to describe a person as a terrorist and Thompson (1980) characterize semantic transi-rather than a freedom fighter, or referencing killer tivity using similar properties, connecting semantic whales rather than orcas.2  Syntactic choices can  features to morphosyntactic behavior across a wide  also have framing effects. For example, Ronald  Reavariety of languages.  gan's famous use of the passive construction,  MisBringing together Dowty with Hopper and  takes were made (in the context of the Iran-Contra  Thompson, we find 13 semantic properties  orscandal), is a classic example of framing or spin:  ganized into three groups, corresponding to the  used without a by-phrase, the passive avoids iden-three components of a canonical transitive clause,  tifying a causal agent and therefore sidesteps the is-expressed as X verb Y in English.4   Propersue of responsibility (Broder, 2007). A toddler who  ties associated with X involve volitional involve-says My toy broke instead of I broke my toy is  ment in the event or state, causation of the event,  employing the same linguistic strategy.  sentience/awareness and/or perception, causing a  Linguists have long studied syntactic variation  change of state in Y, kinesis or movement, and ex-in descriptions of the same event, often under the  istence independent of the event. Properties asso-general heading of syntactic diathesis alternations  ciated with the event or state conveyed by the verb (Levin, 1993; Levin and Hovav, 2005). This line  include aspectual features of telicity (a defined end-of research has established a set of semantic  proppoint) and punctuality (the latter of which may be  erties that are widely viewed as grammatically  relinversely related to a property known as  incremenevant in the sense that they enable generalizations  tal theme). Properties associated with Y include about syntactic packaging of meaning within (and  affectedness, change of state, (lack of) kinesis or  across) the world's languages.  For example, the  movement, and (lack of) existence independent of  verb break in English participates in the causative-the event.  inchoative alternation (causative event X broke Y  Now, observe that this set of semantic  propercan also be expressed without overt causation as Y  ties involves many of the questions that would  natbroke), but the verb climb does not ( X also causes urally help to shape one's opinion about the event  the event in X climbed Y, but that event cannot be described by veer in (1). Was anyone or anything expressed as Y climbed). These facts about partic-affected by what took place, and to what degree?  ipation in the alternation turn out to be connected  Did the event just happen or was it caused? Did the  with the fact that a breaking event entails a change of event reach a defined endpoint? Did participation in  state in Y but a climbing event does not. Grammatically relevant semantic properties of events and their 3Kako (2006) has verified that people make these inferences based on X's syntactic position even when a semantically empty 2Supporters of an endangered species listing in Puget Sound nonsense verb is used.  generally referred to the animals as orcas, while opponents gen-4We are deliberately sidestepping the choice of terminology erally said killer whales (Harden, 2006).  for X and Y, e.g. proto-Patient, theme, etc.  the event involve conscious thought or intent? Our  properties as well as Hopper and Thompson's  sehypothesis is that the syntactic aspects of framing , mantic transitivity components, responding via rat-as characterized by Entman, involve manipulation of  ings on a 1-to-7 scale. For example, the questions  these semantic properties, even when overt opinions  probing volition were: In this event, how likely are not being expressed. That is, we propose a con-is it that hsubjecti chose to be involved? , where  nection between syntactic choices and implicit  sentihsubjecti was the gunmen and the shooting, for 2(a-ment mediated by the very same semantic properties  b), respectively.6  that linguists have already identified as central when connecting surface expression to underlying mean-3.2  Sentiment ratings  ing more generally.  We used the materials above to  construct short, newspaper-like paragraphs, each one  accompanied by a headline version of the same  We validated the hypothesized connection between  syntactic descriptions used above.  For example,  implicit sentiment and grammatically relevant  segiven this paragraph:  mantic properties using psycholinguistic methods,  by varying the syntactic form of event descriptions,  A man has been charged for the suffocation of a  and showing that the semantic properties of  descripwoman early Tuesday morning. City police say  tions do indeed predict perceived sentiment.5  the man suffocated the 24-year-old woman using  a plastic garbage bag. The woman, who police say  Semantic property ratings  had a previous relationship with her attacker, was  Stimuli were constructed using 11  on her way to work when the incident happened.  verbs of killing, which are widely viewed as  protoBased on information provided by neighbors,  potypical for the semantic properties of interest here  lice were able to identify the suspect, who was  ar(Lemmens, 1998): X killed Y normally involves rested at gunpoint later the same day.  conscious, intentional causation by X of a kinetic  event that causes a (rather decisive and clearly  terthe three alternative headlines would be:  minated!) change of state in Y . The verbs comprise  two classes: the transitive class, involving  ex3(a) Man suffocates 24-year old woman  ternally caused change-of-state verbs ( kill,  slaugh(b) Suffocation kills 24-year-old woman  ter, assassinate, shoot, poison), and the ergative  (c) 24-year-old woman is suffocated  class ( strangle, smother, choke, drown, suffocate, starve), within which verbs are internally caused Some paragraphs were based on actual news  sto(McKoon and MacFarland, 2000) or otherwise  emries.7 In all paragraphs, there is an obvious  nomiphasize properties of the object. Variation of syntac-nal referent for both the perpetrator and the victim, tic description involved two forms: a transitive syn-it is clear that the victim dies, and the perpetrator tactic frame with a human agent as subject ( transi-in the scenario is responsible for the resulting death tive form , 2a), and a nominalization of the verb as  directly rather than indirectly (e.g. through  neglisubject and the verb kill as the predicate ( nominalized form , 2b).  6Standard experimental design methods were followed with respect to counterbalancing, block design, and distractor stim-2(a) The gunmen shot the opposition leader  uli; for example, no participant saw more than one of 2(a) or (b) The shooting killed the opposition leader  2(b), and all participants saw equal numbers of transitive and nominalized descriptions. The phrase In this event was repeated in each question and emphasized visually in order to encourage Participants and procedure.  participants to focus on the particular event described in the sen-unteer participants, all native speakers of English,  tence, rather than on the entities or events denoted in general.  were presented with event descriptions and asked to  7In those cases no proper names were used, to avoid any answer questions probing both Dowty's proto-role  inadvertent emotional reactions or legal issues, although the descriptions retained emotional impact because we wanted readers 5Full details and materials in Greene (2007).  to have some emotional basis with which to judge the headlines.  gence).8 The stem of the nominalization always  apering semantic properties individually, we find that  peared in the event description in either verbal or  volition has the strongest correlation with sympathy  (a negative correlation, with r = .776), followed  by sentience (r = .764) and kinesis/movement  Participants and procedure.  (r = .751). Although performing a multiple  reteers, all native speakers of English, were presented gression with all variables for this size dataset is im-with the paragraph-length descriptions and  accompossible, owing to overfitting (as a rule of thumb,  panying headlines. As a measure of sentiment,  par5 to 10 observed items are necessary per each  inticipants were asked to rate headlines on a 1-to-7  scale with respect to how sympathetic they perceive  verb, volition, and telicity as independent variables the headline to be toward the perpetrator. For exam-yields R = .88, R2 = .78 (p < .001). The value for ple, given the paragraph and one of the associated  adjusted R2, which explicitly takes into account the  headlines in (3), a participant would be asked to rate small number of observations, is 74.1.  How sympathetic or unsympathetic is this headline In summary, then, this ratings study confirms the  to the man? 9  influence of syntactic choices on perceptions of  imAnalysis and discussion  for the idea that this influence is mediated by gram-Unsurprisingly, but reassuringly, an analysis of the  sentiment ratings yields a significant effect of  syning that these accounted for approximately 75% of  tactic form on sympathy toward the perpetrator  the variance in implicit sentiment expressed by  al(F (2, 369) = 33.902, p < .001), using a mixed  ternative headlines describing the same event.  model ANOVA run with the headline form as fixed  effect. The transitive form of the headline yielded  Observable Approximation  significantly lower sympathy ratings than the  nominalized or passive forms in pairwise comparisons  Thus far, we have established a predictive  connec(both p < .001). We have thus confirmed  empirtion between syntactic choices and underlying or  imically that Reagan's Mistakes were made was a  plicit sentiment, mediated by grammatically relevant  wise choice of phrasing on his part.  semantic properties. In an ideal world, we could  harMore important, we are now in a position to  exness the predictive power of those properties by  usamine the relationship between syntactic forms and  ing volition, causation, telicity, etc. as features for perceived sentiment in more detail. We performed  regression or classification in sentiment prediction  regression analyses treating the 13 semantic  proptasks. Unfortunately, the properties are not directly erty ratings plus the identity of the verb as indepen-observable, and neither automatic annotators nor  ladent variables to predict sympathy rating as a  debeled training data currently exist.  pendent variable, using the 24 stimulus sentences  We therefore pursue a different strategy, which we  that bridged both collections of ratings.10  Considrefer to as observable proxies for underlying semantics (OPUS). It can be viewed as a middle ground 8An alert reader may observe that headlines with nominal-between relying on construction-level syntactic  disized subjects using the verb kill require some other nominaliza-tinctions (such as the 3-way transitive, nominalized  tion, so they don't say Killing kills victim . For these cases in the data, an appropriate nominalization drawn from the event subject, passive distinction in Section 3) and an-description was used (e.g., explosion).  notation of fine-grained semantic properties. The  9Again, standard experimental design methods were used key idea is to use observable grammatical relations,  with respect to block design, distractor stimuli, etc. The phrase drawn from the usages of terms determined to be  this headline was emphasized to stress that it is the headline relevant to a domain, as proxies for the underlying  being rated, not the story. A second question rating sympathy toward the victim was also asked in each case, as an additional semantic properties that gave rise to their syntactic distractor.  realization using those relations. Automatically  cre10These involved only the transitive and nominalized forms, because many of the questions were inapplicable to the passive pools, regression models were run over the mean values of each form. Since the two ratings studies involved different subject observation in the experimental data.  ated features based on those observable proxies are  The NOOBJ features can capture a habitual  readthen used in classification as described in Section 5.  ing, or in some cases a detransitivizing effect  asIn order to identify the set T of terms relevant  sociated with omission of the direct object (Olsen  to a particular document collection, we adopt the  The bold text in (5) yields  relative frequency ratio (Damerau, 1993), R(t) =  NOOBJ:kill as a feature.  , where Rt = ftc is the ratio of  reference  5(a) At the same time, we should never ignore the  term t's frequency in corpus c to the size Nc of that risks of allowing the inmate to kill again.  corpus. R(t) is a simple but effective comparison  of a term's prevalence in a particular collection as  In this case, omitting the direct object decreases the compared to a general reference corpus. We used  extent to which the killing event is interpreted as  the British National Corpus as the reference because  telic, and it eliminates the possibility of attributing it is both very large and representative of text from a change-of-state to a specific affected object (much  wide variety of domains and genres. The threshold  like Mistakes were made avoids attributing cause  of R(t) permitting membership in T is an  experito a specified subject), placing the phrasing at a  less semantically transitive point on the  transiOPUS features are defined in terms of syntactic  tivity continuum (Hopper and Thompson, 1980).  dependency relations involving terms in T . Given a  Some informants find a perceptible increase in  negset D of syntactic dependency relations, features are ative sentiment toward inmate when the sentence is of the form t : d or d : t, with d D, t T . That  phrased as in 5(b):  is, they are term-dependency pairs extracted from  5(b) At the same time, we should never ignore the  risks of allowing the inmate to kill someone  ing whether the term is the head or the dependent  in the dependency relation. In addition, we add two  construction-specific features: TRANS:v, which  repComputational Application  resents verb v in a canonical, syntactically transitive Having discussed linguistic motivation, empirical  usage, and NOOBJ:v, present when verb v is used  validation, and practical approximation of  semanwithout a direct object.11  tically relevant features, we now present two  studExample 4 shows source text (bolded clause in  ies demonstrating their value in sentiment classifica-4a), an illustrative subset of parser dependencies  tion. For the first study, we have constructed a new  (4b), and corresponding OPUS features (4c):  data set particularly well suited for testing our  approach, based on writing about the death penalty. In  4(a) Life Without Parole does not eliminate the risk  our second study, we make a direct comparison with  that the prisoner will murder a guard, a  visiprior state-of-the-art classification using the Bitter tor, or another inmate.  Lemons corpus of Lin et al. (2006).  Predicting Opinions of the Death Penalty  Corpus.  We constructed a new corpus for  experimentation on implicit sentiment by downloading  the contents of and anti-death-penalty Web  Intuitively the presence of TRANS:murder suggests  sites and manually checking, for a large subset,  the entire complex of semantic properties discussed  that the viewpoints expressed in documents were as  in Section 2, bringing together the impliciation of  expected. The collection, which we will refer to  on the part of prisoner  as the DP corpus, comprises documents from five  (as does nsubj:prisoner), affectedness and change of  pro-death-penalty sites and three anti-death-penalty  state on the part of guard (as does dobj:guard), and sites, and the corpus was engineered to have an even  so forth.  11We parsed English text using the Stanford parser.  We adopted a  superCondition  N features  SVM accuracy  vised classification approach based on word n-gram  features, using SVM classification in the WEKA  machine learning package. In initial exploration  using both unigrams and bigrams, and using both word  forms and stems, we found that performance did not  Table 1: Results for 4-fold site-wise cross-validation us-differ significantly, and chose stemmed bigrams for  ing the DP corpus  our baseline comparisons. In order to control for the difference in the number of features available to the Condition  N features  SVM accuracy  classifier in our comparisons, we use the N most  frequent stemmed bigrams as the baseline feature set  where N is matched to number of OPUS features  used in the comparison condition.  Table 2: DP corpus comparison for OPUS features based OPUS-kill verbs: OPUS features for manually  selected verbs.  We created OPUS features for 14  verbs those used in Section 3, plus murder, exe-anti2 for testing.13 As Table 1 shows, OPUS fea-cute, and stab and their nominalizations (including tures provide substantial and statistically significant both event and -er nominals, e.g. both killing and gains (p < .001).  killer) generating N = 1016 distinct features.  As a reality check to verify that it is  domainrelevant verb usages and the encoding of events they  OPUS features for  domainembody that truly drives improved classification, we  We created OPUS features for the  extracted OPUS features for the 14 most frequent  117 verbs for which the relative frequency ratio  verbs found in the DP Corpus that were not in our was greater than 1. This list includes many of the  manually created list of kill verbs, along with their kill verbs we used in Section 3, and introduces, nominalizations. Table 2 shows the results of a clas-among others, many transitive verbs describing acts  sification experiment using a single train-test split, of physical force (e.g. rape, rob, steal, beat, strike, training on 1062 documents from pro1, pro2, anti1, force, fight) as well as domain-relevant verbs such anti2 and testing on 84 test documents from the sig-as testify, convict, and sentence. Included verbs near nificantly smaller remaining sites.  the borderline included, for example, hold, watch, features for the most frequent kill verbs fails allow, and try. Extracting OPUS features for these to beat the baseline, establishing that it is not sim-verbs yielded N = 7552 features.  ply term frequency, the presence of particular  gramCross-validation at the document  matical relations, or a larger feature set that the  killlevel does not test what we are interested in, since  verb OPUS model was able to exploit, but rather the  a classifier might well learn to bucket documents  acproperties of event encodings involving the kill verbs cording to Web site, not according to or anti-themselves.  death-penalty sentiment. To avoid this difficulty, we 5.2  Predicting Points of View in the  performed site-wise cross-validation. We restricted  our attention to the two sites from each  perspective with the most documents, which we refer to as  In order to make a direct comparison here with prior  pro1, pro2, anti1, and anti2, yielding 4-fold cross-state-of-the-art work on sentiment analysis, we  revalidation. Each fold ftrain,test is defined as  conport on sentiment classification using OPUS features  taining all documents from one pro and one anti site  in experiments using a publicly available corpus  infor training, using all documents from the  remainvolving opposing perspectives, the Bitter Lemons  ing pro and anti sites for testing.  13Site (# of documents): pro1= clarkprosecutor.org (437), ple, fold f11,22 uses all documents from pro1 and pro2= prodeathpenalty.com (117), anti1= deathpenaltyinfo.org anti1 in training, and all documents from pro2 and (319), anti2= nodeathpenalty.org (212)  (hence BL) corpus introduced by Lin et al. (2006).  Corpus.  Classification Accuracy, BL Corpus  says posted at www.bitterlemons.org, which,  in the words of the site, present Israeli and  Palestinian viewpoints on prominent issues of concern .  As a corpus, it has a number of interesting  proper (Noun)  ties. First, its topic area is one of significant interest h  s  and considerable controversy, yet the general tenor  of the web site is one that eschews an overly shrill  or extreme style of writing. Second, the site is orga-0  nized in terms of issue-focused weekly editions that  include essays with contrasting viewpoints from the  Classification Accuracy, BL Corpus  site's two editors, plus two essays, also contrasting, Test Scenario 2 (GeneralFilter)  from guest editors. This creates a natural balance be-12  tween the two sides and across the subtopics being  discussed. The BL corpus as prepared by Lin et al.  contains 297 documents from each of the Israeli and  (Noun)  s  length.  distinguishing Israeli vs. Palestinian perspectives  Figure 1: Results on the Bitter Lemons corpus  using an SVM classifier, a naive Bayes classifier  NB-M using maximum a posteriori estimation, and a  naive Bayes classifier NB-B using full Bayesian  infrom guest authors. As in our site-wise cross  valiference. (Document perspectives are labeled clearly  dation for the DP corpus, this strategy ensures that  on the site.) We continue to use the WEKA SVM  what is being tested is classification according to the classifier, but compare our results to both their SVM  viewpoint, not author or topic.  and NB-B, since the latter achieved their best results.  Figure 1 (top) summarizes a large set of  experiments for Test Scenario 1, in which we varied the  OPUS features.  As in Section 5.1, we  experivalues of for verbs and nouns. Each experiment,  mented with OPUS features driven by  automatiusing a particular h (verbs), (nouns)i, corresponds  cally extracted lists of domain-relevant verbs. For  to a vertical strip on the x-axis. The points on that these experiments, we included domain-relevant  strip include the values for verbs and nouns,  meanouns, and we varied a threshold for the  relasured by the scale on the y-axis at the left of the  tive frequency ratio, including only terms for which  figure; the accuracy of Lin et al.'s SVM (88.22%  acR(t)) > . In addition, we introduced a  gencuracy, constant across all our variations); the accu-eral filter on OPUS features, eliminating syntactic  racy of Lin et al.'s NB-B classifier (93.46%  accudependency types that do not usefully reflect  semanracy, constant across all our variations), and the actically relevant properties: det, predet, preconj, prt, curacy of our SVM classifier using OPUS features,  which varies depending on the values. Across 423  Lin et al. describe two test  scenarexperiments, our average accuracy is 95.41%, with  ios. In the first, referred to as Test Scenario 1, they the best accuracy achieved being 97.64%. Our clas-trained on documents written by the site's guests,  sifier underperformed NB-B slightly, with  accuraand tested on documents from the site's editors. Test cies from 92.93% to 93.27%, in just 8 of the 423  Scenario 2 represents the reverse, training on  documents from the site editors and testing on documents  Figure 1 (bottom) provides a similar summary for  experiments in Test Scenario 2. The first thing to no-form, generated using a proprietary system.  Howtice is that accuracy for all methods is lower than for ever, his features are templatic in nature in that they Test Scenario 1. This is not terribly surprising: it is do not couple specific lexical entries with their logi-likely that training a classifier on the more uniform cal form. Hearst (1992) and Mulder et al. (2004) de-authorship of the editor documents builds a model  scribe systems that make use of argument structure  that generalizes less well to the more diverse  aufeatures coupled with lexical information, though  thorship of the guest documents (though accuracy  is still quite high). In addition, the editor-authored mental results.  In terms of computational experimentation, work  ing of 7,899 sentences, while the guest documents  by Thomas et al.  (2006), predicting yes and no  have a total of 11,033 sentences, a 28% difference.  votes in corpus of United States Congressional floor  In scenario 2, we obtain average accuracy across  exdebate speeches, is quite relevant. They combined  periments of 83.12%, with a maximum of 85.86%,  SVM classification with a min-cut model on graphs  in this case outperforming the 81.48% obtained by  in order to exploit both direct textual evidence and  Lin's SVM fairly consistently, and in some cases  apconstraints suggested by the structure of  Congresproaching or matching NB-B at 85.85%.  sional debates, e.g. the fact that the same  individual rarely gives one speech in favor of a bill and an-6  Related Work  other opposing it. We have extend their method to  use OPUS features in the SVM and obtained  signifiPang and Lee's (2008) excellent monograph  procant improvements over their classification accuracy  vides a thorough, well organized, and relatively  re(Greene, 2007; Greene and Resnik, in preparation).  cent description of computational work on  sentiment, opinion, and subjectivity analysis.  The problem of classifying underlying sentiment  in statements that are not overtly subjective is less In this paper we have introduced an approach to  studied within the NLP literature, but it has received implicit sentiment motivated by theoretical work in  some attention in other fields. These include, for ex-lexical semantics, presenting evidence for the role of ample, research on content analysis in journalism,  media studies, and political economy (Gentzkow  This research is, to our knowledge, the first to draw and Shapiro, 2006a; Gentzkow and Shapiro, 2006b;  an explicit and empirically supported connection  beGroseclose and Milyo, 2005; Fader et al., 2007);  autween theoretically motivated work in lexical  setomatic identification of customer attitudes for busi-mantics and readers' perception of sentiment. In  adness e-mail routing (Durbin et al., 2003). And, of  dition, we have reported positive sentiment  classificourse, the study of perceptions in politics and  mecation results within a standard supervised learning  dia bears a strong family resemblance to real-world  setting, employing a practical first approximation to marketing problems involving reputation manage-those semantic properties, including positive results ment and business intelligence (Glance et al., 2005).  in a direct comparison with the previous state of the art.  Within computational linguistics, what we call  Because we computed OPUS features for  opinimplicit sentiment was introduced as a topic of study ionated as well as non-evaluative language in our  by Lin et al. (2006) under the rubric of identifying  corpora, obtaining overall positive results, we  beperspective, though similar work had begun earlier  lieve these features may also improve conventional  in the realm of political science (e.g. (Laver et al., opinion labeling for subjective text. This will be in-2003)). Other recent work focusing on the notion of  vestigated in future work.  perspective or ideology has been reported by Martin  and Vanberg (2008) and Mullen and Malouf (2008).  Acknowledgments  Among prior authors, Gamon's (2004) research is  perhaps closest to the work described here, in that  The authors gratefully acknowledge useful  discushe uses some features based on a sentence's logical  sions with Don Hindle and Chip Denman.  Paul Hopper and Sandra Thompson. 1980. Transitivity  in Grammar and Discourse. Language, 56:251 295.  John Broder. 2007. Familiar fallback for officials: 'mis-E. Kako. 2006. Thematic role properties of subjects and takes were made'. New York Times. March 14.  objects. Cognition, 101(1):1 42, August.  F. J. Damerau. 1993. Generating and evaluating domain-Michael Laver, Kenneth Benoit, and John Garry. 2003.  oriented multi-word terms from texts.  Information  Extracting policy positions from political texts using Processing and Management, 29:433 447.  American Political Science Review,  Hoa Trang Dang, Karin Kipper, Martha Palmer, and  M. Lemmens. 1998. Lexical perspectives on transitivity lar Sense Extensions Based on Intersective Levin  and ergativity. John Benjamins.  Classes. In ACL/COLING 98, pages 293 299, Mon-Beth Levin and Malka Rappaport Hovav. 2005.  Argument Realization. Research Surveys in Linguistics.  Bonnie J. Dorr. 1993. Machine Translation: A View from Cambridge University Press, New York.  the Lexicon. The MIT Press, Cambridge, MA.  Beth Levin.  David Dowty. 1991. Thematic Proto-Roles and  Argunations: A Preliminary Investigation. University of ment Selection. Language, 67:547 619.  Chicago Press, Chicago, IL.  tem for affective rating of texts. In Proc. 3rd Workshop Alexander Hauptmann. 2006. Which side are you on?  on Operational Text Classification, KDD-2003.  identifying perspectives at the document and sentence Robert M. Entman. 1993. Framing: Toward clarification levels. In Proceedings of the Conference on Natural of a fractured paradigm. Journal of Communication, Language Learning (CoNLL).  Anthony Fader, Dragomir R. Radev, Michael H. Crespin, bust transformation procedure for interpreting political Burt L. Monroe, Kevin M. Quinn, and Michael Co-text. Political Analysis, 16(1):93 100.  MavenRank: Identifying influential  G. McKoon and T. MacFarland. 2000. Externally and  members of the US Senate using lexical centrality. In internally caused change of state verbs. Language, Proceedings of the Conference on Empirical Methods pages 833 858.  in Natural Language Processing (EMNLP).  Michael Gamon. 2004. Sentiment classification on  cus2004. A lexical grammatical implementation of affect.  tomer feedback data: noisy data, large feature vectors, and the role of linguistic analysis. In Proc. COLING.  In Proc. TSD-04, Lecture notes in computer science 3206, pages 171 178). Springer-Verlag.  M. Gentzkow and J. Shapiro. 2006a. Media bias and  reputation. Journal of Political Economy, 114:280  Tony Mullen and Robert Malouf. 2008. Taking sides:  User classification for informal online political discourse. Internet Research, 18:177 190.  M. Gentzkow and J. Shapiro.  What drives  Evidence from U.S. newspapers.  Mari Broman Olsen and Philip Resnik. 1997. Implicit  Object Constructions and the (In)transitivity  Continuum. In 33rd Proceedings of the Chicago Linguistic Natalie Glance, Matthew Hurst, Kamal Nigam, Matthew  Society, pages 327 336.  discussion. In Proc. KDD'05, pages 419 428, New sentiment analysis. Foundations and Trends in Infor-York, NY, USA. ACM.  Stephan Greene. 2007. Spin: Lexical Semantics, Tran-James Pustejovsky.  The Generative Lexicon.  sitivity, and the Identification of Implicit Sentiment.  Computational Linguistics, 17(4):409 441.  Ph.D. thesis, University of Maryland.  Philip J. Stone. 1966. The General Inquirer: A Com-T. Groseclose and J. Milyo. 2005. A measure of media  puter Approach to Content Analysis. The MIT Press.  bias. The Quarterly Journal of Economics, 120:1191  Matt Thomas, Bo Pang, and Lillian Lee.  out the vote:  Determining support or opposition  B. Harden. 2006. On Puget Sound, It's Orca vs. Inc. The from Congressional floor-debate transcripts. In Proc.  Washington Post. July 26, page A3.  Marti Hearst. 1992. Direction-based text interpretation Zhibao Wu and Martha Palmer. 1994. Verb Semantics  as an information access refinement. In Paul Jacobs,  and Lexical Selection. In Proc. ACL, pages 133 138, editor, Text-Based Intelligent Systems, pages 257 274.  Las Cruces, New Mexico.  Lawrence Erlbaum Associates. 