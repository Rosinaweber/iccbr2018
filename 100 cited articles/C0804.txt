 Learning to Shift the Polarity of Words for Sentiment Classification Daisuke Ikeda  Department of Computational Intelligence and Systems Science, Tokyo Institute of Technology ikeda@lr.pi.titech.ac.jp  Department of Computer Science, University of Illinois at Urbana-Champaign ratinov2@uiuc.edu  Precision and Intelligence Laboratory, Tokyo Institute of Technology  because this task is fundamental and has a wide  apWe propose a machine learning based  plicability in sentiment analysis. For example, we  method of sentiment classification of  sencan retrieve individuals' opinions that are related to  tences using word-level polarity. The  polaria product and can find whether they have the positive  ties of words in a sentence are not always the  attitude to the product.  same as that of the sentence, because there  There has been much work on the identification of  can be polarity-shifters such as negation  exsentiment polarity of words. For instance,  beautiThe proposed method models  ful is positively oriented, while dirty is negatively the polarity-shifters.  oriented. We use the term sentiment words to refer trained in two different ways: word-wise and  to those words that are listed in a predefined  polarsentence-wise learning.  In sentence-wise  ity dictionary. Sentiment words are a basic resource  learning, the model can be trained so that the  for sentiment analysis and thus believed to have a  prediction of sentence polarities should be  great potential for applications. However, it is still  accurate. The model can also be combined  an open problem how we can effectively use  senwith features used in previous work such  timent words to improve performance of sentiment  as bag-of-words and n-grams. We  empiriclassification of sentences or documents.  cally show that our method almost always  The simplest way for that purpose would be the  improves the performance of sentiment  clasmajority voting by the number of positive words and  sification of sentences especially when we  the number of negative words in the given sentence.  have only small amount of training data.  However, the polarities of words in a sentence are  not always the same as that of the sentence,  beIntroduction  cause there can be polarity-shifters such as  negaDue to the recent popularity of the internet,  individtion expressions. This inconsistency of word-level  uals have been able to provide various information  polarity and sentence-level polarity often causes  erto the public easily and actively (e.g., by weblogs  rors in classification by the simple majority voting  or online bulletin boards). The information often  inmethod. A manual list of polarity-shifters, which  cludes opinions or sentiments on a variety of things  are the words that can shift the sentiment polarity of  such as new products. A huge amount of work has  another word (e.g., negations), has been suggested.  been devoted to analysis of the information, which  However, it has limitations due to the diversity of  is called sentiment analysis. The sentiment analysis expressions.  has been done at different levels including words,  Therefore, we propose a machine learning based  sentences, and documents. Among them, we focus  method that models the polarity-shifters. The model  on the sentiment classification of sentences, the task  can be trained in two different ways: word-wise  and sentence-wise.  While the word-wise  learnand sentiment for document-level, and reported that  ing focuses on the prediction of polarity shifts, the  their model obtained higher accuracy than the  stansentence-wise learning focuses more on the  prediction of sentence polarities. The model can also be  Although these pieces of work aim to predict not  combined with features used in previous work such  as bag-of-words, n-grams and dependency trees. We  concepts are similar to ours. However, all the above  empirically show that our method almost always  immethods require annotated corpora for all levels,  proves the performance of sentiment classification  such as both subjectivity for sentences and  sentiof sentences especially when we have only small  ments for documents, which are fairly expensive to  amount of training data.  obtain. Although we also focus on two different  layThe rest of the paper is organized as follows. In  Section 2, we briefly present the related work. In  beled data. What we require is just sentence-level  Section 3, we discuss well-known methods that use  labeled training data and a polarity dictionary of  senword-level polarities and describe our motivation. In  Section 4, we describe our proposed model, how to  Simple Voting by Sentiment Words  train the model, and how to classify sentences using  the model. We present our experiments and results  One of the simplest ways to classify sentences  usin Section 5. Finally in Section 6, we conclude our  ing word-level polarities would be a majority voting,  work and mention possible future work.  where the occurrences of positive words and those  of negative words in the given sentence are counted  Related Work  and compared with each other. However, this  majority voting method has several weaknesses. First, the  Supervised machine learning methods including  majority voting cannot take into account at all the  Support Vector Machines (SVM) are often used in  phenomenon that the word-level polarity is not  alsentiment analysis and shown to be very promising  ways the same as the polarity of the sentence.  Consider the following example:  Matsumoto, 2004; Mullen and Collier, 2004;  GaI have not had any distortion problems  mon, 2004). One of the advantages of these  methwith this phone and am more pleased with  ods is that a wide variety of features such as  dependency trees and sequences of words can easily be  inthis phone than any I've used before.  corporated (Matsumoto et al., 2005; Kudo and  Matwhere negative words are underlined and positive  sumoto, 2004; Pang et al., 2002). Our attempt in this  words are double-underlined. The example sentence  paper is not to use the information included in those  has the positive polarity, though it locally contains  substructures of sentences, but to use the word-level  negative words. The majority voting would  misclaspolarities, which is a resource usually at hand. Thus  sify it because of the two negative words.  our work is an instantiation of the idea to use a  reThis kind of inconsistency between sentence-level  source on one linguistic layer (e.g., word level) to  polarity and word-level polarity often occurs and  the analysis of another layer (sentence level).  causes errors in the majority voting. The reason  There have been some pieces of work which  fois that the majority voting cannot take into  accus on multiple levels in text. Mao and Lebanon  count negation expressions or adversative  conjunc(2006) proposed a method that captures local  sentitions, e.g., I have not had any ... in the example  ment flow in documents using isotonic conditional  above. Therefore, taking such polarity-shifting into  random fields. Pang and Lee (2004) proposed to  account is important for classification of sentences  eliminate objective sentences before the sentiment  using a polarity dictionary. To circumvent this  probclassification of documents. McDonald et al. (2007)  lem, Kennedy and Inkpen (2006) and Hu and Liu  proposed a model for classifying sentences and  doc(2004) proposed to use a manually-constructed list  uments simultaneously.  They experimented with  of polarity-shifters. However, it has limitations due  joint classification of subjectivity for sentence-level, to the diversity of expressions.  Another weakness of the majority voting is that and problems , whose polarities are different from  it cannot be easily combined with existing methods  that of the sentence, as belonging to the  polaritythat use the n-gram model or tree structures of the  shifted class. On the contrary, we regard pleased , sentence as features. The method we propose here  whose polarity is the same as that of the sentence, as  can easily be combined with existing methods and  not belonging to polarity-shifted class.  show better performance.  We can use the majority voting by those  (possibly polarity-shifted) sentiment words. Specifically,  Word-Level Polarity-Shifting Model  we first classify each sentiment word in the sentence  We assume that when the polarity of a word is  difaccording to whether the polarity is shifted or not.  ferent from the polarity of the sentence, the polarity  Then we use the majority voting to determine the  of the word is shifted by its context to adapt to the  polarity of the sentence. If the first classifier classi-polarity of the sentence. Capturing such  polarityfies a positive word into the polarity-shifted class, shifts will improve the classification performance of  we treat the word as a negative one. We expect that  the majority voting classifier as well as of more  sothe majority voting with polarity-shifting will  outphisticated classifiers.  perform the simple majority voting without  polarityIn this paper, we propose a word polarity-shifting  shifting. We actually use the weighted majority  votmodel to capture such phenomena. This model is  ing, where the polarity-shifting score for each  sentia kind of binary classification model which  determent word is used as the weight of the vote by the  mines whether the polarity is shifted by its context.  word. We expect that the score works as a  confiThe model assigns a score s  shif t( x, S) to the  sentiment word x in the sentence S. If the polarity of x We can formulate this method as follows. Here,  is shifted in S, s  and P are respectively defined as the sets of neg-shif t( x, S) > 0. If the polarity of x is not shifted in S, s  ative sentiment words and positive sentiment words.  shif t( x, S) 0. Let w be a parameter vector of the model and be a pre-defined For instance, x N means that x is a negative word.  feature function. Function s  We also write x S to express that the word x oc-shif t is defined as  curs in S.  s  First, let us define two scores, score  p( S) and  scoren( S), for the input sentence S. The scorep( S) Since this model is a linear discriminative model,  and the scoren( S) respectively represent the num-there are well-known algorithms to estimate the  paber of votes for S being positive and the number rameters of the model.  of votes for S being negative.  If scorep( S) >  Usually, such models are trained with each  occurscoren( S), we regard the sentence S as having the rence of words as one instance (word-wise learning).  positive polarity, otherwise negative. We suppose  However, we can train our model more effectively  that the following relations hold for the scores:  with each sentence being one instance  (sentencewise learning). In this section, we describe how to  train our model in two different ways and how to  sshift( x, S) +  sshift( x, S) ,  apply the model to a sentence classification.  Word-wise Learning  sshift( x, S) +  sshift( x, S) .  In this learning method, we train the word-level  polarity-shift model with each occurrence of  senWhen either a polarity-unchanged positive word  timent words being an instance.  Training  exam( sshift( x, S) 0) or a polarity-shifted negative ples are automatically extracted by finding sentiment  word occurs in the sentence S, scorep( S) increases.  words in labeled sentences. In the example of  SecWe can easily obtain the following relation between  tion 3, for instance, both negative words (  distortwo scores:  tion or problems ) and a positive word ( pleased )  appear in a positive sentence. We regard distortion  scorep( S) = scoren( S) .  Since, according to this relation, scorep( S) > the word-level polarity.  On the other hand,  sevscoren( S) is equivalent to scorep( S) > 0, we use eral methods that use another set of features, for ex-only scorep( S) for the rest of this paper.  ample, bag-of-words, n-grams or dependency trees,  were proposed for the sentence or document  classiSentence-wise Learning  fication tasks. We propose to combine our method  The equation (2) can be rewritten as  with existing methods.  We refer to it as hybrid  In recent work, discriminative models including  SVM are often used with many different features.  w ( x, S) I( x) These methods are generally represented as  where X indicates the target of classification, for ex-x S  ample, a sentence or a document. If score0p( X) > 0, where I( x) is the function defined as follows: X is classified into the target class. 0( X) is a  feature function. When the method uses the  bag-ofwords model, 0 maps X to a vector with each ele-I( x) =  if x P ,  ment corresponding to a word.  otherwise.  Here, we define new score function scorecomb( S) This score  as a linear combination of score  p( S) can also be seen as a linear discrimi-p( S), the score  native model and the parameters of the model can be  function  of  learning,  and  estimated directly (i.e., without carrying out  wordscore0p( S), the score function of an existing wise learning). Each labeled sentence in a corpus  method. Using this, we can write the function as  can be used as a training instance for the model.  In this method, the model is learned so that the  predictive ability for sentence classification is  optiw ( x, S) I( x) + (1 ) w0 0( S) mized, instead of the predictive ability for polarity-x S  shifting. Therefore, this model can remain  indeciwcomb  sive on the classification of word instances that have  little contextual evidence about whether  polarityshifting occurs or not. The model can rely more  heavily on word instances that have much evidence.  Note that hi indicates the concatenation of two vec-In contrast, the word-wise learning trains the  tors, wcomb is defined as hw, w0i and is a param-model with all the sentiment words appearing in a  eter which controls the influence of the word-level  corpus. It is assumed here that all the sentiment  polarity-shifting model. This model is also a  diswords have relations with the sentence-level  polarcriminative model and we can estimate the  paramity, and that we can always find the evidence of the  eters with a variety of algorithms including SVMs.  phenomena that the polarity of a word is different  We can incorporate additional information like  bagfrom that of a sentence. Obviously, this  assumpof-words or dependency trees by 0( S).  tion is not always correct. As a result, the word-wise  Discussions on the Proposed Model  learning sometimes puts a large weight on a context  word that is irrelevant to the polarity-shifting. This  Features such as n-grams or dependency trees can  might degrade the performance of sentence  classifialso capture some negations or polarity-shifters. For  cation as well as of polarity-shifting.  example, although satisfy is positive, the bigram  model will learn not satisfy as a feature  correlated with negative polarity if it appears in the train-Both methods described in Sections 4.1 and 4.2  ing data. However, the bigram model cannot  generare to predict the sentence-level polarity only with  alize the learned knowledge to other features such  classifiers take into consideration the combination Table 1: Statistics of the corpus  of features.  # of Labeled Sentences  # of Sentiment Words  Inconsistent Words  We used two datasets, customer reviews 1 (Hu  and Liu, 2004) and movie reviews 2 (Pang and  Lee, 2005) to evaluate sentiment classification of  as not great or not disappoint . On the other  Both of these two datasets are often  hand, our polarity-shifter model learns that the word  used for evaluation in sentiment analysis researches.  not causes polarity-shifts. Therefore, even if there  The number of examples and other statistics of the  was no not disappoint in training data, our model  datasets are shown in Table 1.  can determine that not disappoint has correlation  Our method cannot be applied to sentences which  with positive class, because the dictionary contains  contain no sentiment words. We therefore  elimi disappoint as a negative word. For this reason,  nated such sentences from the datasets. Available  the polarity-shifting model can be learned even with  in Table 1 means the number of examples to which  our method can be applied.  Sentiment Words  What we can obtain from the proposed method is  shows the number of sentiment words that are found  not only a set of polarity-shifters. We can also obtain in the given sentences. Please remember that senti-the weight vector w, which indicates the strength of ment words are defined as those words that are listed  each polarity-shifter and is learned so that the  prein a predefined polarity dictionary in this paper.  Indictive ability of sentence classification is optimized consistent Words shows the number of the words  especially in the sentence-wise learning. It is  imposwhose polarities conflicted with the polarity of the  sible to manually determine such weights for  numerous features.  We performed 5-fold cross-validation and used  It is also worth noting that all the models proposed  the classification accuracy as the evaluation  meain this paper can be represented as a kernel function.  sure. We extracted sentiment words from General  For example, the hybrid model can be seen as the  Inquirer (Stone et al., 1996) and constructed a  polarity dictionary. After some preprocessing, the  dictionary contains 2,084 positive words and 2,685  negative words.  Here, K means the kernel function between  We employed the Max Margin Online Learning  words and K0 means the kernel function  beAlgorithms for parameter estimation of the model  respectively.  In preliminary experiments, this algorithm yielded  an instance of convolution kernels, which was  equal or better results compared to SVMs. As the  proposed by Haussler (1999). Convolution kernels  feature representation, ( x, S), of polarity-shifting are a general class of kernel functions which are  model, we used the local context of three words  calculated on the basis of kernels between  substructo the left and right of the target sentiment word.  tures of inputs. Our proposed kernel treats sentences  We used the polynomial kernel of degree 2 for  as input, and treats sentiment words as substructures  polarity-shifting model and the linear kernel for  othof sentences. We can use high degree polynomial  kernels as both K which is a kernel between sub-http://www.cs.uic.edu/ liub/FBS/FBS.  structures, i.e. sentiment words, of sentences, and  K0 which is a kernel between sentences to make the movie-review-data/  Table 2 shows the results of these experiments.  Table 2: Experimental results of the sentence  classiHybrid 3gram, which corresponds to the proposed  fication  method, obtained the best accuracy on customer  recustomer  the proposed method did not outperform 3gram. In  Section 5.4, we will discuss this result in details.  Comparing word-wise to simple-voting, the  accuracy increased by about 7 points. This means that  Simple-Voting  the polarity-shifting model can capture the  polarityshifts and it is an important factor for sentiment clas-Word-wise  sification. In addition, we can see the effectiveness  Sentence-wise  of sentence-wise, by comparing it to word-wise in  Opt in Table 2 shows the results of hybrid  models with optimal and combination of models. The Opt  optimal results of hybrid models achieved the best  accuracy on both datasets.  We show some dominating polarity-shifters  obers, and feature vectors are normalized to 1. In  hytained through learning. We obtained many  negabrid models, the feature vectors,  and 0( S) are normalized respectively.  might, would, may), prepositions (e.g., without,  despite), comma with a conjunction (e.g., , but as  Comparison of the Methods  in the case is strong and stylish, but lacks a  winWe compared the following methods:  dow ), and idiomatic expressions (e.g., hard resist  as in it is hard to resist , and real snooze ).  Baseline classifies all sentences as positive.  Effect of Training Data Size  BoW uses unigram features. 2gram uses uni-When we have a large amount of training data, the  ngram classifier can learn well whether each n-gram  grams, and 3grams.  tends to appear in the positive class or the negative  Simple-Voting is the most simple majority vot-class. However, when we have only a small amount  ing with word-level polarity (Section 3).  of training data, the n-gram classifier cannot capture  such tendency. Therefore the external knowledge,  Negation Voting proposed by Hu and  such as word-level polarity, could be more valuable  Liu (2004) is the majority voting that takes  information for classification. Thus it is expected  negations into account.  As negations, we  that the sentence-wise model and the hybrid model  employed not, no, yet, never, none, nobody, will outperform n-gram classifier which does not  nowhere, nothing, and neither, which are taken take word-level polarity into account, more largely  from (Polanyi and Zaenen, 2004; Kennedy and  with few training data.  Inkpen, 2006; Hu and Liu, 2004) (Section 3).  To verify this conjecture, we conducted  experiments by changing the number of the training  exWord-wise was described in Section 4.1.  amples, i.e., the labeled sentences. We evaluated  Sentence-wise was described in Section 4.2.  three models: sentence-wise, 3gram model and  hybrid 3gram on both customer review and movie  reare combinations of sentence-wise model and  Figures 1 and 2 show the results on customer  rerespectively BoW, 2gram and 3gram (Section view and movie review respectively. When the size  of the training data is small, sentence-wise  outperthat is based both on the model and on existing  classifiers. We evaluated our method and reported that  the proposed method almost always improved the  accuracy of sentence classification compared with  other simpler methods. The improvement was more  significant when we have only a limited amount of  For future work, we plan to explore new feature  sets appropriate for our model. The feature sets we  used for evaluation in this paper are not  necessarily optimal and we can expect a better performance  by exploring appropriate features. For example,  deFigure 1: Experimental results on customer review  pendency relations between words or appearances of  conjunctions will be useful. The position of a word  in the given sentence is also an important factor in  sentiment analysis (Taboada and Grieve, 2004).  Furthermore, we should directly take into account the  fact that some words do not affect the polarity of the  sentence, though the proposed method tackled this  problem indirectly. We cannot avoid this problem  to use word-level polarity more effectively. Lastly,  since we proposed a method for the sentence-level  sentiment prediction, our next step is to extend the  method to the document-level sentiment prediction.  Acknowledgement  This research was supported in part by Overseas  AdFigure 2: Experimental results on movie review  vanced Educational Research Practice Support  Program by Ministry of Education, Culture, Sports,  Science and Technology.  forms 3gram on both datasets. We can also see that  the advantage of sentence-wise becomes smaller as  the amount of training data increases, and that the  hybrid 3gram model almost always achieved the best  accuracy among the three models. Similar behaviour  Shalev-Shwartz, and Yoram Singer. Online  PassiveAggressive Algorithms. In Journal of Machine  Learnwas observed when we ran the same experiments  ing Research, Vol.7, Mar, pp.551 585, 2006.  with 2gram or BoW model. From these results, we  can conclude that, as we expected above, the  wordMichael Gamon. Sentiment classification on customer  feedback data: noisy data, large feature vectors, and  level polarity is especially effective when we have  the role of linguistic analysis. In Proceedings of the only a limited amount of training data, and that the  20th International Conference on Computational  Linhybrid model can combine two models effectively.  Conclusion  tures, Technical Report UCS-CRL-99-10, University  of California in Santa Cruz, 1999.  We proposed a model that captures the  polarityMinqing Hu and Bing Liu. Mining Opinion Features  shifting of sentiment words in sentences. We also  in Customer Reviews. In Proceedings of Nineteeth  presented two different learning methods for the  National Conference on Artificial Intellgience (AAAI-model and proposed an augmented hybrid classifier  2004) , pp.755 560, San Jose, USA, July 2004.  Alistair Kennedy and Diana Inkpen. Sentiment Classi-Philip J. Stone, Dexter C. Dunphy, Marshall S. Smith,  fication of Movie and Product Reviews Using  Conand Daniel M. Ogilvie. The General Inquirer: A  Comtextual Valence Shifters. In Workshop on the Analysis puter Approach to Content Analysis. The MIT Press, of Formal and Informal Information Exchange during  Negotiations (FINEXIN-2005), 2005.  Maite Taboada and Jack Grieve. Analyzing Appraisal  Automatically. In AAAI Spring Symposium on  Explorfor Classification of Semi-Structured Text. In Proceeding Attitude and Affect in Text: Theories and Applica-ings of the Conference on Empirical Methods in  Nattions (AAAI-EAAT2004), pp.158 161, 2004.  ural Language Processing (EMNLP-2004), pp.301  Yu Mao and Guy Lebanon. Isotonic Conditional  Random Fields and Local Sentiment Flow. In Proceedings of the Newral Information Processing Systems (NIPS-2006), pp.961 968, 2006.  Okumura. Sentiment Classification using Word  SubSequences and Dependency Sub-Trees. In  Proceedings of the 9th Pacific-Asia International Conference on Knowledge Discovery and Data Mining (PAKDD-2005), pp.301 310 , 2005.  Ryan McDonald, Kerry Hannan, Tyler Neylon, Mike  Wells, and Jeff Reynar. Structured Models for  Fine-toCoarse Sentiment Analysis. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL-2007), pp.432 439, 2007.  Tony Mullen and Nigel Collier. Sentiment analysis  using support vector machines with diverse  information sources. In Proceedings of the Conference on  Empirical Methods in Natural Language Processing  Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.  Thumbs up? Sentiment Classification using Machine  Learning Techniques. In Proceedings of the  Conference on Empirical Methods in Natural Language  Processing (EMNLP-2002), pp.76 86, 2002.  Bo Pang and Lillian Lee. A Sentimental Education:  Sentiment Analysis Using Subjectivity Summarization  Based on Minimum Cuts. In Proceedings of the 42th  Annual Meeting of the Association for Computational Linguistics (ACL-2004), pp.271 278, 2004.  Bo Pang and Lillian Lee. Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL-2005), pp.115 124, 2005.  Shifters. In AAAI Spring Symposium on Exploring  Attitude and Affect in Text: Theories and Applications (AAAI-EAAT2004), 2004. 