 Automatic Detection of Text Genre  Xerox Palo Alto Research Center  Department of Linguistics  3333 Coyote Hill Road  Stanford University  Stanford CA 94305-2150 USA  genres than in formal ones). In information retrieval,  genre classification could enable users to sort search  As the text databases available to users  beresults according to their immediate interests.  People who go into a bookstore or library are not usually  becomes increasingly important for  comlooking simply for information about a particular  putational linguistics as a complement to  topic, but rather have requirements of genre as well:  topical and structural principles of  classifithey are looking for scholarly articles about  hypnocation. We propose a theory of genres as  tism, novels about the French Revolution, editorials  bundles of facets, which correlate with  varabout the supercollider, and so forth.  ious surface cues, and argue that genre  deIf genre classification is so useful, why hasn't it  figtection based on surface cues is as  successured much in computational linguistics before now?  ful as detection based on deeper structural  One important reason is that, up to now, the  digitized corpora and collections which are the subject  of much CL research have been for the most part  Introduction  generically homogeneous (i.e., collections of scientific  abstracts or newspaper articles, encyclopedias, and  Computational linguists have been concerned for the  so on), so that the problem of genre identification  most part with two aspects of texts: their structure  could be set aside. To a large extent, the problems  and their content. That is, we consider texts on  of genre classification don't become salient until we  the one hand as formal objects, and on the other  are confronted with large and heterogeneous search  as symbols with semantic or referential values. In  domains like the World-Wide Web.  this paper we want to consider texts from the point  Another reason for the neglect of genre, though, is  of view of genre; that is, according to the various  functional roles they play.  that it can be a difficult notion to get a conceptual  Genre is necessarily a heterogeneous classificatory  handle on, particularly in contrast with properties of  principle, which is based among other things on the  structure or topicality, which for all their  complicaway a text was created, the way it is distributed,  tions involve well-explored territory. In order to do  the register of language it uses, and the kind of  ausystematic work on automatic genre classification,  dience it is addressed to. For all its complexity, this  by contrast, we require the answers to some basic  attribute can be extremely important for many of  theoretical and methodological questions. Is genre a  the core problems that computational linguists are  single property or attribute that can be neatly laid  concerned with. Parsing accuracy could be increased  out in some hierarchical structure? Or are we really  by taking genre into account (for example, certain  talking about a multidimensional space of properties  object-less constructions occur only in recipes in  Enthat have little more in common than that they are  glish). Similarly for POS-tagging (the frequency of  more or less orthogonal to topicality? And once we  uses of trend as a verb in the Journal of Commerce have the theoretical prerequisites in place, we have  is 35 times higher than in Sociological Abstracts). In to ask whether genre can be reliably identified by  means of computationally tractable cues.  restricted to texts of a particular style, such as  colIn a broad sense, the word genre is merely a  loquial or formal (for example the word pretty is far literary substitute for kind of text, and discus-more likely to have the meaning rather in informal  sions of literary classification stretch back to  Aristotle.  We will use the term genre here to  rewhen we are searching for public reactions to the  fer to any widely recognized class of texts defined  supercollider, where newspaper columns, editorials,  by some common communicative purpose or other  and letters to the editor will be of roughly equal  infunctional traits, provided the function is connected  terest. For other purposes we will want to stress  to some formal cues or commonalities and that the  narrativity, for example in looking for accounts of  class is extensible. For example an editorial is a  the storming of the Bastille in either novels or  hisshortish prose argument expressing an opinion on  tories.  some matter of immediate public concern, typically  Secondly, we can extend our classification to  genwritten in an impersonal and relatively formal style  res not previously encountered. Suppose that we  in which the author is denoted by the pronoun we.  are presented with the unfamiliar category  finanBut we would probably not use the term genre  cial analysts' report. By analyzing genres as  to describe merely the class of texts that have the  bundles of facets, we can categorize this genre as  objective of persuading someone to do something,  institutional (because of the use of we as in edi-since that class which would include editorials,  torials and annual reports) and as non-suasive or  sermons, prayers, advertisements, and so forth  non-argumentative (because of the low incidence of  has no distinguishing formal properties. At the other  question marks, among other things), whereas a  sysend of the scale, we would probably not use genre  tem trained on genres as atomic entities would not  to describe the class of sermons by John Donne, since  be able to make sense of an unfamiliar category.  that class, while it has distinctive formal  characteristics, is not extensible. Nothing hangs in the balance  Previous Work on Genre Identification  on this definition, but it seems to accord reasonably  well with ordinary usage.  The first linguistic research on genre that uses  quanThe traditional literature on genre is rich with  titative methods is that of Biber (1986; 1988; 1992; classificatory schemes and systems, some of which  1995), which draws on work on stylistic analysis, might in retrospect be analyzed as simple at-readability indexing, and differences between  spotribute systems.  (For general discussions of  literary theories of genre, see, e.g., Butcher (1932), several textual dimensions , which are constructed  Dubrow (1982), Fowler (1982), Frye (1957), Her-by applying factor analysis to a set of linguistic  synnadi (1972), Hobbes (1908), Staiger (1959), and tactic and lexical features. Those dimensions are  Todorov (1978).) We will refer here to the attributes then characterized in terms such as informative vs.  used in classifying genres as generic facets. A  involved or narrative vs. non-narrative. Factors  facet is simply a property which distinguishes a class  are not used for genre classification (the values of a  of texts that answers to certain practical interests,  text on the various dimensions are often not  inforand which is moreover associated with a  characterismative with respect to genre). Rather, factors are  tic set of computable structural or linguistic  properused to validate hypotheses about the functions of  ties, whether categorical or statistical, which we will  various linguistic features.  An important and more relevant set of  experican be described in terms of an indefinitely large  ments, which deserves careful attention, is presented  number of facets. For example, a newspaper story  in Karlgren and Cutting (1994).  They too begin  about a Balkan peace initiative is an example of a  with a corpus of hand-classified texts, the Brown  broadcast as opposed to directed  communicacorpus. One difficulty here, however, is that it is  tion, a property that correlates formally with  cernot clear to what extent the Brown corpus  classitain uses of the pronoun you. It is also an example fication used in this work is relevant for practical  of a narrative, as opposed to a directive (e.g.,  or theoretical purposes. For example, the category  in a manual), suasive (as in an editorial), or  de Popular Lore contains an article by the decidedly  scriptive (as in a market survey) communication;  highbrow Harold Rosenberg from Commentary, and  and this facet correlates, among other things, with  articles from Model Railroader and Gourmet, surely a high incidence of preterite verb forms.  not a natural class by any reasonable standard. In  Apart from giving us a theoretical framework for  addition, many of the text features in Karlgren and  understanding genres, facets offer two practical  adCutting are structural cues that require tagging. We  vantages. First, some applications benefit from  catwill replace these cues with two new classes of cues  egorization according to facet, not genre. For  exthat are easily computable: character-level cues and  ample, in an information retrieval context, we will  want to consider the opinion feature most highly  Identifying Genres: Generic Cues  This section discusses generic cues, the observable  (where W = word tokens, S = sentences, C =  charproperties of a text that are associated with facets.  acters, T = word types). The 55 cues in our  experiments can be combined to almost 3000 different  ratios. The log representation ensures that all these  ratios are available implicitly while avoiding  overfitizations, topicalized sentences, and counts of the  freting and the high computational cost of training on  quency of syntactic categories (e.g., part-of-speech  a large set of cues.  tags). These cues are not much discussed in the  traVariation measures capture the amount of  variaditional literature on genre, but have come to the  tion of a certain count cue in a text (e.g., the  stanfore in recent work (Biber, 1995; Karlgren and  Cutdard deviation in sentence length). This type of  useting, 1994). For purposes of automatic classification ful metric has not been used in previous work on  they have the limitation that they require tagged or  parsed texts.  The experiments in this paper are based on 55  cues from the last three groups: lexical,  characterlevel and derivative cues. These cues are easily  comMost facets are correlated with lexical cues.  Examputable in contrast to the structural cues that have  ples of ones that we use are terms of address (e.g.,  figured prominently in previous work on genre.  Mr. , Ms. ), which predominate in papers like the New York Times; Latinate affixes, which signal certain 3  highbrow registers like scientific articles or scholarly  works; and words used in expressing dates, which are  Corpus  common in certain types of narrative such as news  The corpus of texts used for this study was the  Brown Corpus. For the reasons mentioned above,  we used our own classification system, and  elimiCharacter-Level Cues  nated texts that did not fall unequivocally into one  Character-level cues are mainly punctuation cues  of our categories. We ended up using 499 of the  and other separators and delimiters used to mark  802 texts in the Brown Corpus. (While the Corpus  text categories like phrases, clauses, and sentences  contains 500 samples, many of the samples contain  (Nunberg, 1990). Such features have not been used several texts.)  in previous work on genre recognition, but we  beFor our experiments, we analyzed the texts in  lieve they have an important role to play, being at  terms of three categorical facets: Brow,  Narraonce significant and very frequent. Examples include  tive, and Genre. Brow characterizes a text in  counts of question marks, exclamations marks,  capterms of the presumptions made with respect to the  italized and hyphenated words, and acronyms.  required intellectual background of the target  auDerivative Cues  middle, and high. For example, the mainstream  Derivative cues are ratios and variation measures  deAmerican press is classified as middle and tabloid  rived from measures of lexical and character-level  newspapers as popular. The Narrative facet is  features.  binary, telling whether a text is written in a  narraRatios correlate in certain ways with genre, and  tive mode, primarily relating a sequence of events.  have been widely used in previous work. We  repreThe Genre facet has the values reportage,  edsent ratios implicitly as sums of other cues by  transitorial, scitech, legal, nonfiction, fiction.  forming all counts into natural logarithms. For  exThe first two characterize two types of articles from  ample, instead of estimating separate weights , ,  the daily or weekly press: reportage and editorials.  and for the ratios words per sentence (average  The level scitech denominates scientific or  technisentence length), characters per word (average word  cal writings, and legal characterizes various types  length) and words per type (token/type ratio),  reof writings about law and government  administraspectively, we express this desired weighting:  tion. Finally, nonfiction is a fairly diverse  category encompassing most other types of expository  writing, and fiction is used for works of fiction.  Our corpus of 499 texts was divided into a  trainas follows:  ing subcorpus (402 texts) and an evaluation  subcorpus (97). The evaluation subcorpus was designed  to have approximately equal numbers of all repre-3.3  Neural Networks  sented combinations of facet levels. Most such  comBecause of the high number of variables in our  exbinations have six texts in the evaluation corpus, but  periments, there is a danger that overfitting occurs.  due to small numbers of some types of texts, some  LR also forces us to simulate polytomous decisions  extant combinations are underrepresented. Within  by a series of binary decisions, instead of directly  this stratified framework, texts were chosen by a  pseudo random-number generator. This setup  results in different quantitative compositions of  trainFor these reasons, we ran a second set of  experiing and evaluation set. For example, the most  frements with neural networks, which generally do well  quent genre level in the training subcorpus is  rewith a high number of variables because they  proportage, but in the evaluation subcorpus  nonfictect against overfitting. Neural nets also naturally  tion predominates.  model variable interactions. We used two  architectures, a simple perceptron (a two-layer feed-forward  We chose logistic regression (LR) as our basic  numernetwork with all input units connected to all output  ical method. Two informal pilot studies indicated  units), and a multi-layer perceptron with all input  that it gave better results than linear discrimination  units connected to all units of the hidden layer, and  and linear regression.  all units of the hidden layer connected to all  outLR is a statistical technique for modeling a binary  put units. For binary decisions, such as determining  response variable by a linear combination of one or  whether or not a text is Narrative, the output  more predictor variables, using a logit link function:  layer consists of one sigmoidal output unit; for  polytomous decisions, it consists of four (Brow) or six  (Genre) softmax units (which implement a  multiand modeling variance with a binomial random  variThe size of the hidden layer was chosen to be three  modeled as a linear combination of the independent  times as large as the size of the output layer (3 units  variables. The model has the form g( ) = x  for binary decisions, 12 units for Brow, 18 units for  i where  is the estimated response probability (in our case  the probability of a particular facet value), x  For binary decisions, the simple perceptron fits  i is the  feature vector for text i, and is the weight vector  a logistic model just as LR does. However, it is  which is estimated from the matrix of feature  vecless prone to overfitting because we train it using  tors. The optimal value of is derived via maximum  three-fold cross-validation. Variables are selected  likelihood estimation (McCullagh and Nelder, 1989), by summing the cross-entropy error over the three  using SPlus (Statistical Sciences, 1991).  validation sets and eliminating the variable that if  For binary decisions, the application of LR was  eliminated results in the lowest cross-entropy error.  straightforward. For the polytomous facets genre  The elimination cycle is repeated until this summed  and brow, we computed a predictor function  indecross-entropy error starts increasing. Because this  pendently for each level of each facet and chose the  selection technique is time-consuming, we only  apcategory with the highest prediction.  ply it to a subset of the discriminations.  The most discriminating of the 55 variables were  selected using stepwise backward selection based on  the AIC criterion (see documentation for step.glm  Table 1 gives the results of the experiments. For each in Statistical Sciences (1991)).  A separate set of  variables was selected for each binary discrimination  cues (both with logistic regression and neural nets)  against results using Karlgren and Cutting's  structural cues on the one hand (last pair of columns)  In order to see whether our easily-computable  surand against a baseline on the other (first column).  face cues are comparable in power to the structural  Each text in the evaluation suite was tested for each  cues used in Karlgren and Cutting (1994), we also facet. Thus the number 78 for Narrative under  ran LR with the cues used in their experiment.  Bemethod LR (Surf.) All means that when all texts  cause we use individual texts in our experiments  inwere subjected to the Narrative test, 78% of them  stead of the fixed-length conglomerate samples of  were classified correctly.  Karlgren and Cutting, we averaged all count  feaThere are at least two major ways of conceiving  tures over text length.  what the baseline should be in this experiment. If  the machine were to guess randomly among k cat-5  egories, the probability of a correct guess would be  The experiments indicate that categorization  deci1/4 for Brow. But one could get dramatic  improvesions can be made with reasonable accuracy on the  ment just by building a machine that always guesses  basis of surface cues. All of the facet level  assignthe most populated category: nonfict for Genre,  ments are significantly better than a baseline of  almiddle for Brow, and No for Narrative. The  ways choosing the most frequent level (Table 1), and first approach would be fair, because our machines  the performance appears even better when one  conin fact have no prior knowledge of the distribution of  siders that the machines do not actually know what  genre facets in the evaluation suite, but we decided  the most frequent level is.  to be conservative and evaluate our methods against  When one takes a closer look at the performance  the latter baseline. No matter which approach one  of the component machines, it is clear that some  takes, however, each of the numbers in the table is  facet levels are detected better than others. Table 2  significant at p < .05 by a binomial distribution.  shows that within the facet Genre, our systems do  That is, there is less than a 5% chance that a  maa particularly good job on reportage and fiction,  chine guessing randomly could have come up with  trend correctly but not necessarily significantly for  results so much better than the baseline.  scitech and nonfiction, but perform less well for  It will be recalled that in the LR models, the  editorial and legal texts. We suspect that the  facets with more than two levels were computed by  indifferent performance in scitech and legal texts  means of binary decision machines for each level,  may simply reflect the fact that these genre levels are  then choosing the level with the most positive score.  fairly infrequent in the Brown corpus and hence in  Therefore some feeling for the internal functioning of  our training set. Table 3 sheds some light on the our algorithms can be obtained by seeing what the  other cases. The lower performance on the  editoperformance is for each of these binary machines,  rial and nonfiction tests stems mostly from  misand for the sake of comparison this information is  classifying many nonfiction texts as editorial.  also given for some of the neural net models.  TaSuch confusion suggests that these genre types are  ble 2 shows how often each of the binary machines closely related to each other, as in fact they are. Ed-correctly determined whether a text did or did not  itorials might best be treated in future experiments  fall in a particular facet level. Here again the  apas a subtype of nonfiction, perhaps distinguished  propriate baseline could be determined two ways.  by separate facets such as Opinion and  InstituIn a machine that chooses randomly, performance  tional Authorship.  would be 50%, and all of the numbers in the table  Although Table 1 shows that our methods pre-would be significantly better than chance (p < .05,  dict Brow at above-baseline levels, further analysis  binomial distribution). But a simple machine that  (Table 2) indicates that most of this performance always guesses No would perform much better, and  comes from accuracy in deciding whether or not a  it is against this stricter standard that we computed  text is high Brow. The other levels are identified  the baseline in Table 2. Here, the binomial distribu-at near baseline performance. This suggests  probtion shows that some numbers are not significantly  lems with the labeling of the Brow feature in the  better than the baseline. The numbers that are  sigtraining data. In particular, we had labeled  journalnificantly better than chance at p < .05 by the  biistic texts on the basis of the overall brow of the host  publication, a simplification that ignores variation  Tables 1 and 2 present aggregate results, when among authors and the practice of printing features  all texts are classified for each facet or level.  Tafrom other publications. We plan to improve those  ble 3, by contrast, shows which classifications are labelings in future experiments by classifying brow  assigned for texts that actually belong to a specific  on an article-by-article basis.  known level. For example, the first row shows that  The experiments suggest that there is only a  of the 18 texts that really are of the reportage  small difference between surface and structural cues.  Genre level, 83% were correctly classified as  reComparing LR with surface cues and LR with  strucportage, 6% were misclassified as editorial, and  tural cues as input, we find that they yield about the  11% as nonfiction. Because of space constraints,  same performance: averages of 77.0% (surface) vs.  we present this amount of detail only for the six  77.5% (structural) for all variables and 78.4%  (surGenre levels, with logistic regression on selected  face) vs. 78.9% (structural) for selected variables.  Looking at the independent binary decisions on a  task-by-task basis, surface cues are worse in 10 cases  Table 1: Classification Results for All Facets.  Narrative  Note. Numbers are the percentage of the evaluation subcorpus (N = 97) which were correctly assigned to the appropriate facet level; the Baseline column tells what percentage would be correct if the machine always guessed the most frequent level. LR is Logistic Regression, over our surface cues (Surf.) or Karlgren and Cutting's structural cues (Struct.); 2LP and 3LP are or 3-layer perceptrons using our surface cues. Under each experiment, All tells the results when all cues are used, and Sel. tells the results when for each level one selects the most discriminating cues. A dash indicates that an experiment was not run.  Table 2: Classification Results for Each Facet Level.  LR (Struct.)  Nonfict  Fict  High  Note. Numbers are the percentage of the evaluation subcorpus (N = 97) which was correctly classified on a binary discrimination task. The Baseline column tells what percentage would be got correct by guessing No for each level. Headers have the same meaning as in Table 1.  * means significantly better than Baseline at p < .05, using a binomial distribution (N =97, p as per first column).  Table 3: Genre Binary Level Classification Results by Genre Level.  Nonfict  Fict  Nonfict  Fict  Note. Numbers are the percentage of the texts actually belonging to the Genre level indicated in the first column that were classified as belonging to each of the Genre levels indicated in the column headers. Thus the diagonals are correct guesses, and each row would sum to 100%, but for rounding error.  and better in 8 cases. Such a result is expected if Speech and Writing. Cambridge University Press,  we assume that either cue representation is equally  Cambridge, England.  likely to do better than the other (assuming a  bino[Biber1992] Biber, Douglas. 1992. The  multidimenmial model, the probability of getting this or a more  sional approach to linguistic analyses of genre  b(i; 18, 0.5) = 0.41). We  convariation: An overview of methodology and  findclude that there is at best a marginal advantage to  ing. Computers in the Humanities, 26(5 6):331  using structural cues, an advantage that will not  justify the additional computational cost in most cases.  Our goal in this paper has been to prepare the  [Biber1995] Biber, Douglas. 1995. Dimensions of  ground for using genre in a wide variety of areas in  Register Variation: A Cross-Linguistic  Comparnatural language processing. The main remaining  ison.  Cambridge University Press, Cambridge,  technical challenge is to find an effective strategy for  variable selection in order to avoid overfitting  during training. The fact that the neural networks have  tle's Theory of Poetry and Fine Arts, with The  a higher performance on average and a much higher  Poetics. Macmillan, London. 4th edition.  performance for some discriminations (though at the  price of higher variability of performance) indicates  [Dubrow1982] Dubrow, Heather.  Methuen, London and New York.  that overfitting and variable interactions are  important problems to tackle.  [Fowler1982] Fowler, Alistair. 1982. Kinds of  LiteraOn the theoretical side, we have developed a  taxture. Harvard University Press, Cambridge,  Masonomy of genres and facets. Genres are considered  to be generally reducible to bundles of facets, though  sometimes with some irreducible atomic residue.  [Frye1957] Frye, Northrop. 1957. The Anatomy of  Criticism. Princeton University Press, Princeton,  This way of looking at the problem allows us to  New Jersey.  define the relationships between different genres  instead of regarding them as atomic entities. We also  have a framework for accommodating new genres as  Cornell University Press, Ithaca, New York.  yet unseen bundles of facets. Finally, by  decomposing genres into facets, we can concentrate on  what[Hobbes1908] Hobbes, Thomas. 1908. The answer of  ever generic aspect is important in a particular  applimr Hobbes to Sir William Davenant's preface  before Gondibert. In J.E. Spigarn, editor, Critical  cation (e.g., narrativity for one looking for accounts  Essays of the Seventeenth Century. The  Clarenof the storming of the Bastille).  don Press, Oxford.  Further practical tests of our theory will come  in applications of genre classification to tagging,  and  summarization, and other tasks in computational  Douglass Cutting. 1994. Recognizing text genres  linguistics.  We are particularly interested in  apwith simple metrics using discriminant analysis.  plications to information retrieval where users are  In Proceedings of Coling 94, Kyoto.  often looking for texts with particular, quite  nar[McCullagh and Nelder1989] McCullagh, P. and J.A.  row generic properties: authoritatively written  documents, opinion pieces, scientific articles, and so on.  ter 4, pages 101 123. Chapman and Hall, 2nd  Sorting search results according to genre will gain  edition.  importance as the typical data base becomes  increasingly heterogeneous. We hope to show that the  usefulness of retrieval tools can be dramatically  imguistics of Punctuation. CSLI Publications,  Stanford, California.  proved if genre is one of the selection criteria that  Yves Chauvin. 1995. Backpropagation: The basic  theory. In Yves Chauvin and David E. Rumelhart,  editors, Back-propagation: Theory, Architectures,  and Applications. Lawrence Erlbaum, Hillsdale,  ten textual dimensions in English: Resolving the  New Jersey, pages 1 34.  contradictory findings. Language, 62(2):384 413.  [Biber1988] Biber, Douglas. 1988. Variation across  [Statistical Sciences1991] Statistical Sciences. 1991.  S-PLUS Reference Manual. Statistical Sciences,  Seattle, Washington. 