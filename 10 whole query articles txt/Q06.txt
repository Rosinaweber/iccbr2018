 Learning Word Vectors for Sentiment Analysis Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts  Stanford University  Stanford, CA 94305  [amaas, rdaly, ptpham, yuze, ang, cgpotts]@stanford.edu Abstract  recognition, part of speech tagging, and document  retrieval (Turney and Pantel, 2010; Collobert and  Unsupervised vector-based approaches to  seWeston, 2008; Turian et al., 2010).  mantics can model rich lexical meanings, but  In this paper, we present a model to capture both  they largely fail to capture sentiment  information that is central to many word meanings and  semantic and sentiment similarities among words.  important for a wide range of NLP tasks. We  The semantic component of our model learns word  vectors via an unsupervised probabilistic model of vised and supervised techniques to learn word  documents. However, in keeping with linguistic and vectors capturing semantic term document in-cognitive research arguing that expressive content formation as well as rich sentiment content.  The proposed model can leverage both  conplan, 1999; Jay, 2000; Potts, 2007), we find that  this basic model misses crucial sentiment  informaformation as well as non-sentiment  annotations. We instantiate the model to utilize the  tion. For example, while it learns that wonderful document-level sentiment polarity annotations  and amazing are semantically close, it doesn't cap-present in many online documents (e.g. star  ture the fact that these are both very strong positive ratings). We evaluate the model using small,  sentiment words, at the opposite end of the spectrum widely used sentiment and subjectivity cor-from terrible and awful.  pora and find it out-performs several  previously introduced methods for sentiment  clasThus, we extend the model with a supervised  sification. We also introduce a large dataset  sentiment component that is capable of embracing  of movie reviews to serve as a more robust  many social and attitudinal aspects of meaning (Wil-benchmark for work in this area.  and Zhu, 2006; Snyder and Barzilay, 2007). This  Introduction  component of the model uses the vector  represenWord representations are a critical component of  tation of words to predict the sentiment annotations many natural language processing systems.  It is  on contexts in which the words appear. This causes common to represent words as indices in a vocab-words expressing similar sentiment to have similar ulary, but this fails to capture the rich relational vector representations. The full objective function structure of the lexicon. Vector-based models do  of the model thus learns semantic vectors that are much better in this regard. They encode continu-imbued with nuanced sentiment information. In our  ous similarities between words as distance or angle experiments, we show how the model can leverage  between word vectors in a high-dimensional space.  document-level sentiment annotations of a sort that The general approach has proven useful in tasks  are abundant online in the form of consumer reviews such as word sense disambiguation, named entity  for movies, products, etc. The technique is  suffiProceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 142 150, Portland, Oregon, June 19-24, 2011. c  2011 Association for Computational Linguistics  ciently general to work also with continuous and ing sentiment-imbued topics rather than embedding  multi-dimensional notions of sentiment as well as  words in a vector space.  non-sentiment annotations (e.g., political affiliation, Vector space models (VSMs) seek to model words  speaker commitment).  directly (Turney and Pantel, 2010). Latent  SemanAfter presenting the model in detail, we  protic Analysis (LSA), perhaps the best known VSM,  vide illustrative examples of the vectors it learns, explicitly learns semantic word vectors by apply-and then we systematically evaluate the approach  ing singular value decomposition (SVD) to factor a on document-level and sentence-level classification term document co-occurrence matrix. It is typical  tasks. Our experiments involve the small, widely  to weight and normalize the matrix values prior to used sentiment and subjectivity corpora of Pang and SVD. To obtain a k-dimensional representation for a Lee (2004), which permits us to make comparisons  given word, only the entries corresponding to the k with a number of related approaches and published  largest singular values are taken from the word's ba-results. We also show that this dataset contains many sis in the factored matrix. Such matrix factorization-correlations between examples in the training and  based approaches are extremely successful in  practesting sets. This leads us to evaluate on, and make tice, but they force the researcher to make a number publicly available, a large dataset of informal movie of design choices (weighting, normalization, dimen-reviews from the Internet Movie Database (IMDB).  sionality reduction algorithm) with little theoretical guidance to suggest which to prefer.  Related work  Using term frequency (tf) and inverse document  frequency (idf) weighting to transform the values  The model we present in the next section draws  inin a VSM often increases the performance of  respiration from prior work on both probabilistic topic trieval and categorization systems. Delta idf weight-modeling and vector-spaced models for word  meaning (Martineau and Finin, 2009) is a supervised vari-ings.  ant of idf weighting in which the idf calculation is Latent Dirichlet Allocation (LDA; (Blei et al.,  done for each document class and then one value  2003)) is a probabilistic document model that  asis subtracted from the other. Martineau and Finin  sumes each document is a mixture of latent  toppresent evidence that this weighting helps with sen-ics. For each latent topic T , the model learns a  timent classification, and Paltoglou and Thelwall  conditional distribution p(w|T ) for the probability (2010) systematically explore a number of weight-that word w occurs in T .  One can obtain a  king schemes in the context of sentiment analysis.  dimensional vector representation of words by first The success of delta idf weighting in previous work training a k-topic model and then filling the matrix suggests that incorporating sentiment information  with the p(w|T ) values (normalized to unit length).  into VSM values via supervised methods is  helpThe result is a word topic matrix in which the rows ful for sentiment analysis. We adopt this insight, are taken to represent word meanings. However,  but we are able to incorporate it directly into our because the emphasis in LDA is on modeling top-model's objective function.  ics, not word meanings, there is no guarantee that our approach with a representative sample of such  the row (word) vectors are sensible as points in a weighting schemes.)  k-dimensional space. Indeed, we show in section  4 that using LDA in this way does not deliver  robust word vectors. The semantic component of our  model shares its probabilistic foundation with LDA, To capture semantic similarities among words, we  but is factored in a manner designed to discover  derive a probabilistic model of documents which  word vectors rather than latent topics. Some recent learns word representations. This component does  work introduces extensions of LDA to capture  sennot require labeled data, and shares its foundation timent in addition to topical information (Li et al., with probabilistic topic models such as LDA. The  2010). Like LDA, these methods focus on  modelannotations to constrain words expressing similar  sentiment to have similar representations. We can  how closely its representation vector w matches the efficiently learn parameters for the joint objective scaling direction of . This idea is similar to the function using alternating maximization.  word vector inner product used in the log-bilinear language model of Mnih and Hinton (2007).  Capturing Semantic Similarities  Equation 1 resembles the probabilistic model of  We build a probabilistic model of a document  using a continuous mixture distribution over words in-as mixtures of latent topics. One could view the en-dexed by a multi-dimensional random variable .  tries of a word vector as that word's association We assume words in a document are conditionally  strength with respect to each latent topic dimension.  independent given the mixture variable . We assign The random variable then defines a weighting over a probability to a document d using a joint distribu-topics.  However, our model does not attempt to  tion over the document and . The model assumes  model individual topics, but instead directly models each word wi d is conditionally independent of  word probabilities conditioned on the topic mixture the other words given . The probability of a docu-variable . Because of the log-linear formulation of ment is thus  the conditional distribution, is a vector in R and Z  not restricted to the unit simplex as it is in LDA.  We now derive maximum likelihood learning for  this model when given a set of unlabeled documents D. In maximum likelihood learning we maximize  Where N is the number of words in d and wi is  the probability of the observed data given the model the ith word in d. We use a Gaussian prior on .  We define the conditional distribution p(wi| )  ussamples. Thus the learning problem becomes  ing a log-linear model with parameters R and b.  The energy function uses a word representation  matrix R R( x |V |) where each word w (represented max p(D; R, b) =  as a one-on vector) in the vocabulary V has a  sponding to that word's column in R. The random  Using maximum a posteriori (MAP) estimates for , variable is also a -dimensional vector, R  we approximate this learning problem as  which weights each of the dimensions of words'  representation vectors. We additionally introduce a Y  w for each word to capture differences in  overR,b  all word frequencies. The energy assigned to a word dk D  w given these model parameters is  where  k denotes the MAP estimate of for dk.  We introduce a Frobenious norm regularization term E(w; , w, bw) = T w bw.  for the word representation matrix R. The word  biTo obtain the distribution p(w| ) we use a softmax, ases b are not regularized reflecting the fact that we want the biases to capture whatever overall word fre-exp( E(w; , w, bw))  quency statistics are present in the data. By taking exp( E(w ; ,  the logarithm and simplifying we obtain the final  obexp( T  exp( T  The number of terms in the denominator's  summation grows linearly in |V |, making exact  computation of the distribution possible. For a given which is maximized with respect to R and b. The  , a word w's occurrence probability is related to hyper-parameters in the model are the regularization 144  weights ( and ), and the word vector  dimensionwhere (x) is the logistic function and R is the ality .  logistic regression weight vector. We additionally introduce a scalar bias bc for the classifier.  Capturing Word Sentiment  The logistic regression weights and bc define  a linear hyperplane in the word vector space where The model presented so far does not explicitly capa word vector's positive sentiment probability  deture sentiment information. Applying this algorithm pends on where it lies with respect to this hyper-to documents will produce representations where  plane. Learning over a collection of documents  rewords that occur together in documents have  simsults in words residing different distances from this ilar representations.  However, this unsupervised  hyperplane based on the average polarity of  docuapproach has no explicit way of capturing which  ments in which the words occur.  words are predictive of sentiment as opposed to  Given a set of labeled documents D where s  content-related. Much previous work in natural lan-k is  guage processing achieves better representations by k , we wish to  maximize the probability of document labels given  learning from multiple tasks (Collobert and Weston, the documents. We assume documents in the collec-2008; Finkel and Manning, 2009). Following this  tion and words within a document are i.i.d. samples.  theme we introduce a second task to utilize labeled By maximizing the log-objective we obtain,  documents to improve our model's word  representations.  cept. Depending on which aspects of sentiment we  wish to capture, we can give some body of text a  The conditional probability p(s  sentiment label s which can be categorical, continu-k|wi; R, , bc) is  easily obtained from equation 9.  ous, or multi-dimensional. To leverage such labels, we introduce an objective that the word vectors of 3.3  Learning  our model should predict the sentiment label using The full learning objective maximizes a sum of the some appropriate predictor,  two objectives presented. This produces a final objective function of,  s = f ( w).  Using an appropriate predictor function f (x) we  map a word vector w to a predicted sentiment label k=1  s. We can then improve our word vector w to better  predict the sentiment labels of contexts in which that  word occurs.  For simplicity we consider the case where the  sen|Sk| denotes the number of documents in the dataset timent label s is a scalar continuous value repre-with the same rounded value of sk (i.e. sk < 0.5  senting sentiment polarity of a document. This cap-and sk 0.5). We introduce the weighting 1 to  tures the case of many online reviews where  doccombat the well-known imbalance in ratings present uments are associated with a label on a star rating in review collections. This weighting prevents the scale. We linearly map such star values to the inter-overall distribution of document ratings from affect-val s [0, 1] and treat them as a probability of pos-ing the estimate of document ratings in which a paritive sentiment polarity. Using this formulation, we ticular word occurs. The hyper-parameters of the  employ a logistic regression as our predictor f (x).  model are the regularization weights ( and ), and We use w's vector representation w and regression the word vector dimensionality .  weights to express this as  Maximizing the objective function with respect to  R, b, , and bc is a non-convex problem. We use  alternating maximization, which first optimizes the 145  word representations (R, b, , and bc) while  leavbeled set of reviews contains neutral reviews as well ing the MAP estimates (  ) fixed. Then we find the  as those which are polarized as found in the labeled new MAP estimate for each document while leav-set. Training the model with additional unlabeled  ing the word representations fixed, and continue this data captures a common scenario where the amount  process until convergence. The optimization  algoof labeled data is small relative to the amount of un-rithm quickly finds a global solution for each  labeled data available. For all word vector models, cause we have a low-dimensional, convex problem  we use 50-dimensional vectors.  in each  k. Because the MAP estimation problems  As a qualitative assessment of word  represenfor different documents are independent, we can  tations, we visualize the words most similar to a  solve them on separate machines in parallel. This  query word using vector similarity of the learned  facilitates scaling the model to document collections representations.  Given a query word w and  anwith hundreds of thousands of documents.  other word w we obtain their vector representations w and w , and evaluate their cosine similarity as 4  . By assessing the  simiWe evaluate our model with document-level and  larity of w with all other words w , we can find the sentence-level categorization tasks in the domain of words deemed most similar by the model.  Table 1 shows the most similar words to given  tion, we compare our method to previously  pubquery words using our model's word representations lished results on a standard dataset, and introduce as well as those of LSA. All of these vectors capa new dataset for the task. In both tasks we  comture broad semantic similarities. However, both ver-pare our model's word representations with several sions of our model seem to do better than LSA in  bag of words weighting methods, and alternative ap-avoiding accidental distributional similarities (e.g., proaches to word vector induction.  screwball and grant as similar to romantic) A comparison of the two versions of our model also begins 4.1  Word Representation Learning  to highlight the importance of adding sentiment information. In general, words indicative of sentiment We induce word representations with our model us-tend to have high similarity with words of the same ing 25,000 movie reviews from IMDB. Because  sentiment polarity, so even the purely unsupervised some movies receive substantially more reviews  model's results look promising. However, they also than others, we limited ourselves to including at  show more genre and content effects. For  exammost 30 reviews from any movie in the collection.  ple, the sentiment enriched vectors for ghastly are We build a fixed dictionary of the 5,000 most fre-truly semantic alternatives to that word, whereas the quent tokens, but ignore the 50 most frequent terms vectors without sentiment also contain some content from the original full vocabulary. Traditional stop words that tend to have ghastly predicated of them.  word removal was not used because certain stop  Of course, this is only an impressionistic analysis of words (e.g. negating words) are indicative of senti-a few cases, but it is helpful in understanding why ment. Stemming was not applied because the model  the sentiment-enriched model proves superior at the learns similar representations for words of the same sentiment classification results we report next.  stem when the data suggests it. Additionally,  because certain non-word tokens (e.g. ! and :-) ) 4.2  Other Word Representations  are indicative of sentiment, we allow them in our vocabulary. Ratings on IMDB are given as star values For comparison, we implemented several alternative ( {1, 2, ..., 10}), which we linearly map to [0, 1] to vector space models that are conceptually similar to use as document labels when training our model.  our own, as discussed in section 2:  The semantic component of our model does not  We apply truncated SVD to a tf.idf  model which uses 50,000 unlabeled reviews in  addiweighted, cosine normalized count matrix, which  tion to the labeled set of 25,000 reviews. The unla-is a standard weighting and smoothing scheme for  Semantic only  thoughtful  heartbreaking  warmth  lyrical  melancholy  profound  embarrassingly  hideous  hideous  ghastly  severely  atrocious  unsuspecting  charming  relationship  chemistry  comedy  Table 1: Similarity of learned word vectors. Each target word is given with its five most similar words using cosine similarity of the vectors determined by each model. The full version of our model (left) captures both lexical similarity as well as similarity of sentiment strength and orientation. Our unsupervised semantic component (center) and LSA (right) capture semantic relations.  VSM induction (Turney and Pantel, 2010).  of such weighting variants for sentiment tasks.  Allocation  We use the method described in  secDocument Polarity Classification  tion 2 for inducing word representations from the  Our first evaluation task is document-level  sentitopic matrix. To train the 50-topic LDA model we  ment polarity classification. A classifier must pre-use code released by Blei et al. (2003). We use the dict whether a given review is positive or negative same 5,000 term vocabulary for LDA as is used for  given the review text.  training word vector models. We leave the LDA  Given a document's bag of words vector v, we  hyperparameters at their default values, though  obtain features from our model using a  matrixsome work suggests optimizing over priors for LDA  vector product Rv, where v can have arbitrary tf.idf is important (Wallach et al., 2009).  weighting. We do not cosine normalize v, instead  Weighting Variants  We evaluate both binary (b)  applying cosine normalization to the final feature term frequency weighting with smoothed delta idf  vector Rv. This procedure is also used to obtain  ( t') and no idf (n) because these variants worked features from the LDA and LSA word vectors. In  well in previous experiments in sentiment  (Marpreliminary experiments, we found bnn' weighting  tineau and Finin, 2009; Pang et al., 2002). In all to work best for v when generating document fea-cases, we use cosine normalization (c). Paltoglou  tures via the product Rv. In all experiments, we  and Thelwall (2010) perform an extensive analysis  use this weighting to get multi-word representations 147  Features  Subjectivity  Bag of Words (bnc)  Bag of Words (b t'c)  Our Semantic Only  Our Full, Additional Unlabeled  Our Semantic + Bag of Words (bnc)  Our Full + Bag of Words (bnc)  Our Full, Add'l Unlabeled + Bag of Words (bnc)  Bag of Words SVM (Pang and Lee, 2004)  Contextual Valence Shifters (Kennedy and Inkpen, 2006) 86.20  tf. idf Weighting (Martineau and Finin, 2009)  Appraisal Taxonomy (Whitelaw et al., 2005)  Table 2: Classification accuracy on three tasks. From left to right the datasets are: A collection of 2,000 movie reviews often used as a benchmark of sentiment classification (Pang and Lee, 2004), 50,000 reviews we gathered from IMDB, and the sentence subjectivity dataset also released by (Pang and Lee, 2004). All tasks are balanced two-class problems.  from word vectors.  Our method's features clearly outperform those of  other VSMs, and perform best when combined with  the original bag of words representation. The vari-The polarity dataset version 2.0 introduced by Pang ant of our model trained with additional unlabeled and Lee (2004) 1 consists of 2,000 movie reviews,  data performed best, suggesting the model can effec-where each is associated with a binary sentiment po-tively utilize large amounts of unlabeled data along larity label. We report 10-fold cross validation re-with labeled examples. Our method performs  comsults using the authors' published folds to make our petitively with previously reported results in spite of results comparable with others in the literature. We our restriction to a vocabulary of only 5,000 words.  use a linear support vector machine (SVM) classifier We extracted the movie title associated with each  trained with LIBLINEAR (Fan et al., 2008), and set review and found that 1,299 of the 2,000 reviews in the SVM regularization parameter to the same value the dataset have at least one other review of the same used by Pang and Lee (2004).  movie in the dataset. Of 406 movies with multiple  Table 2 shows the classification performance of  reviews, 249 have the same polarity label for all of our method, other VSMs we implemented, and pre-their reviews. Overall, these facts suggest that, rela-viously reported results from the literature. Bag of tive to the size of the dataset, there are highly corre-words vectors are denoted by their weighting  notalated examples with correlated labels. This is a nat-tion. Features from word vector learner are denoted ural and expected property of this kind of document by the learner name. As a control, we trained ver-collection, but it can have a substantial impact on sions of our model with only the unsupervised se-performance in datasets of this scale. In the random mantic component, and the full model (semantic and folds distributed by the authors, approximately 50%  sentiment). We also include results for a version of of reviews in each validation fold's test set have a our full model trained with 50,000 additional unla-review of the same movie with the same label in the beled examples. Finally, to test whether our mod-training set. Because the dataset is small, a learner els' representations complement a standard bag of  may perform well by memorizing the association  bewords, we evaluate performance of the two feature  tween label and words unique to a particular movie representations concatenated.  (e.g., character names or plot terms).  1http://www.cs.cornell.edu/people/pabo/movie-review-data We introduce a substantially larger dataset, which 148  uses disjoint sets of movies for training and testing.  is substantially different from the review classifica-These steps minimize the ability of a learner to rely tion task because it uses sentences as opposed to en-on idiosyncratic word class associations, thereby  tire documents and the target concept is subjectivity focusing attention on genuine sentiment features.  instead of opinion polarity. We randomly split the 10,000 examples into 10 folds and report 10-fold  cross validation accuracy using the SVM training  We constructed a collection of 50,000 reviews from protocol of Pang and Lee (2004).  IMDB, allowing no more than 30 reviews per movie.  Table 2 shows classification accuracies from the  The constructed dataset contains an even number of sentence subjectivity experiment. Our model again  positive and negative reviews, so randomly guessing provided superior features when compared against  yields 50% accuracy. Following previous work on  other VSMs. Improvement over the bag-of-words  polarity classification, we consider only highly po-baseline is obtained by concatenating the two feature larized reviews. A negative review has a score 4  vectors.  out of 10, and a positive review has a score 7  out of 10. Neutral reviews are not included in the 5  dataset. In the interest of providing a benchmark for future work in this area, we release this dataset to the public.2  We presented a vector space model that learns word We evenly divided the dataset into training and  representations captuing semantic and sentiment in-test sets. The training set is the same 25,000  laformation.  The model's probabilistic foundation  beled reviews used to induce word vectors with our gives a theoretically justified technique for word model.  We evaluate classifier performance after  vector induction as an alternative to the overwhelm-cross-validating classifier parameters on the training ing number of matrix factorization-based techniques set, again using a linear SVM in all cases. Table 2  commonly used. Our model is parametrized as a  shows classification performance on our subset of  log-bilinear model following recent success in  usIMDB reviews. Our model showed superior  pering similar techniques for language models (Bengio formance to other approaches, and performed best  et al., 2003; Collobert and Weston, 2008; Mnih and when concatenated with bag of words representa-Hinton, 2007), and it is related to probabilistic latent tion. Again the variant of our model which utilized topic models (Blei et al., 2003; Steyvers and Grif-extra unlabeled data during training performed best.  fiths, 2006). We parametrize the topical component of our model in a manner that aims to capture word Differences in accuracy are small, but, because  representations instead of latent topics. In our ex-our test set contains 25,000 examples, the variance periments, our method performed better than LDA,  of the performance estimate is quite low. For  exwhich models latent topics directly.  ample, an accuracy increase of 0.1% corresponds to correctly classifying an additional 25 reviews.  We extended the unsupervised model to  incorporate sentiment information and showed how this  Subjectivity Detection  extended model can leverage the abundance of  sentiment-labeled texts available online to yield  As a second evaluation task, we performed sentence-word representations that capture both sentiment  level subjectivity classification. In this task, a clas-and semantic relations. We demonstrated the  utilsifier is trained to decide whether a given sentence is ity of such representations on two tasks of senti-subjective, expressing the writer's opinions, or ob-ment classification, using existing datasets as well jective, expressing purely facts. We used the dataset as a larger one that we release for future research.  of Pang and Lee (2004), which contains subjective  These tasks involve relatively simple sentiment in-sentences from movie review summaries and  objecformation, but the model is highly flexible in this tive sentences from movie plot summaries. This task regard; it can be used to characterize a wide variety 2Dataset and further details are available online at: of annotations, and thus is broadly applicable in the http://www.andrew-maas.net/data/sentiment  growing areas of sentiment analysis and retrieval.  Acknowledgments  F. Li, M. Huang, and X. Zhu. 2010. Sentiment analysis with global topics and local dependency. In Proceed-This work is supported by the DARPA Deep  Learnings of AAAI, pages 1371 1376.  ing program under contract number  FA8650-10-CC. Lin and Y. He. 2009. Joint sentiment/topic model for 7020, an NSF Graduate Fellowship awarded to AM,  sentiment analysis. In Proceeding of the 18th ACM  and ONR grant No. N00014-10-1-0109 to CP.  Conference on Information and Knowledge Management, pages 375 384.  J. Martineau and T. Finin. 2009. Delta tfidf: an improved C. O. Alm, D. Roth, and R. Sproat. 2005. Emotions from feature space for sentiment analysis. In Proceedings text: machine learning for text-based emotion predic-of the 3rd AAAI International Conference on Weblogs tion. In Proceedings of HLT/EMNLP, pages 579 586.  and Social Media, pages 258 261.  A. Mnih and G. E. Hinton. 2007. Three new graphical Net for fuzzy sentiment: sentiment tag extraction from models for statistical language modelling. In Proceed-WordNet glosses.  In Proceedings of the European  ings of the ICML, pages 641 648.  G. Paltoglou and M. Thelwall. 2010. A study of informa-Y. Bengio, R. Ducharme, P. Vincent, and C. Jauvin. 2003.  tion retrieval weighting schemes for sentiment analy-a neural probabilistic language model. Journal of Ma-sis. In Proceedings of the ACL, pages 1386 1395.  chine Learning Research, 3:1137 1155, August.  B. Pang and L. Lee. 2004. A sentimental education: D. M. Blei, A. Y. Ng, and M. I. Jordan. 2003. Latent sentiment analysis using subjectivity summarization dirichlet allocation. Journal of Machine Learning Re-based on minimum cuts. In Proceedings of the ACL, search, 3:993 1022, May.  J. Boyd-Graber and P. Resnik. 2010. Holistic sentiment B. Pang and L. Lee. 2005. Seeing stars: exploiting class analysis across languages: multilingual supervised la-relationships for sentiment categorization with respect tent Dirichlet allocation. In Proceedings of EMNLP, to rating scales. In Proceedings of ACL, pages 115  R. Collobert and J. Weston. 2008. A unified architecture B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs for natural language processing. In Proceedings of the up? sentiment classification using machine learning ICML, pages 160 167.  techniques. In Proceedings of EMNLP, pages 79 86.  S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. LanC. Potts. 2007. The expressive dimension. Theoretical dauer, and R. Harshman. 1990. Indexing by latent se-Linguistics, 33:165 197.  mantic analysis. Journal of the American Society for B. Snyder and R. Barzilay. 2007. Multiple aspect rank-Information Science, 41:391 407, September.  ing using the good grief algorithm. In Proceedings of R. E. Fan, K. W. Chang, C. J. Hsieh, X. R. Wang, and NAACL, pages 300 307.  C. J. Lin. 2008. LIBLINEAR: A library for large lin-M. Steyvers and T. L. Griffiths. 2006. Probabilistic topic ear classification. The Journal of Machine Learning models. In T. Landauer, D McNamara, S. Dennis, and Research, 9:1871 1874, August.  W. Kintsch, editors, Latent Semantic Analysis: A Road J. R. Finkel and C. D. Manning. 2009. Joint parsing and to Meaning.  named entity recognition. In Proceedings of NAACL, J. Turian, L. Ratinov, and Y. Bengio. 2010. Word rep-pages 326 334.  resentations: A simple and general method for semi-A. B. Goldberg and J. Zhu. 2006. Seeing stars when supervised learning. In Proceedings of the ACL, page there aren't many stars: graph-based semi-supervised 384394.  learning for sentiment categorization. In TextGraphs: P. D. Turney and P. Pantel. 2010. From frequency to HLT/NAACL Workshop on Graph-based Algorithms  meaning: vector space models of semantics. Journal for Natural Language Processing, pages 45 52.  of Artificial Intelligence Research, 37:141 188.  Why We Curse:  H. Wallach, D. Mimno, and A. McCallum. 2009.  ReSocial Theory of Speech. John Benjamins, Philadel-thinking LDA: why priors matter. In Proceedings of phia/Amsterdam.  D. Kaplan. 1999. What is meaning? Explorations in the C. Whitelaw, N. Garg, and S. Argamon. 2005. Using ap-theory of Meaning as Use. Brief version draft 1.  praisal groups for sentiment analysis. In Proceedings Ms., UCLA.  of CIKM, pages 625 631.  A. Kennedy and D. Inkpen.  T. Wilson, J. Wiebe, and R. Hwa. 2004. Just how mad sification of movie reviews using contextual valence are you? Finding strong and weak opinion clauses. In shifters.  Proceedings of AAAI, pages 761 769. 